{"0": {
    "doc": "CS 684 (Sp24)",
    "title": "Welcome to CS 684!",
    "content": "Welcome to CS 684! This class is focused on software quality: both how to assess it and how to achieve it in your own work. The course therefore has two technical focuses: testing and static analysis, both of which are important for assuring quality in the real world. We’ll spend roughly 60% of the course (through spring break) on testing, and the rest of the course on static analysis. My goal in this course is to get you up-to-date with the best practices at the very best software engineering firms in the world in these two topics: that is, the goal of this course is to give you a firm foundation in the “state-of-the-practice” in industry. Note that reaching this level requires us to engage with the research literature, as the top engineers at the best software firms do—–especially the most important papers from the past 10-20 years. On this course website, you can find: . | the syllabus, | a course calendar (which includes links to the required readings), | links to all assignments, | useful tutorials, | a staff page, and | information about how I write exams (including old exams that I have written for undergraduate versions of this course, with solutions). | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/#welcome-to-cs-684",
    "relUrl": "/#welcome-to-cs-684"
  },"1": {
    "doc": "CS 684 (Sp24)",
    "title": "CS 684 (Sp24)",
    "content": " ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/",
    "relUrl": "/"
  },"2": {
    "doc": "Syllabus",
    "title": "Syllabus",
    "content": "Welcome to CS 684! This class is focused on software quality: both how to assess it and how to achieve it in your own work. The course therefore has two technical focuses: testing and static analysis, both of which are important for assuring quality in the real world. We’ll spend roughly 60% of the course (through spring break) on testing, and the rest of the course on static analysis. My goal in this course is to get you up-to-date with the best practices at the very best software engineering firms in the world in these two topics: that is, the goal of this course is to give you a firm foundation in the “state-of-the-practice” in industry. Note that reaching this level requires us to engage with the research literature, as the top engineers at the best software firms do—–especially the most important papers from the past 10-20 years. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/",
    "relUrl": "/about/"
  },"3": {
    "doc": "Syllabus",
    "title": "Prerequisites",
    "content": "While this course has no official prerequisites, I will assume in this course that you already know how to program: that is, that if I tell you to go write some code, you’ll be able to go do it. Since this course focuses on how to program well (i.e., how to engineer software!), you first need to know how to program at all. I’ll also assume some familiarity with command line tools, debugging, and using a search engine: I expect that if I ask you to go write code in some language you’ve never seen before, you’ll be able to find the necessary components online, find an online tutorial on the syntax, and figure out how to write that code. Put another way, I won’t teach you how to write a program: this course already assumes that you can do that. It is a graduate-level CS elective, after all. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#prerequisites",
    "relUrl": "/about/#prerequisites"
  },"4": {
    "doc": "Syllabus",
    "title": "Topics",
    "content": "The course is primarily structured around covering two topics in depth: testing and static analysis. We will cover testing in the greatest depth, including at least the following topics: . | formal definitions of testing | basic testing terminology and theory (e.g., unit vs integration testing, regression tests, etc.) | coverage | fuzzing and random test input generation | mutation testing and analysis | oracles and oracle generation | differential testing | . In addition, we will cover other analysis techniques for quality assurance. These will include at least: . | dataflow analysis | abstract interpretation | reduction of program analysis problems to SMT | other useful dynamic analyses beyond testing, such as dynamic race detectors | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#topics",
    "relUrl": "/about/#topics"
  },"5": {
    "doc": "Syllabus",
    "title": "Course Structure",
    "content": "This is an evening class in a three-hour block. Three hours is a long time, and I do not think you all want to listen to me talk for that long; further, I do not want to lecture for three hours straight every week. With that in mind, almost all classes will be split into two parts: a “lecture” part first, followed by a in-class exercise. Each in-class exercise is also a homework assignment (and all homework assignments begin as in-class exercises). These assignments are generally due one week later (i.e., by the end of the day before the next class), though there is one exception to this (the mutation testing assignment is longer and worth more points, so I’ve spread it over two weeks; there is no in-class for “other dynamic analyses” to compensate for that). During the in-class exercise period, the TA and I will circulate through the room and answer questions about the assignments. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#course-structure",
    "relUrl": "/about/#course-structure"
  },"6": {
    "doc": "Syllabus",
    "title": "Grading and Assignments",
    "content": "Your grade is composed of the following sub-scores (in no particular order): . | 60%: Homeworks | 25%: Exams (10% for the midterm, 15% for the final) | 15%: Participation &amp; Professionalism | . This class will be curved: when grading, I prefer to use the whole range available rather than scores in a tight range. That is, if an assignment is worth 10 points, I will give grades at all the points between 0 and 10. I will project your raw scores onto the final distribution twice during the semester: . | after the mid-term exam | shortly before the final exam | . You will be notified of your current projected class grade via email at each of these points. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#grading-and-assignments",
    "relUrl": "/about/#grading-and-assignments"
  },"7": {
    "doc": "Syllabus",
    "title": "Readings and Reading Responses",
    "content": "Each lecture has mandatory readings. I expect you to read mandatory readings before coming to class that day, and I will check that you’ve done so using reading quizzes (see Participation &amp; Professionalism, below). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#readings-and-reading-responses",
    "relUrl": "/about/#readings-and-reading-responses"
  },"8": {
    "doc": "Syllabus",
    "title": "Participation &amp; Professionalism",
    "content": "Your participation &amp; professionalism grade is composed of two scores. First, your Professionalism score is based on the instructors’ impression of how well you participated in class, with deductions for distracting other students and credit for asking and answering questions (either in person or on the course discussion board). Second, your Participation score is based on reading quizzes at the beginning of most lectures. You get half credit on these quizzes just for being there, and half credit for answering the reading questions correctly (the questions will always be easy if you did the reading). For full participation, you need to get at least a score of 70% on all quizzes over the whole semester (this gives you space to e.g., miss a reading quiz because you were sick or have a family emergency - there are no excuses for missing reading quizzes). Put another way, you can miss up to 30% of the reading quiz points and still get full participation points. These policies are designed to encourage you to come to class. A big part of the goal of this class is to help you develop an intuition for what good software engineering looks like, and without coming to class you won’t get the full benefit of that intuition. Remote Participation . Generally this class does not support remote participation: teaching is much more effective, in my experience, when everyone is physically present. However, I understand that sometimes you are sick, traveling, or otherwise unable to come to class. I will arrange for remote participation in any particular lecture as long as you request it at least one hour in advance (if you’re sick or in some other emergency) or 24 hours in advance (if you’re traveling or otherwise planning to be unable to come to class). Notify the instructor via email if you need to participate in a particular class remotely. Asking Questions . There is a course Discord server which you can use to ask (and answer) questions about any of the course topics or for help with the homework. Participating on Discord is optional, but if you do participate in a productive manner (especially by answering other student’s questions!), it can have a positive impact on your participation score. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#participation--professionalism",
    "relUrl": "/about/#participation--professionalism"
  },"9": {
    "doc": "Syllabus",
    "title": "Exams",
    "content": "There are two exams in this course: . | a mid-term, which is held in class about halfway through the semester (worth 10% of your course grade) | a final exam, which is held during the university-scheduled final exam slot (worth 15% of your course grade) | . Both exams will cover a range of topics discussed in lecture and/or in the mandatory readings, from any time during the semester up to the point when the exam is held. The exam will be comprehensive, covering many of the topics we discuss; I may ask about anything we covered in class or that you were supposed to read. The exam will be conducted in person. Contact the course staff privately via email if you are not able to attend for any reason (e.g., you are sick or need special accommodations) and we will arrange an alternative. See the exams page for more information. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#exams",
    "relUrl": "/about/#exams"
  },"10": {
    "doc": "Syllabus",
    "title": "Collaboration Policy",
    "content": "Collaboration is generally encouraged in this course, as is consulting online resources. You are permitted to copy small amounts of code from any source except another student’s copy of an assignment, as long as you cite your source. “Another student’s copy of an assignment” also includes students not currently enrolled in the course - e.g., students who took this class in previous semesters or took classes that used similar materials at other institutions. To make this more clear, here are some examples of acceptable and unacceptable collaboration on a programming assignment in this course: . Acceptable collaborations: . | Discuss problems/solutions/anything with any number of other students (as long as you don’t look at each other’s code). | Copy a short (about 10 lines or fewer - use your judgment) snippet from stackoverflow.com or a similar source, as long as you include a comment with the source URL. | Copy code written by one of your teammates during the group project for another part of the group project. | Copy code from the output of a large language model such as ChatGPT that you prompted yourself, if you include a link to a record of your interaction with the model (e.g., ChatGPT’s “share” feature) as a code comment. | . Unacceptable collaborations: . | Copy code directly from another student on an individual project. | Copy code from another group on a group project. | Copy a significant portion (more than about 10 lines of code or a single method - use your judgment) of your assignment from the internet, even if you cite your source. | Copy a short snippet from the internet without citing your source. | Copy code from the output of a large language model (such as ChatGPT) without citing your source | Copy code from the output of a large language model prompted by someone other than you | . These rules are intended to mimic what is acceptable in industry when working as a software engineer: using the resources available to you, such as your teammates and the wider internet, is always allowed. But, it would be illegal to copy code from a competing company working on a similar product. The same rules apply to English writing, although you should avoid copying text whole-sale from any source (this specifically means that using an LLM to help you with writing is allowed, but do note that I don’t think LLMs produce particularly lucid text, so you should definitely avoid using LLM-generated text without editing it heavily if you want to do well on a written assignment). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#collaboration-policy",
    "relUrl": "/about/#collaboration-policy"
  },"11": {
    "doc": "Syllabus",
    "title": "Consequences of Violating the Collaboration Policy",
    "content": "(From the University) . “Academic Integrity is the cornerstone of higher education and is central to the ideals of this course and the university. Cheating is strictly prohibited and devalues the degree that you are working on. As a member of the NJIT community, it is your responsibility to protect your educational investment by knowing and following the academic code of integrity policy that is found at: http://www5.njit.edu/policies/sites/policies/files/academic-integrity-code.pdf. Please note that it is my professional obligation and responsibility to report any academic misconduct to the Dean of Students Office. Any student found in violation of the code by cheating, plagiarizing or using any online software inappropriately will result in disciplinary action. This may include a failing grade of F, and/or suspension or dismissal from the university. If you have any questions about the code of Academic Integrity, please contact the Dean of Students Office at dos@njit.edu” . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#consequences-of-violating-the-collaboration-policy",
    "relUrl": "/about/#consequences-of-violating-the-collaboration-policy"
  },"12": {
    "doc": "Syllabus",
    "title": "Late Policy",
    "content": "You may use a late day on a homework assignment up to twice throughout the semester. Assignments are generally due on a particular day “anywhere on Earth” (AoE), which is typically 7am the following day on the US east coast. Using a late day allows you to submit up to 24 hours later without penalty. Assignments turned in more than one day late or after you have already used two late days during the semester will not be accepted. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#late-policy",
    "relUrl": "/about/#late-policy"
  },"13": {
    "doc": "Syllabus",
    "title": "Acknowledgments",
    "content": "This course is heavily inspired by a number of other courses in software engineering at other universities, especially: . | René Just’s CSE 504P at the University of Washington | Michael Ernst’s CSE 503 at the University of Washington | Wes Weimer’s EECS 481 at the University of Michigan | . Thanks especially to René and Wes for permitting me to reuse assignment specifications from their courses. As a student, if you’re looking for more materials (or just a different perspective) on any of the topics we cover, you might start with those (excellent) courses. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/about/#acknowledgments",
    "relUrl": "/about/#acknowledgments"
  },"14": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/",
    "relUrl": "/calendar/"
  },"15": {
    "doc": "Calendar",
    "title": "Week 1",
    "content": "Jan 18 Introduction Reading: none, but you should come to class (even if you’re on the waitlist). In-class: background survey and start HW0 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-1",
    "relUrl": "/calendar/#week-1"
  },"16": {
    "doc": "Calendar",
    "title": "Week 2",
    "content": "Jan 24 Homework 0 due Jan 25 Testing Basics Reading: Shore’s The Art of Agile Development: Test-Driven Development and SQLite’s How SQLite is Tested In-class: start HW1 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-2",
    "relUrl": "/calendar/#week-2"
  },"17": {
    "doc": "Calendar",
    "title": "Week 3",
    "content": "Jan 31 Homework 1 due Feb 1 Coverage Reading: Ivankovic et al.’s Code Coverage at Google and Chen et al.’s Revisiting the Relationship Between Fault Detection, Test Adequacy Criteria, and Test Set Size In-class: start HW2 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-3",
    "relUrl": "/calendar/#week-3"
  },"18": {
    "doc": "Calendar",
    "title": "Week 4",
    "content": "Feb 7 Homework 2 due Feb 8 Fuzzing Reading: Zeller’s Fuzzing: Breaking Things With Random Inputs In-class: start HW3 . Lecture recording: video (.mp4), transcript (.vtt) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-4",
    "relUrl": "/calendar/#week-4"
  },"19": {
    "doc": "Calendar",
    "title": "Week 5",
    "content": "Feb 14 Homework 3 due Feb 15 More Test Input Generation Reading: Fraser and Arcuri’s EvoSuite: Automatic Test Suite Generation for Object-Oriented Software In-class: start HW4 . Lecture recording: video (.mp4), transcript (.vtt) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-5",
    "relUrl": "/calendar/#week-5"
  },"20": {
    "doc": "Calendar",
    "title": "Week 6",
    "content": "Feb 21 Homework 4 due Feb 22 Oracles and Invariants Reading: Ernst et al.’s The Daikon system for dynamic detection of likely invariants and Yang et al.’s Finding and Understanding Bugs in C Compilers In-class: start HW5 . Lecture recording: video (.mp4), transcript (.vtt) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-6",
    "relUrl": "/calendar/#week-6"
  },"21": {
    "doc": "Calendar",
    "title": "Week 7",
    "content": "Feb 28 Homework 5 due Feb 29 Mutation Testing Reading: Petrović et al.’s Practical Mutation Testing at Scale:A view from Google In-class: start HW6 . Lecture recording: video (.mp4), transcript (.vtt) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-7",
    "relUrl": "/calendar/#week-7"
  },"22": {
    "doc": "Calendar",
    "title": "Week 8",
    "content": "Mar 7 Other Dynamic Analyses Reading: Musuvathi et al.’s Finding and Reproducing Heisenbugs in Concurrent Programs In-class: continue working on HW6 . Lecture recording: video (.mp4), transcript (.vtt) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-8",
    "relUrl": "/calendar/#week-8"
  },"23": {
    "doc": "Calendar",
    "title": "Week 9",
    "content": "Mar 13 Homework 6 due Mar 14 No class (spring break) ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-9",
    "relUrl": "/calendar/#week-9"
  },"24": {
    "doc": "Calendar",
    "title": "Week 10",
    "content": "Mar 21 Intro to Static Analysis Reading: none (study for the midterm) In-class: midterm . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-10",
    "relUrl": "/calendar/#week-10"
  },"25": {
    "doc": "Calendar",
    "title": "Week 11",
    "content": "Mar 28 Dataflow Analysis Reading: Ayewah et al.’s Experiences Using Static Analysis to Find Bugs Lecture recording: webex . In-class: start HW7 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-11",
    "relUrl": "/calendar/#week-11"
  },"26": {
    "doc": "Calendar",
    "title": "Week 12",
    "content": "Apr 3 Homework 7 due Apr 4 Abstract Interpretation (1) Reading: sections 2.0 to 2.14 of Ernst’s Notes on Program Analysis Lecture Recording . In-class: start HW8 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-12",
    "relUrl": "/calendar/#week-12"
  },"27": {
    "doc": "Calendar",
    "title": "Week 13",
    "content": "Apr 10 Homework 8 due Apr 11 Abstract Interpretation (2) Reading: sections 2.15 to 2.20 of Ernst’s Notes on Program Analysis and sections 1.0 to 2.2 of Jones and Nielson’s Abstract Interpretation: a semantics-based tool for program analysis, then skim the remainder of chapter 2 of the same Demo script . Lecture Recording . In-class: start HW9 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-13",
    "relUrl": "/calendar/#week-13"
  },"28": {
    "doc": "Calendar",
    "title": "Week 14",
    "content": "Apr 17 Homework 9 due Apr 18 Using SMT solvers Reading: Bjørner et al.’s Programming Z3 (article begins on page 165 of the PDF; not as long as it looks!). Optional additional reading (may be useful for studying for the final) on some of the topics covered in class: Chapter 12 of Aldrich, Le Goues, and Padhye (chapter 12 starts on page 77 of the PDF). Demo code . Lecture Recording . In-class: start HW10 . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-14",
    "relUrl": "/calendar/#week-14"
  },"29": {
    "doc": "Calendar",
    "title": "Week 15",
    "content": "Apr 24 Homework 10 due Apr 25 Class’ Choice: DevOps and Wrapup Reading: Sloss’ “Introduction”, Baye’s “Emergency Response”, and Lunney and Lueder’s “Postmortem Culture: Learning from Failure” from Google’s Site Reliability Engineering Lecture recording . In-class: fill out the course evaluation . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-15",
    "relUrl": "/calendar/#week-15"
  },"30": {
    "doc": "Calendar",
    "title": "Week 16",
    "content": "Exam Slot (May 9, 6PM, CKB 313) final exam (cumulative, about half from before the midterm and half after) ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/calendar/#week-16",
    "relUrl": "/calendar/#week-16"
  },"31": {
    "doc": "Exams",
    "title": "Exams",
    "content": "My exams are generally cumulative: anything we’ve covered in the course up to the point at which you take the exam is fair game. I may also include questions about assigned mandatory readings, homework assignments, or any other class content that you are supposed to have viewed. My exam design philosophy is to aim for a wide range of question difficulties: I try to include both some questions that I think every student should get right and some questions that I think are difficult enough that only those who have deeply understood multiple concepts that we covered in class will even be able to answer them in a reasonable way, and everything in between. To help you prepare for this class’ exams, below you can find links to exams from my undergraduate software engineering course, all of which have solutions (“keys”). These exams are for a lower-level but broader course, so you’ll want to be careful when studying using them—not everything on these exams will be covered in this class. I’m releasing them to you here so that you can get an idea of the sorts of exam questions that I like to ask, and so that you’ll be prepared for the format of the exams (I expect the exams in 684 to follow the same general format). CS 490 Sp23 Practice Final (key) . CS 490 Sp23 Final (key) . CS 490 Au23 Midterm (key) . CS 490 Au23 Final (key) . CS 684 Sp24 Midterm (key) . CS 684 Sp24 Final (key) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/exam/",
    "relUrl": "/exam/"
  },"32": {
    "doc": "How to Read a Paper",
    "title": "What is a research paper?",
    "content": "In computer science, original research is typically published at peer-reviewed conferences. Typically these papers have between two and ten authors, and the paper typically reports on about a person-year’s worth of work (though this can vary widely). The authors will be a mix of junior and senior researchers: anyone who contributed something “intellectually significant” to the paper is typically listed as an author. In most CS sub-disciplines (including software engineering, which is the source for most of the readings), author order is indicative: the first author is usually the person who did most of the technical work (e.g., implementing the tool, running the experiments, etc.), and the last author is typically the project leader (often, but not always, the first author’s research advisor). Often, but not always, the first author is a PhD student. To be accepted at a peer-reviewed conference, a research paper must be novel: that is, it must contain some new knowledge or evidence that the research community wasn’t aware of before. This requirement impacts how they are written: a research paper must focus on the specific thing that is novel about it, rather than surveying the field as a whole (though you can find “survey” papers that give an overview of a research area, and if you need to know the current state of a sub-field, looking for a survey paper is the way to go). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/tutorials/reading-papers.html#what-is-a-research-paper",
    "relUrl": "/tutorials/reading-papers.html#what-is-a-research-paper"
  },"33": {
    "doc": "How to Read a Paper",
    "title": "External Resources",
    "content": "I strongly recommend Keshav’s How to Read a Paper if you’re not sure where to start. This short (3-page) article gives a specific strategy for attacking a research paper. I recommend Griswold’s How to Read an Engineering Research Paper. This short article is more aimed at PhD students, but it helps to explain how a research paper is structured (and might be useful to you to help understand the anatomy of a research paper). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/tutorials/reading-papers.html#external-resources",
    "relUrl": "/tutorials/reading-papers.html#external-resources"
  },"34": {
    "doc": "How to Read a Paper",
    "title": "How to Read a Paper",
    "content": "Many of the readings for this course are papers from the research literature. These papers can be intimidating if you haven’t encountered them before. This page contains some suggestions on how to read a research paper, along with links to useful external resources. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/tutorials/reading-papers.html",
    "relUrl": "/tutorials/reading-papers.html"
  },"35": {
    "doc": "Homework 0: Setup",
    "title": "Two Options — Local or Cloud",
    "content": "You must select one of the following two full-credit options for this assignment: . | Option 1: Local: Set up a local Ubuntu 22.04 Virtual machine on your computer. This is the most popular option for most students. It has a nice UI that makes it easy to navigate. | Some students may have WSL Ubuntu set up. Unfortunately, it is a different version of Ubuntu and may not work for this class: we recomend that you follow the instructions below. However, your experience setting it up will help you here! | Some student reports that VirtualBox is not compatible with the new Macbooks (e.g., with M1 and M2 chipsets). If you are using such a Macbook, you may have to select the Option 2 below and use the Cloud instead of your local machine. | Some students may be tempted to install an ARM Ubuntu setup, but unfortunately the x86_64 architecture is required. (If you’re not certain what this means, you can ignore it.) | Some students have experience with docker. Unfortunately, docker will not suffice here (but experience with it will help you): follow the instructions below. | Some students already have other versions of Ubuntu installed. Crushingly, you will almost certainly need the specific version mentioned here: follow the instructions below. | . | Option 2: Cloud: Set up an Amazon EC2 cloud instance with Ubuntu 22.04 running on it. This option will work if you have a slower or older computer. Start early; Amazon takes up to 24 hours to verify cloud computing accounts. This option involves more of a command-line interface but typically runs some course tools a bit faster than local machine. | . Both options should work with all assignments in this course. Option 1 (local VM) will have you install VirtualBox on your computer, download an Ubuntu 22.04 installation image, and install x86_64 Ubuntu 22.04 in your virtual machine. A reasonably modern computer (e.g., at most 5 years old) should be able to run a VM guest without issue. However, some students report that the VM executes too slowly (e.g., the mouse is laggy, keystrokes are missed, programs take too long, etc.). If your VM guest is too slow, you can consider using Option 2 instead (see below). First, you may want to read the summary of virtual machines and cloud computing below. Even if you are familiar with the concepts from previous experiences, this course may use slightly different terminology, and I recommend that you skim the material (click on the box below to see the background material). Background: Virtual Machines and Cloud Computing A Virtual Machine is an emulation of a computer system. Loosely, you can think of a VM as a program that can run an entire virtual computer system. Virtual machines are powerful software systems that enable running software designed for one operating system inside another operating system. For example, you can use your Windows host computer to run a Virtual Machine that contains a Linux operating system. Consider the image below: . This is a Windows 10 host_computer running three different Virtual Machine _guests. The guest instances are complete (virtual) environments that are isolated from the host. All of the guests share the host’s hardware as they execute — each window in the screenshot above lets you interact with a separate emulated guest. Thus, even though the host is a Windows computer, you can use one of the guests to execute Linux software inside the guest. Virtual Machines can be used in many combinations. You can have a Windows, Linux, or Mac host computer, and run arbitary numbers and combinations of Linux and Windows guests. Finally, guests are stored as files in the host computer — this means you can move your VM guest from one host to another by transferring that file around. Option 1 (“Local”): You can choose to set up and run your own Ubuntu 22.04 virtual machine locally. This will allow you complete all of the assignments in this course within that virtual machine. However, some students report that the VM guest runs too slowly (especially if you do not have enough RAM in your computer). If you find that a local VM is too slow, you can use Option 2 instead. Virtual machines are a critical part of Cloud computing. You can “rent out” computing resources from a provider like Amazon EC2 or Microsoft Azure to do whatever computation you might need. Amazon EC2 and Microsoft Azure both offer you virtual machine guests that run on their hardware. Thus, you can get access to a virtual machine running whatever operating system you like to run a variety of software. Option 2 (“Cloud”): If you find that a local VM is too slow, you can instead get a free Ubuntu 22.04 virtual machine from Amazon EC2 (or any other cloud computing provider, but this specification walks you through how to do it on EC2). Amazon EC2 (“Elastic Cloud Compute”) is a service that lets you buy and configure virtual machines. Option 2 has you setup and launch an Ubuntu 22.04 cloud instance (this is free if you are a student). Many of the assignments are easier to complete on Linux or similar command-line systems. If you’re not comfortable with such systems, the background tab below on Linux Fundamentals might be useful: . Background: Linux Fundamentals Vanderbilt professor Kevin Leach has prepared a (long) video that provides a gentle introduction to a number of Linux concepts that are relevant to this course. This video is optional, but you may find it useful if you are less familiar with the Linux environment. There are timestamps in a comment below the video that contain points of interest, such as: . | terminals | environment variables | scripts in the shell | compiling programs from source | using ssh | . The first half is more about terminals and shells (why do we have to type ./a.out? why can’t we just say a.out?), and the second half is more about compiling programs from source. The video also covers elinks in particular, which is a terminal-based browser program (using elinks is not required for this course, but it might be helpful if you choose to use a cloud computer and need to access the web to e.g., submit an assignment). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#two-options--local-or-cloud",
    "relUrl": "/projects/hw0.html#two-options--local-or-cloud"
  },"36": {
    "doc": "Homework 0: Setup",
    "title": "Option 1 — Local Virtual Machine",
    "content": "You can set up your own local virtual machine for free. However, before you proceed, consider checking whether your CPU supports accelerated virtualization. If your CPU does not support virtualization extensions, then your VM may run slowly. If that’s the case, consider Option 2 for this assignment instead. You will need: . | A copy of VirtualBox for your operating system. General download link (look under “Platform Package” or similar). | A copy of 64-bit Ubuntu 22.04 (Download — 64-bit is required here: don’t use 32-bit). This is a large .iso file that might take a long time to download. You don’t need it until part way through the installation process, but you should start the download now. | When something goes wrong during this installation, we recommend that you search this webpage and also look for previous posts on the forum. Some solutions may be listed a little lower on the webpage than when you encounter them. Macs typically give students many more issues than Windows machines, so if you are a student using a Mac, looking to see if the issue is already addressed can be a big time saver. | . VirtualBox . VirtualBox is a Virtual Machine Manager. You install VirtualBox on your host computer (i.e., as a regular program or app). Then, you use VirtualBox to create a virtual machine guest. Once you have created a guest, you install Ubuntu 22.04 inside of the guest. Then, you can start the guest and have a complete Ubuntu 22.04 environment within that guest. Isolation in Virtual Machine Guests Note well: Implicit here is that the guest is, to some extent, isolated from the host. This is very important and entails a number of conceptual hurdles if you are not used to virtualization: . | The clipboard is isolated. That is, if you copy something from your host environment, you cannot paste it inside the guest environment. This is because the VM guest is a completely independent operating system environment from your host. | Typing and mouse movements have to be captured by the guest. | If you want to download a file to use in the guest, you must do so from the guest environment. Unless you set up a shared drive (which is not required), you have to download or create files within the guest environment rather than the host environment. | . Installing VirtualBox . You can install VirtualBox with the default settings. For your reference, screenshots of the course staff completing the installation are shown below: . If you receive a “The installation failed.” message on a Mac, you can resolve the issue by going to Security and Privacy and allowing the installation. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#option-1--local-virtual-machine",
    "relUrl": "/projects/hw0.html#option-1--local-virtual-machine"
  },"37": {
    "doc": "Homework 0: Setup",
    "title": "Creating a Virtual Machine",
    "content": "After installing VirtualBox, it will display the main VM Management console, which we can use to create a New Machine (see circular highlight in upper left): . Next, configure your virtual machine. Select “Type” as “Linux” and “Version” as “Ubuntu 64-bit”. (If you only see options for 32-bit and do not see options for 64-bit, you will not be able to complete this option and will instead have to use the Amazon EC2 Cloud instance option. This happens to some students with older 32-bit Mac machines that cannot emulate 64-bit guests.) You can name your VM whatever you like (though note that the name in the picture is from a different course than this one that uses the same setup). We recommend using at least 2048MB of Memory. See highlights below: . Next, it will ask you to create a storage device. Remember, you are creating a virtual machine — an entire simulated computer. That includes simulating a hard disk for storage. This is represented as a large (&gt; 20GB file) on your host computer. We recommend at least 20GB, and you can choose “dynamically allocated” to save space: . After this step, you will have successfully created a Virtual Machine. Now, you have a bare system with nothing installed on it. Next, we must install an OS on it to run the VM. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#creating-a-virtual-machine",
    "relUrl": "/projects/hw0.html#creating-a-virtual-machine"
  },"38": {
    "doc": "Homework 0: Setup",
    "title": "Installing an OS in the Guest VM",
    "content": "After creating a VM, we need to install Ubuntu 22.04 on it to help run software. Remember downloading a large .iso file as indicated above when we discussed downloading Ubuntu (if you missed it, you should go back and download it now)? This is a Disk Image — we need to attach the OS Disk Image into the VM. On the VM Management window, right click the VM you just created, and click “Settings”: . Next, click on “Storage”, then click on the “Empty IDE Controller” (your version of VirtualBox may call this a CD drive, Optical storage drive, or similar. Regardless, you should be able to select a virtual disk image). Click the Disk icon, then click “Choose disk file…”: . Then, select the Ubuntu .iso file you downloaded earlier. This places the Ubuntu 22.04 installation medium in the VM’s disk drive. Click OK, and you are now ready to start your VM from the Manager (note: the image below is from a previous version of the course that used Ubuntu 16.04 instead of Ubuntu 22.04. When you do this, your .iso file must be for Ubuntu 22.04.): . If you receive a “Kernel driver not installed” error, follow these instructions online for how to resolve the issue. (The image below shows the “Kernel driver not installed” error, for your reference.) . The Virtual Machine will now boot and load the Ubuntu 22.04 installation. The VM opens in a new window — you can think of this window as the virtual “screen” that lets you see what’s happening in the emulated system. You can follow through the normal Ubuntu 22.04 installation: . Note: If the VM asks you to select a startup disk, you need only select your .iso file. You want the VM to boot from the installation media so you can install Ubuntu within the guest. We recommend opting to install updates and third-party software. It should not affect the system one way or another: . You can select “Erase disk and install Ubuntu”. This is only referring to erasing the “virtual” disk you created earlier with the VM. If you are receiving an error like the “following disc images couldn’t be opened for the reason of no mountable file systems”, you may be able to resolve the issue by following recommendations online . Note: Sometimes during installation, students find that a window is too large to display all the buttons. You can actually move the window like normal to reveal the Continue button (just click to drag the window like any other — the window inside the Virtual Machine, not the Virtual Machine itself): . Next, it will ask you to create an account for logging in. You can put whatever credentials you like here — it will not have any bearing on your host computer. This is merely for an account on the guest VM. Just make sure you don’t forget whatever password you choose! . Next, you just wait a bit for the OS to install inside the guest. It might take a few minutes to complete. Eventually, you’ll see a screen asking you to remove installaton media and restart. You can just click restart (on the guest) and you’ll be all set! . Virtual Machines and Mice While you’re running the VM, you may find that it “takes control” of your mouse and keyboard, and you aren’t able to leave the window. If this happens, press CTRL+ALT to release control from the VM window. (The keystrokes may be different on Mac OS). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#installing-an-os-in-the-guest-vm",
    "relUrl": "/projects/hw0.html#installing-an-os-in-the-guest-vm"
  },"39": {
    "doc": "Homework 0: Setup",
    "title": "Install VirtualBox Additions",
    "content": "One thing you’ll notice when you install your VM successfully is that the window is small. In our opinion, one thing that makes the experience way better is the VirtualBox Additions package. It provides a number of “Quality of Life” features when using VMs. It’s essentially a helper program you install inside the VM guest that makes it “aware” that it’s running inside of a VM. To install, click “Devices”, then “Insert Guest Additions CD Image…” . Eventually, a window pops up asking if you want to run the media. Just click Run. After installing, you can reboot the VM image. One more step to make sure gcc (a compiler for C and C++ programs) is installed in your guest. In a terminal, use: . sudo apt-get update sudo apt-get install gcc . You’re all set! You can proceed to submitting the assignment (see below, after option 2)! . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#install-virtualbox-additions",
    "relUrl": "/projects/hw0.html#install-virtualbox-additions"
  },"40": {
    "doc": "Homework 0: Setup",
    "title": "Option 2 — Amazon EC2",
    "content": "Note well: This option will take longer than Option 1. Amazon AWS accounts can take up to 24 hours to verify, which means you may have to wait before you can submit the assignment. Start early! . You will need a Secure Shell (SSH) client. SSH allows you to remotely interact with a server. (If you’ve never used SSH before, scrolling back up the page and watching the appropriate section of the “Linux Fundamentals” video might help.) When you SSH to a remote computer, you have access to a command prompt that runs software on that computer. We will be using SSH to interact with a virtual machine we create in the cloud with Amazon EC2. On Windows, I recommend using WSL to run SSH. You can also use PuTTY. On Mac, you should already have ssh installed. Open a terminal and you can run ssh. On Linux, you can use ssh, but you may need to install it first (e.g., sudo apt-get install openssh or similar, depending on your platform). It is your responsibility to understand how to use SSH, though we give some pointers below. Amazon EC2 is a cloud computing service that allows you to rent virtual machines that you can ssh to and run programs like any other computer. Amazon offers a large number of cloud-based services all under the umbrella of AWS (Amazon Web Services). EC2 is a subset of AWS. In this section, you will create an AWS account to manage EC2 virtual machines. You can sign up for a new account on Amazon EC2, and in doing so, you get 12 months of free access to a virtual machine that is enough to complete the assignments in this course. If you do not already have an Amazon EC2 account, navigate to https://aws.amazon.com/ec2/ and click “Create new account” in the upper right. Complete the sign up process. You may be prompted for credit card information, however you should not be charged as long as you create only one virtual machine on the free tier. You then will have access to the Amazon AWS Console. If you are prompted, you want to sign in as a “Root” user for the AWS console. AWS Account Creation Note that it can take 24 hours for Amazon to verify your account. We believe this is because they manually review account creation — after all, they are giving you access to computing resources. Since cloud services are easily abused (e.g., for spam emails, command and control virus management, and distributed denial of service attacks), Amazon applies a bit of scrutiny to AWS users. Start early! . Notice: AWS Web GUI Changes Some of the screenshots in this guide are from older versions of the AWS Web Interface. The GUI changes fairly frequently and so your view may look a little different from the screenshots. Everything is fine and it’s good practice to follow along with documentation that is not an exact match. The course staff verified that the instructions work and pass the HW0 autograder most recently on 8/27/2022. If you believe you’ve discovered a problematic difference between this guide and the current version of the AWS GUI, contact your TA. Creating a New VM . Now that you have created an account, you can use the AWS Console to help manage and launch virtual machine instances. We will walk you through the steps to create an Ubuntu 22.04 VM below. (1) Open the AWS Console . After you create an AWS account, you can visit the AWS Console at https://console.aws.amazon.com. At the console, you should be greeted with a large screen full of many services. See highlight on left: . Click here to see AWS Console screenshot . (2) Open the EC2 Manager . From the AWS Console, click the “EC2” link to open the Elastic Cloud Compute manager. The EC2 Manager lets you manage and launch Instances, which are virtual machines that you configure. The first thing we need to do is configure and launch a new instance. Click the Launch Instance button. Click here to see EC2 Manager screenshot . (3) Choose an Ubuntu 22.04 LTS Instance . This is the most important step. You must select an Ubuntu Server 22.04 LTS (HVM), SSD Volume Type instance. This is a free tier eligible instance that contains an environment suitable for completing the rest of the assignments. Don’t pick other versions of Ubuntu (NOT 18.04 or 20.04, etc.). The autograder uses Ubuntu 22.04 (in an AWS VM!), so if you want the smoothest experience, use that version. As of 1/12/2023, the correct image is the default for Ubuntu: . Click here to see screenshot of the instructor selecting the correct VM image . After that you can fill out the rest of the selection (e.g., making certain to select your key pair for that instance) and then verify that it is in the Free Tier. Click here for \"free tier\" screenshot . (4) Configure Your Instance . After you select the image to launch, it may ask you a few questions about storage (pick the default if so). Usually, it will skip ahead and ask you about instance details. You want to pick the free version, called a t2.micro instance. If you were using cloud computing for a business or another project, you could configure resources like (a) how many CPUs, (b) how much RAM, and (c) what type of storage you get on the VM. For this course, just pick “t2.micro” to get the free level. Click here for instance type selection screenshot . (5) Configure Authentication . After you set up your instance, you need to create a way to login. This is a tricky security problem because Amazon wants to give you root (Administrator) access to your new instance. The way they do this is by using asymmetric key encryption. Basically, Amazon will let you download a file that serves as your credentials. Rather than entering a password, you will provide this special file to let you login. If you’d like to learn more about asymmetric key encryption, take a security course. Now, you will be prompted to set up credentials for logging in. Select Create a new key pair and type in any name (the examples use “eecs481” in the screenshots below). (If you are given a key type option, like “RSA” vs. “ED22519”, pick “RSA”.) Then, click Download Key Pair. It is imperative that you keep this file in a secure location. Do not upload it to GitHub, do not move it around. This is basically like a password for accessing your instance — you wouldn’t want someone malicious to access your instance and do something bad with it (you would be legally responsible for whatever they did!). Click here for keypair creation screenshot . Once you had downloaded your Key Pair, you should be able to Launch your instance. Do so and continue. There is a screenshot below showing what you should see after launching your instance. Click here for launch confirmation screenshot . (6) Connect to Your Instance . At this point, you have set up an Ubuntu 22.04 instance on EC2 and created associated credentials. You now have a virtual machine running in the cloud that you can connect to. You will use ssh to connect to your instance. This is the recommended way — you could technically install a front-end and use remote desktop software, however we strongly recommend using the command line, since you will be using the CLI in many of the course assignments. From the EC2 Management Dashboard, right-click your running instance. You should see a menu pop up like below: . Click “Connect”. It will pop up a window giving you a number of options. Pick the “SSH Client” tab to see how to connect via ssh: . On this window, you will see the hostname of your EC2 instance to which you can ssh, as well as a number of instructions for connecting. Mac permissions errors Some students, especially those using Mac computers, report receiving permission errors when they try to SSH into their EC2 instances: . In this case, a command like . chmod go-rwx /path/to/eecs481.pem . usually resolves the issue. More information is available online about this SSH issue. Using Windows WSL to SSH to EC2 If you are using Windows Subsystem for Linux (WSL) to connect to your Amazon EC2 instance, you must prepare your key file before connecting. Our recommendation is to run the following (but use your path): . mkdir -p ~/.ssh/ cp /path/to/your/downloaded/eecs481.pem ~/.ssh chmod 400 ~/.ssh/eecs481.pem . Windows WSL does not apply Linux file permissions correctly unless you are dealing with files contained within the Linux FS. Moving your key to ~/.ssh/ will allow you to chmod 400 appropriately. The SSH client will not allow you to connect to any server using that key if it does not have the correct permissions. Recall you downloaded a .pem file when you set up authentication for your instance (see part 5 above). You must specify this file on your SSH client to connect to your instance. First, you must provide the correct access permissions to the .pem file. Usually, this means running chmod 400 /path/to/your/.pem. Once you do so, you can use the ssh command directly: . ssh -i /path/to/your/.pem ubuntu@&lt;your-EC2-hostname-here&gt; . (You must substitute in the path to your downloaded .pem file as well as the hostname of your EC2 instance, which takes the form of ec2-X-Y-Z.us.W.compute.amazonaws.com for some values of W, X, Y, and Z. Collect these values from the EC2 Console.) . If you receive an error that the path is “too long for Unix domain socket” or the like, open ~/.ssh/config in a text editor and modify the control path to match this (reference): . Host * ControlPath ~/.ssh/control/%C ControlMaster auto . At this point, you should be logged in to your EC2 Instance! See below for an example of connecting to such an instance from the WSL environment (though note that the machine in the screenshot uses an old version of Ubuntu. Your instance should be version 22.04 (codename: jammy) instead of version 16.04): . Once you’re all finished, you need one more step to install gcc (a compiler for C and C++ programs): . sudo apt-get update sudo apt-get install gcc . Then, you can proceed to Submitting the assignment below! . You can safely stop the VM instance when you aren’t using it (e.g., between homeworks) and restart it when you are. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#option-2--amazon-ec2",
    "relUrl": "/projects/hw0.html#option-2--amazon-ec2"
  },"41": {
    "doc": "Homework 0: Setup",
    "title": "Submitting HW0",
    "content": "Note well: after submitting this assignment, you are welcome to use whatever environment you like for this course instead, but you may run into issues this semester with compiling or running some software. Debugging systems integration issues is good practice (and indeed, an intentional part of this courses assignments). Unfortunately, we cannot support every combination of student hardware and software. Thus, the officially supported environment in Ubuntu 22.04. Complete the assignment through Gradescope (accessed via the bar at the top of this webpage).For HW0, you are asked to submit a single file named output.txt. Obtain your output.txt file by running the following commands in your virtual machine guest: . cd ~ wget https://web.eecs.umich.edu/~weimerw/481/hw0/hw0sample chmod u+x hw0sample ./hw0sample . If you receive an error such as “failed: Temporary failure in name resolution. wget: unable to resolve host address ‘web.eecs.umich.edu’” on your VM, make sure your guest is connected to the Internet by switching it to bridged mode. After invoking ./hw0sample, you will find a file output.txt in your home directory. Upload that file to the autograder and you’re done! . What do these commands do? The file hw0sample is a program that detects which version of Ubuntu you are running and which version of gcc you have installed. If you followed either of Option 1 or Option 2, you should have an identical environment with Ubuntu 22.04 installed and gcc 11.4.0 installed. Thus, the output.txt will (mostly) only been correct if invoked on the environment expected by the autograder for the subsequent assignments. If you get full credit for HW0, then you at least have some confidence that you can eventually get the rest of the assignments working as well! . Note well: If you run hw0sample on another environment besides the Ubuntu 22.04 environment described in this spec, then no guarantees are made about the correctness of the file (or whether you can run the program at all). Only run this in your VM. How do I get output.txt out of the VM? Note that since you’re working inside a VM, you’ll occasionally need to move files to and from your VM guest and host. In this case, you have downloaded a program (hw0sample) using the wget utility. This makes a file in your VM guest environment. When you run that program, it creates a new output.txt file in the VM environment as well. But how do you get that file to the autograder? . If you used Option 1 and installed the Guest Additions, you can drag and drop files to and from the VM. Just open up the file manager inside your VM, then drag the output.txt file to a directory on your host. Then you can upload from there. If you aren’t quite certain about how to drag and drop once Guest Additions is installed see this video for more information. In addition, with option 1, you can also open Firefox inside of the guest VM and open Gradescope from there! You may find this easier when working on the other assignments: just keep the autograder open in your guest, and upload from there. If you used Option 2, you can use the scp (Secure Copy) utility to copy files from your EC2 instance. On your host computer in a terminal, you download a file from your EC2 instance to your host computer: . scp -i /path/to/your/.pem ubuntu@&gt;your_EC2_hostname&lt;:/path/to/some/remote/file.txt /path/to/where/you/want/to/download/it/target.txt . The command above copies some file.txt to target.txt. On your host computer in a terminal, you can upload a file to your EC2 instance from your host computer: . scp -i /path/to/your/.pem /path/to/local/file/to/upload.txt ubuntu@&gt;your_EC2_hostname&lt;:/path/to/some/remote/target.txt . The command above will upload upload.txt from your local computer to target.txt on the EC2 instance. For some later homeworks, the -r option for scp may be helpful: it recursively transfers entire directories. How do I transfer many files at once with scp Quick answer: scp -r (but keep the -i key.pem) . Long answer: If you’re not familiar with utilities like these, we definitely encourage you to watch the video above and practice Googling usage patterns for and hints for less-familiar tools. There will be multiple instances later in the course where similar questions come up and you will definitely be in a better position to help yourself if you cultivate a habit of looking in multiple sources for such information. Good luck! . Penalty for cheating on HW0 It would be easy to copy someone else’s output.txt file and submit it as your own. Don’t do this: it is cheating. If you later have any problems and you come to office hours without a working Ubuntu 22.04 environment (and you got full credit on HW0), we will know that you cheated on HW0 and you will automatically fail the course. Trust us on this: it is easy for us to tell. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#submitting-hw0",
    "relUrl": "/projects/hw0.html#submitting-hw0"
  },"42": {
    "doc": "Homework 0: Setup",
    "title": "Final Remarks",
    "content": "There is a fair bit of systems programming in this course. We will use a mixture of command line tools, multiple languages, and other large projects that you may not have seen, written, or used before. That’s the point. In software engineering, much of your day-to-day work will involve reading code and documentation, as well as getting things set up to run. We are big believers that this type of experience is some of the most valuable you can acquire as a student — it makes you more productive at other tasks. This assignment is not meant to take more than 2 hours (excluding the time taken to download the Ubuntu 22.04 .iso in Option 1, or the Amazon AWS signup time in Option 2). Please use this assignment as a gauge for your technical preparedness in this course. A big component of the assignments is “read the docs, figure out how to invoke the tools.” We acknowledge this is not for everyone — indeed, one purpose of having this assignment due so early is to help you decide whether you like this style of assignment. Please contact us on Discord if you have any questions! . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html#final-remarks",
    "relUrl": "/projects/hw0.html#final-remarks"
  },"43": {
    "doc": "Homework 0: Setup",
    "title": "Homework 0: Setup",
    "content": "CS 684 is a software engineering course. There a focus on reading code and using large systems to accomplish tasks, because real systems are large—too large for you to hold their entire specification or codebase in your head, almost certainly. In this course, you will be expected to develop and maintain programs and scripts in multiple languages using multiple tools. As a result, I want to help you prepare a suitable development environment for the assignments in this course. Creating a Virtual Machine may be useful for the assignments in this class. HW0 will guide you in doing just that. This assignment will help you create a development environment that matches the autograder environment. If you are not familiar with Linux command line tools, this assignment is a great place to start. The assignments in this course have been designed around an x86_64 Ubuntu 22.04 LTS environment. All of the assignments are known to work in this environment. Officially, you have to use this environment. (If you do not then you will likely run into issues that are not covered in the homework specifications. That is, later commands will not work for you and you will be unable to complete the homeworks.) Different versions of tools and libraries are installed by default in different versions of Linux. As a result, if you deviate from the suggested x86_64 Ubuntu 22.04 environment, you may encounter corner cases that cause test cases to fail on the autograder. In some cases, the staff may direct you to set up an Ubuntu 22.04 Virtual Machine if you have not done so and are stuck on some assignments. Ultimately, it is your responsibility to read documentation and install supported tools. This HW0 spec is meant to help you walk through the creation of an x86_64 Ubuntu 22.04 environment. ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw0.html",
    "relUrl": "/projects/hw0.html"
  },"44": {
    "doc": "Homework 1: Coverage Warmup",
    "title": "Homework 1: Coverage Warmup",
    "content": "In this assignment (and in HW2), you will create a high-coverage test suite. The main difference between this homework and HW2 is the complexity of the program you have to test: in this assignment, the program is relatively simple and you can probably read the whole thing fairly quickly. In HW2, the program is large enough that you probably can’t read the whole thing, even if you spend the whole week on it. In that way, HW2 is much more realistic. You will then be asked to write a short report reflecting on the activity. There is no particular assumption that you are familiar with any of the subject programs in this assignment or any other assignment in this class. Indeed, that is the point: you will be applying testing concepts to unknown software. You may work with a partner for this assignment. Only one partner needs to submit for any of the programming assignments on the autograder, but you do need to use Gradescope’s interface to select your partner. (Here is a video showing Gradescope partner selection.). Only one of you needs to submit the written report on Canvas, but similarly you need to create a project group on Canvas in order to submit as a group. You may use files, benchmarks or resources from the Internet (unlike in many other classes), provided you cite them in your written report. (If you use the same resource many times, such as StackOverflow, one citation per resource suffices.) . Assignment Flavor and Learning Goals A recurring theme in this course is a focus on everything except writing code. Perhaps surprisingly, other elements, such as reading code, testing code, eliciting requirements, debugging code, and planning projects, are usually more important in industry than simply writing software. Your other electives cover programming — this one covers software engineering. Many assignments in this class are often more like “open ended puzzles”. You won’t be writing much code. Instead, you will be reading and using code written by other people. (Yes, that’s annoying — that’s the point!) . Among other things, we hope this assignment and HW2, together, will give students exposure to: statement (or line) coverage, branch coverage, legacy code bases, white-box testing, black-box testing, writing your own tests from scratch, slightly editing existing tests to improve coverage, thinking about high-coverage inputs from first principles, and using other available resources. These assignments may be different from what you are used to. HW1 focuses on white-box testing and looking at the code. In HW2, there is too much code for you to read it all, so you will have to think of other black-box approaches. Subject Program . The HW1 subject program is a simple python implementation of an abstract data type: the AVL Tree container data structure. Test cases for this program take the form of sequences of instructions for manipulating a single global AVL tree: . | i${number} — insert number into the tree | d${number} — delete number from the tree | p — print the current tree | . For example, if the text file test1.avl contains i1 i2 i3 i4 i5 d4 p, then python avl.py test1.avl produces the output: . 2. / \\ 1 5 /\\ /\\ 3 /\\ . We compute coverage for this program using the coverage package for Python. Both statement and branch coverage are considered. (For more information about statement and branch coverage, read here - we’ve briefly covered these in class, but we’ll do into more detail next week.) . The reference avl.py implementation is available here. The program is about 300 lines long and is a self-contained single file. A test suite for this application is a collection of .avl files. The reference starter test suite is available here. Python Build, Installation and Coverage Details . Installing coverage may look like this on your Ubuntu setup: . $ echo I am typing this in the VirtualBox or Cloud Computing setup from HW0 $ sudo apt-get install python-pip python-dev build-essential $ sudo pip install --upgrade pip $ sudo pip install --upgrade virtualenv $ sudo pip install coverage . (If sudo pip install coverage fails for you, the advice here may help. Some students report that wget https://bootstrap.pypa.io/pip/2.7/get-pip.py ; sudo python get-pip.py works for them for the --upgrade pip issue.) . Note that apt-get is Debian/Ubuntu-specific. If you have another Linux distribution you may need to use something else (yum on Red Hat, etc.). If you’re using a Mac, you’ll need something else entirely. While this homework assignment isn’t too hard to do on a Mac, students have reported that HW2 is somewhere between “unbelievably frustrating” and “impossible” to do on a Mac, so you might consider setting up a virtual machine now. After that, you can use the coverage utility on multiple test cases and view combined coverage results: . $ coverage run --append avl.py simple1.avl 1 /\\ 2 /\\ $ coverage report Name Stmts Miss Cover ---------------------------- avl.py 182 99 46% $ coverage run --append avl.py simple2.avl 2. / \\ 1 5 /\\ /\\ 3 /\\ $ coverage report Name Stmts Miss Cover ---------------------------- avl.py 182 54 70% $ coverage erase . (If you see no file to run: 'avl.py', go back and make sure you download the avl.py file from this webpage above and put it in the directory you are working in.) . Note how the measured coverage of only the first test is low (46%) but the combined coverage result for the two tests is higher. The --append option is necessary to avoid overwriting the stored coverage data with each new test run. Now we consider branch coverage. Simply add --branch: . $ coverage run --append --branch avl.py simple1.avl $ coverage run --append --branch avl.py simple2.avl $ coverage report Name Stmts Miss Branch BrPart Cover ------------------------------------------ avl.py 182 54 90 19 66% $ coverage report -m Name Stmts Miss Branch BrPart Cover Missing ---------------------------------------------------- avl.py 182 54 90 19 66% 82-85, 88, 101, 109-112, 121, 123-127, 139-141, 145, 189, 201-202, 211, 216, 223-238, 244-248, 253-254, 284, 286-292, 304-306, 81-&gt;82, 87-&gt;88, 100-&gt;101, 107-&gt;109, 120-&gt;121, 122-&gt;123, 138-&gt;139, 144-&gt;145, 171-&gt;exit, 210-&gt;211, 212-&gt;214, 215-&gt;216, 243-&gt;244, 250-&gt;253, 283-&gt;284, 285-&gt;286, 301-&gt;303, 303-&gt;304, 319-&gt;312 $ coverage erase . The additional columns give branch-specification information (e.g., about partial branches; see the manual), but the final column now gives the branch coverage. The columns may look different on other setups — that’s fine. Note also how the missing column guides you to line numbers that are not exercised by the current suite. There is external written documentation available for this utility. Finally, note that this utility can also produce XML and HTML reports, which you may find easier to interpret. Recommended Approach . Any test input you create is fine: the goal is to get coverage, not to have good or pretty trees. (Yes, really any random input is fine.) . You will almost certainly need to inspect the source code of the program (i.e., white-box testing) to construct a high-coverage test suite. We recommend that you start with the test cases we have provided. Because of limits on autograding submissions, and so that you learn how coverage computations work across various systems (a relevant skill for interviews, etc.), you will almost certainly want to install the coverage utilities yourself. As you read the project’s source code and expand your test suite, recompute the coverage locally. When you perceive that it has gone up significantly, submit to the grading server for a more official check. Submission: test cases . Submit your (individual, not zipped) test cases via Gradescope to the “HW1” assignment. The autograder will report a score between 0 and 10. You may submit multiple times, but no more than 5 times in any 24-hour period. The exact grading rubric (e.g., x points for y coverage) is: statement coverage 50% (one point) to 94% (five points); branch coverage 50% (one point) to 92% (five points). Note that your local results may differ largely from the autograder results and that is fine and expected. For example, you may observe 6.8% line coverage “at home” and 16.8% on the autograder. (Different compilers, header files, optimizations, etc., may result in different branch and line counts.) Your grade is based on the autograder results, regardless of what you see locally. We always use your best autograder submission result (even if your latest result is worse) for your grade. Note also that the grading server has resource usage (e.g., CPU time) caps. As a result, if you submit a test suite that is very large or long-running, we may not be able to evaluate your submission. Consider both quantity and quality. Submission: written report . You must also write a short two-paragraph report reflecting on your experiences creating a high-coverage test suite for this assigment. (If you are working with a partner, indicate as much in the text or header. Recall from above that you need only submit one copy of the report, but if both you do, nothing bad happens. Select your partner on Canvas.) Consider addressing points such as: . | How did you go about manually creating or otherwise obtaining test cases? | Did you use or modify any of the tests we provided or tests from the Internet as part of your answer? (Reminder: You are allowed to do that in this class!) | What was harder than you expected or different than you expected? | (If you used any external resources, such as image files from the Internet or help from Stack Overflow, list it in an optional third paragraph. There is no particular format – a list of URLs is fine. If you used the same general source multiple times, just cite it once.) | . I am worried about the my report being too long or too short! Many students report stress or uncertainty about the length limit. The safest answer is to go with the restriction as written. The graders are free to dock points if your answer is too long. In practice, there are a bunch of ways to cheese the system (e.g., we don’t give a word count). I would expect three short paragraphs to be about the same as two longer paragraphs. The real challenge here is that we are asking you to be concise. In a real software engineering job, your manager will typically not read overly-long reports. So the rule isn’t strict, but it’s judged by humans. Students are often unhappy when their expectations are unmet. Basically the only failure case here is “you think writing longer is OK” + “the graders decide to be firm about it” so you lose points. So you can write something longer, but you don’t have any recourse if the subjective judgment says that yours is too long. If you don’t feel comfortable with that gamble (e.g., for students who may not be native English speakers, or may not be confident in their prose), cleave to both the spirit and the letter of the law. Rubric: . | 5 points — a two-paragraph report reflecting on your activities creating a high-coverage test suite for this assignment, including comparisons and contrasts between your experiences and expectations (with a third paragraph listing any external sources or files used) | 4 points — a reasonable report, but lacking a solid description of one or more aspects or significantly exceeding the length limit | 3 points — a brief report, detailing only half of the required information | 2 points — a report drawing only the bare minimum of contrasts and comparisons (e.g., between two aspects and no more) | 1 point — a terse or uninformative report, perhaps describing only one activity or subject | -1 point — English prose or grammatical errors | -1 point — Text does not include University email address(es) and/or does not make it clear whether you are working alone or with a partner | -all points — Submission uses uncited external resources | . There is no explicit format (e.g., for headings or citations) required. You may discuss other activities (e.g., validation or automation scripts you wrote, etc.) as well. The grading staff may select a small number of excerpts from particularly high-quality or instructive reports and share them with the class. If your report is selected you will receive extra credit. Submit your report to the “HW1” assignment on Canvas. Commentary . This assignment is somewhat open-ended. There is no “one true path” to manually creating high-coverage test suites. You may find yourself thinking something like “I know what to do at a high level, but I don’t know specifically what to create here. I could try to read and understand the program to make tests that cause it to do different things, but reading and understanding the program takes a long time, especially since I didn’t write this code and I don’t really care about it and I’m only doing it because someone is telling me to.” Such concerns are, in some sense, the point: they are indicative of industrial software engineering. Finally, students sometimes wonder if it is possible to get 100% coverage on this assignment. While it should be possible to get 100% coverage for the general AVL tree algorithm, this particular implementation of the algorithm may well have branches that you are unable to reach — especially given this testing setup. FAQ and Troubleshooting . In this section we detail previous student issues and resolutions: . | Question: When I type the command sudo apt-get install python-pip python-dev build-essential I am prompted for a password — which should I use? Answer: The password should be the one associated with your user account (the one you used to log in to the OS). If you are using a virtual machine, it is the virtual machine login password, not your “real” login password. | Question: I’m getting “Can’t add branch measurements to existing line data”. Answer: Run coverage erase when switching between statement coverage and branch coverage. | Question: Can you post guidelines or points of interest for writing high-quality or instructive reports? Answer: I regret — I cannot. At least, not in the way one is likely to desire when posing such a query. You can potentially reverse engineer things a bit, but ultimately there’s no magic formula. The grading staff may well select a small number excerpts that are worth sharing with the class. You can infer from that that we’ll be favoring excerpts that are “family friendly” and that contribute to pedagogical goals: either by bringing something new to light, or by reinforcing or reinterpreting concepts from class. Given my views on liberal arts education, however, this could potentially be anything from a strong link between, say, testing and rhetoric, to some direct point about software maintenance. Usually these sorts of things end up being awarded to students who have clearly spent a bit more time than usual on the assignment. (If you are being very mercenary, it’s probably not worth shooting for an ill-defined unsure thing.) . | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw1.html",
    "relUrl": "/projects/hw1.html"
  },"45": {
    "doc": "Homework 10: Formal Methods with Z3",
    "title": "Homework 10: Formal Methods with Z3",
    "content": "High level goals . The high-level goal of this assignment is to learn about automated theorem provers (Z3 in particular), and how they can be used to model programs, prove program properties, and generate test cases. You may work with a partner for this assignment. If you do you must use the same partner for all sub-components of this assignment. Setup . Download and unzip the hw10-z3.zip archive. Open the Z3 web interface (or this or this) in your browser. (Alternatively, download the latest Z3 release and run the examples from the command line.) . Check out the Z3 Tutorial if you want more background. However, you should be able to do most of this exercise with targeted queries as opposed to reading the entirety of it. Instructions . The hw10-z3.zip archive contains four folders (three pairs and one set of programs). Each pair contains the original program, a mutated program, and z3 starter code for comparing the two. The set contains the original program, a set of four mutants, and z3 starter code. Follow these steps: . | Examine the original and mutated program in the pair1 directory. Are they equivalent? (See question 1, below.) | Complete Z3startercode.pair1.smt2 (see hints below!). Your completed code should either prove equivalence of the two programs or generate a model (i.e., a test case) that proves non-equivalence. | Test your code by running it with Z3. Run the .smt2 file with Z3. You can copy the entire contents of the file into the web interface and run it there. | ** Repeat steps 2 and 3 for the pair2 and pair3 directories.** Note that we are using width-8 BitVecs instead of the normal width-32 BitVec. This is for ease of reading/writing/reasoning: the principals we care about are the same, but are a little easier to grok at this lower precision. Also, recall the BitVec operators, such as bvadd and bvsgt, that replace Int operators, such as + and &gt;; if you need more information about the available BitVec operators, you can consult the documentation. | Familiarize yourself with Z3 scopes. | Examine the four mutants in the set1 directory. | Use scopes to complete Z3startercode.set1.smt2. Your completed code should, for each mutant, either prove equivalence or generates a model (test case) that proves non-equivalence. By using scopes you can leverage the fact that much of the execution is identical between the original program and the mutant programs. (See Question 2 and 3) | Test your code by running it with Z3. | . Hints . When modifying the .smt2 templates, only modify what is between the following two lines. Do not alter anything that is not between the following two lines, including the lines themselves! . ;;;;;;;;;;;;;;;;; START STUDENT CODE ;;;;;;;;;;;;;;; . and . ;;;;;;;;;;;;;;;;; END STUDENT CODE ;;;;;;;;;;;;;;; . These anchor lines are used for grading. Submission: Written Report . Answer the following questions: . | Which of the mutants in pair1, pair2, and pair3 are equivalent? Provide, for each non-equivalent mutant, a test case that detects it. The test case should be the output of the (get-model) instruction in your smt2 code. [5 points, -2 per incorrect answer and -1 per missing or incorrect test case, to a minimum of 0] | Which of the four mutants in set1 are equivalent? Provide, for each non-equivalent mutant, a test case that detects it. [3 points, -1 per incorrect answer or missing test case to a minimum of zero] | Briefly explain how scopes work in Z3 and when they are useful? [1 point for explanation, 1 point for when they are useful] | . Submit a plain-text file or PDF with your answers to the above questions to the HW10 assignment on Canvas. Include in that file: . | the name and UCID of your partner, if applicable | your final versions of the four Z3startercode.&lt;xyz&gt;.smt2 templates. | citations for any outside sources that you used | . FAQ . Coming soon! . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw10.html",
    "relUrl": "/projects/hw10.html"
  },"46": {
    "doc": "Homework 2: Coverage",
    "title": "Homework 2: Coverage",
    "content": "Two of the key properties found in industrial software engineering, but not in most academic coursework, are: the program is large and you did not write the program. If you are hired by Microsoft as a software engineer, they will not ask you to write Office from scratch. Instead, as discussed in class, the vast majority of software engineering is the comprehension and maintenance of large legacy codebases (i.e., old code you did not write). Thus, there is no particular assumption that you are familiar with the subject program in this assignment. Indeed, that is the point: you will be applying testing concepts to unknown software. In this assignment, we’re taking this to the next level (relative to HW1): the subject program is a real, actual program that people use to accomplish actual work. In this assignment, you will create a high-coverage test suite for a real open-source program: libpng, a library for manipulating image files. You will then be asked to write a short report reflecting on the activity. You may work with a partner for this assignment. Only one partner needs to submit for any of the programming assignments on the autograder, but you do need to use Gradescope’s interface to select your partner. (Here is a video showing Gradescope partner selection.). Only one of you needs to submit the written report on Canvas, but similarly you need to create a project group on Canvas in order to submit as a group. You may use files, benchmarks or resources from the Internet (unlike in many other classes), provided you cite them in your written report. (If you use the same resource many times, such as StackOverflow, one citation per resource suffices.) . Assignment Flavor and Learning Goals A recurring theme in this course is a focus on everything except writing code. Perhaps surprisingly, other elements, such as reading code, testing code, eliciting requirements, debugging code, and planning projects, are usually more important in industry than simply writing software. Your other electives cover programming — this one covers software engineering. Many assignments in this class are often more like “open ended puzzles”. You won’t be writing much code. Instead, you will be reading and using code written by other people. (Yes, that’s annoying — that’s the point!) . Among other things, we hope this assignment and HW1, together, will give students exposure to: statement (or line) coverage, branch coverage, legacy code bases, white-box testing, black-box testing, writing your own tests from scratch, slightly editing existing tests to improve coverage, thinking about high-coverage inputs from first principles, and using other available resources. These assignments may be different from what you are used to. HW1 focused on white-box testing and looking at the code. In this homework, there is too much code for you to read it all, so you will have to think of other black-box approaches. Installing, Compiling and Running Legacy Code It is your responsibility to download, compile, and run the subject programs in this assignment (and the other assignments in this course). Getting the code to work is part of the assignment. You can post on the forum for help and compare notes bemoaning various architectures (e.g., windows vs. mac vs. linux, etc.). Ultimately, however, it is your responsibility to read the documentation for these programs and utilities and use some elbow grease to make them work. If you are having trouble (e.g., windows is often a bit more complicated than linux for these things), post on the forum. Other students should be able to offer help and advice. For example, one TA reports that gcc may not easily support static linking on a Mac, but that it took fewer than two minutes to set everything up in Ubuntu. Subject Program: PNG Graphics (C) . The HW2 subject program is the portable network graphics file format reference library, libpng. It is used for image manipulation and conversion. We will be using the developer-provided pngtest driver. It takes as input a single .png file. We compute coverage for this program using the gcov test coverage program for gcc. Only statement coverage is considered. The reference implementation (version 1.6.40) is available here. It contains about 85,000 lines of code spread over about 70 files. The SHA-256 checksum is 8f720b363aa08683c9bf2a563236f45313af2c55d542b5481ae17dd8d183bb42. A test suite for this application is a collection of .png files. The reference implementation comes with over 150 such example files. (You really can use any images that came with libpng, plus any images from anywhere else, as part of your submitted answer, see below.) Feel free to use an image manipulation or conversion program to create your own files or to use files or benchmarks you find on the Internet or to use the files that come with the program. The difficulty difference between HW1 and HW2 is large. (For example, students may report that HW1 takes “minutes” while HW2 takes “hours”. In addition, many students find that the difficulty lies more in compilation and instrumentation than in high-coverage images.) . C Build, Installation and Coverage Details . The gcov utility usually comes with gcc, so you should not need to do anything specific to install it. (Unless you are trying to use a Mac natively despite our warnings not to do so. In such a world you will likely encounter the issue that gcc static linking may not work on a Mac and that using dynamic linking will give you 0% coverage. You should then install linux in a VM.) However, our subject program depends on the development version of a compression library: . $ sudo apt-get install libz-dev . In addition, you will have to compile the project with coverage instrumentation (taking care to use static linking or to otherwise make all of the libpng source files, and not just the test harness, visible to coverage): . $ echo I am typing this in the VirtualBox or Cloud Computing setup from HW0 $ cd libpng-1.6.40 $ sh ./configure CFLAGS=\"--coverage -static\" $ make clean ; make $ ./pngtest pngtest.png Testing libpng version 1.6.40 ... $ gcov *.c ... File 'png.c' Lines executed:37.78% of 1236 # your numbers may differ! Creating 'png.c.gcov' File 'pngerror.c' Lines executed:16.67% of 252 # your numbers may differ! Creating 'pngerror.c.gcov' ... Lines executed:28.71% of 10606 # your numbers may differ! $ ./pngtest contrib/gregbook/toucan.png ... $ gcov *.c ... File 'pngwutil.c' Lines executed:61.90% of 979 # your numbers may differ! Creating 'pngwutil.c.gcov' Lines executed:30.72% of 10606 # your numbers may differ # and everything is still fine! $ rm *.gcda pngout.png . (If you get an error like “bash: cd: libpng-1.6.40: No such file or directory”, be sure you downloaded and unpacked the reference implementation from the course website above. If you are certain you downloaded the file and you’re still getting an error like that, make sure you also moved the file to your VM or EC2 instance: a common mistake is downloading it to your local machine but not moving it to your work area.) . (If you get an error like “No targets specified and no makefile found” when you run “make clean; make”, go back and double-check that the configure step ran correctly. If it said something like “configure: error: zlib not installed”, you should resolve all of those issues first.) . Note how gcov gives a separate report for each source file specified on the command line, but also gives a sum total for statement coverage (the final Lines executed reported). Your coverage numbers may be slightly different from the example ones listed above. (If you are getting output from gcov, but it does not give you the final Lines executed total, you are likely using a different version of gcov. Students who use WSL, for example, have reported that its version of gcov omits the total. Unfortunately, the solution is to go back to HW0 and use one of the required Linux approaches.) . The png.c.gcov (etc.) files created by this processed are marked-up source files that include coverage and visitation information. You can view them to determine which lines and branches were covered. Note that lcov, a graphical front-end to gcov, may help you interpret that output for large projects. While it is possible to obtain branch coverage using gcov (e.g., -b -c) we will not for this assignment. Note that pngtest creates a new .png file named pngout.png. (This can confuse some students, because if you collect coverage after running on *.png and then do it again, you may get a different answer the second time if you’re not careful because of the newly-added file!) . Recommended Approach . Any test input you create or find is fine: the goal is to get coverage, not to have good or pretty or well-behaved images. (Yes, really any random input is fine. Yes, you can really use a folder of images you found somewhere if you want to and you think that will get good coverage. Yes, really.) Note well, however, the limited resources available on the autograder: if you submit too large of a collection of images, your submission will time out and you will not get any credit for it. We recommend being judicious in your choice of images. You may not upload more than 50 images to the autograder, so choosing “the largest collection of images you can find” is not a good strategy. Submission: test cases . Submit your (individual, not zipped) test cases via Gradescope to the “HW2” assignment. You may submit up to 50 images. The autograder will report a score between 0 and 10. You may submit multiple times, but no more than 5 times in any 24-hour period. The exact grading rubric (e.g., x points for y coverage) is: statement coverage 29% (one point) to 36% (ten points). Note that your local results may differ largely from the autograder results and that is fine and expected. For example, you may observe 6.8% line coverage “at home” and 16.8% on the autograder. (Different compilers, header files, optimizations, etc., may result in different branch and line counts.) Your grade is based on the autograder results, regardless of what you see locally. We always use your best autograder submission result (even if your latest result is worse) for your grade. Note also that the grading server has resource usage (e.g., CPU time) caps. As a result, if you submit a test suite that is very large or long-running, we may not be able to evaluate your submission. Consider both quantity and quality. Submission: written report . You must also write a short two-paragraph report reflecting on your experiences creating a high-coverage test suite for this assigment. (If you are working with a partner, indicate as much in the text or header. Recall from above that you need only submit one copy of the report, but if both you do, nothing bad happens. Select your partner on Canvas.) Consider addressing points such as: . | How did you go about manually creating or otherwise obtaining test cases? | How did your process for creating a high-coverage test suite differ between this assignment and HW1? | Did you use or modify any of the tests we provided or tests from the Internet as part of your answer? (Reminder: You are allowed to do that in this class!) | What was harder than you expected or different than you expected? | (If you used any external resources, such as image files from the Internet or help from Stack Overflow, list it in an optional third paragraph. There is no particular format – a list of URLs is fine. If you used the same general source multiple times, just cite it once.) | . Rubric: . | 5 points — a two-paragraph report reflecting on your activities creating a high-coverage test suite for this assignment, including comparisons and contrasts between your experiences and expectations (with a third paragraph listing any external sources or files used) | 4 points — a reasonable report, but lacking a solid description of one or more aspects or significantly exceeding the length limit | 3 points — a brief report, detailing only half of the required information | 2 points — a report drawing only the bare minimum of contrasts and comparisons (e.g., between two aspects and no more) | 1 point — a terse or uninformative report, perhaps describing only one activity or subject | -1 point — English prose or grammatical errors | -1 point — Text does not include University email address(es) and/or does not make it clear whether you are working alone or with a partner | -all points — Submission uses uncited external resources | . There is no explicit format (e.g., for headings or citations) required. You may discuss other activities (e.g., validation or automation scripts you wrote, etc.) as well. The grading staff may select a small number of excerpts from particularly high-quality or instructive reports and share them with the class. If your report is selected you will receive extra credit. Submit your report to the “HW2” assignment on Canvas. Commentary . Like HW1, this assignment is an open-ended puzzle. There is no “one true path” to manually creating high-coverage test suites. This assignment is intentionally much more difficult than HW1 (for most students). Don’t get discouraged by this: the subject program in HW1 is a “toy” program (the implementation of a data structure typically covered in an undergraduate course), while the subject program here is very much a real-world program that people actually use. Real software is much bigger and more complex than the sort of thing you see in (most) undergraduate-level courses! . FAQ and Troubleshooting . In this section we detail previous student issues and resolutions: . | Question: I get The program 'make' can be found in the following packages: * make. Answer: You need to do sudo apt-get install make or similar. (If you are uncertain about installing and using make, you may need to work a little extra in this assignment and some of the others to brush up on your Linux programming skills. You may want to watch the video linked in HW0 about Linux fundamentals.) . | Question: Can I really use images I found online to help with this assignment? Answer: Yes, provided that you cite them at the end of your report. This class is about “everything except writing code”, in some sense, and in the real world people do everything they can to get high-coverage test suites (including paying people to construct them and using special tools). So you can use image files or benchmarks you find on the Internet if you like — but you’ll still have to do the work of paring things down to a small number of high-coverage files. You’ll likely get the most out of the assignment if you use a combination of white-box testing, black-box testing and searching for resources — but there are many ways to complete it for full credit. | Question: I’m getting an error message like: ./.libs/libpng16.a(pngrutil.o): In function `png_inflate_claim': pngrutil.c:(.text+0xd5b): undefined reference to `inflateValidate' collect2: error: ld returned 1 exit status Makefile:1005: recipe for target 'pngfix' failed . or . Note, selecting 'zlib1g-dev' instead of 'libz-dev' . Answer: You do not have libz-dev installed correctly. One student eventually resolved this by installing an Ubuntu virtual machine. | Question: I get this error: make: *** No targets specified and no makefile found. Stop. Answer: You need to run configure before running make. Double-check the build and installation instructions above. | Question: When I try to run: gcc -o pngtest pngtest.c . It chokes with undefined reference errors. Answer: Answer: Yes — pngtest requires a number of libraries to build. You should follow the installation instructions above (run “configure” then “make”, etc.). | Question: How do other students tackle HW2? Answer: Here’s a public answer from one former student describing the process: . | Oh my god what is this libpng doing…I’m not very familiar with C…What do I do… | Whatever, I guess I could try several png files first (maybe some big files) and check the coverage. Oops, they only cover around 15%…this is frustrating… | All right, I guess I should read the code and look at the conditionals. It seems libppng handles png files which can have different “parameter values”, errors etc. | I tried creating some png files myself setting the parameter values as I want. I searched for some scripts that generate png files. I also tried some software to change an existed png to a new png in the way I want. Great, now my test suite can reach 33%. But after generating some more pngs by manipulating the script, the coverage would not increase further. | Now, should I figure out how to edit the script more to generate more sophisticated pngs? Since C is not my best skill, this will probably cost me a lot of time. How do other people test different png files? Let me scour the web and look for something useful. | Now mixing all the pngs I have together, my test suite can reach much higher than the full marks in the autograder! But I can only submit 50 files…Currently I have more than 100 files… | Let me write a script to automate the selection of the 100+ files. Ah ha, I found a sub set of my test suite that has less than 50 files and can reach higher than 36% coverage. | Finally, I can make a test suite for a real software that I don’t know of. | . | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw2.html",
    "relUrl": "/projects/hw2.html"
  },"47": {
    "doc": "Homework 3: Fuzzing with AFL",
    "title": "Homework 3: Fuzzing with AFL",
    "content": "In this assignment you will use tools to automatically create a high-coverage test suite for a program. You may work with a partner for this assignment. Start Early . Professors often exhort students to start assignments early. Many students wait until the night before and then complete the assignments anyway. Students thus learn to ignore “start early” suggestions. This is not that sort of suggestion. Warning: the tools take hours! The tools you must use for this assignment literally take multiple hours to run. Some students reported that it took over 14 hours to run! (However, others were able to finish in about five minutes. Regardless of when you finish, everything is fine.) Even if you are fast and can finish your work at the last minute, the tools are not and can not. On a high-powered multi-core rack-mounted RAID-storage test machine it took 6.3 hours to run the AFL tool. However, as soon as you get enough data (see below) you can stop early (just press Ctrl-C). However, once running, the tools are completely automated. Thus, you can start them running overnight, sleep and ignore them, and wake up to results. This means that even though the assignment may not take hours of your active personal attention, you must start it days before the due date to be able to complete it in time. Installing, Compiling and Running Legacy Code It is your responsibility to download, compile, and run the subject programs in this assignment (and the other assignments in this course). Getting the code to work is part of the assignment. You can post on the forum for help and compare notes bemoaning various architectures (e.g., windows vs. mac vs. linux, etc.). Ultimately, however, it is your responsibility to read the documentation for these programs and utilities and use some elbow grease to make them work. Subject Program and Tool: PNG Graphics (C) + American Fuzzy Lop . The first subject program is libpng’s pngtest program, seen earlier in Homework 2. This reuse has two advantages. First, since you are already familiar with the program, it should not take long to get started. Second, you will be able to compare the test cases produced by the black-box tool to the white-box test cases you made manually. (You’ll have to recompile it with special flags, but it’s the same source code.) . The associated test input generation tool is American fuzzy lop (hereafter “AFL”), version 2.52b. A mirror copy of the AFL tarball is here, but you should visit the project webpage for documentation. As the (punny? bunny?) name suggests, it is a fuzz testing tool. You will use AFL to create a test suite of .png images to exercise the pngtest program, starting from all of the .png images provided with the original tarball. Note that you can terminate AFL as soon as you reach 510 paths_total (also called total paths in the GUI)— AFL does not stop on its own (instead, press Ctrl-C to stop it). AFL installation and use details . AFL claims that one of its key advantages is ease of use. We will consider four separate high-level steps in this dynamic analysis. Step 1: Compile AFL . Follow along with AFL’s quick start guide. Extract the AFL tarball (to its own directory) and run “make”. Note that this results in files such as afl-gcc and afl-fuzz, which we will use in subsequent steps. Step 2: ‘Instrument’ libpng . Do not re-use your HW2 copy of libpng. (It is possible, but leads to much confusion.) Instead, download a fresh copy of the reference implementation (version 1.6.40) here and place it in a new folder for Homework 3 (e.g., HW3). Change to that libpng-1.6.40 directory and re-configure libpng with a special configure line like this: . $ CC=/REPLACE/THIS/TEXT/WITH/YOUR/PARTICULAR/PATH/TO/afl-gcc_(don't_just_copy_this_in_unchanged) ./configure --disable-shared CFLAGS=\"-static\" $ make . The “CC” bit will look something like (but maybe different for you) CC=/home/ubuntu/cs684/hw3/afl-2.52b/afl-gcc — note that there is no trailing slash. If you see configure: error: C compiler cannot create executables, double-check your spelling here. Also, folder names with spaces (like “CS 684/HW 3”) will not work: rename the folder to remove the spaces. Multiple students have reported that WSL does not work with AFL and that they needed to move to an Ubuntu virtual machine instead (as per HW0). See the FAQ below. Note that you are not using “coverage” or gcov for this part of the homework assignment. We only want AFL instrumentation for now. Step 3 — Choosing seed images . AFL uses initial inputs you provide and mutates them to find new inputs that cover additional parts of the program. (For more information, see its documentation.) The initial inputs you provide are called seed inputs. Since we are testing libpng, the seed inputs are “images”. Because AFL repeatedly processes these seed files, if you include very large or very many seed files, AFL will take too long to run. Make a new subdirectory to hold your seed files. This subdirectory may be called testcase_dir in the documentation, but you can name it whatever you want. Most students put their 50 manual test cases from HW2 there, but if your HW2 images are large, consider only including the smaller ones. (You’ll want to know the total coverage of the seed images you start with for the HW3 written report, but since you’ve left your HW2 installation alone, you can compute that using the same method you used in HW2. Delete the old coverage information in your HW2 folder, run pngtest on all of your seed images, and run gcov to list the total coverage.) . Step 4 — AFL generates inputs for libpng . Now it is time to run AFL on libpng. $ sudo su # echo core &gt; /proc/sys/kernel/core_pattern # exit $ /REPLACE/THIS/TEXT/WITH/YOUR/path/to/afl-fuzz -i testcase_dir -o findings_dir -- /path/to/pngtest_(not_.c_nor_.png_but_the_executable_you_built) @@ . (In this command, the /path/to/pngtest_(not_.c_nor_.png_but_the_executable_you_built) part is the absolute path to the pngtest executable that is created after running make in the libpng directory for HW3 in Step 2 above. For example, it might potentially look something like /home/ubuntu/HW3/libpng-1.6.40/pngtest but might be slightly different for you.) . Do double-check the end of the previous line for @@. It is required, it is not a typo, and if you did not type it in (to tell AFL where its randomly-created arguments to pngtest go) you are likely to “get stuck” when enumerating paths and tests (see FAQ below). Note that findings_dir is a new folder you make up: afl-fuzz will put its results there (in a queue subfolder). The results will be “images” (both good and bad) produced by AFL to get high coverage. The results will all have ugly names, but they will be the output of AFL. Note that you must stop afl-fuzz yourself (just press Ctrl-C), otherwise it will run forever — it does not stop on its own. Read the Report instructions below for information on the stopping condition and knowing “when you are done”. Note also that you can resume afl-fuzz if it is interrupted or stopped in the middle (you don’t “lose your work”). When you try to re-run it, it will give you a helpful message like: . To resume the old session, put '-' as the input directory in the command line ('-i -') and try again. Just follow its directions. Warning: when you resume AFL it will overwrite your findings/plot_data file (which you need for the final report), so be sure to save a copy of that somewhere before resuming. Note that afl-fuzz may abort the first few times you run it and ask you to change some system settings (e.g., echo core | sudo tee /proc/sys/kernel/core_pattern, echo core &gt;/proc/sys/kernel/core_pattern etc.). For example, on Ubuntu systems it often asks twice. Just become root and execute the commands. Note that sudo may not work for some of the commands (e.g., sudo echo core &gt;/proc/sys/kernel/core_pattern will fail because bash will do the &gt; redirection before running sudo so you will not yet have permissions, etc.) — so just become root (e.g., run sudo sh) and then execute the commands in a root shell. If you are getting core_pattern: Permission denied errors, make sure you become root first before executing the commands: . sudo su echo core &gt; /proc/sys/kernel/core_pattern exit . The produced test cases are in the findings_dir/queue/ directory. They may not have the .png extension (instead, they might have names like 000154,sr...pos/36,+cov), but you can rename them if you like. Note that AFL can and will produce “invalid” PNG files to test error handling code; such “invalid” PNG files will appear to produce errors or otherwise not be viewable. This is normal and expected. At some point, many students are tempted to ask a question like “Is it normal that my XYZ Machine got to ABC paths in PQR minutes?” We acknowledge that students are often anxious about this assignment. For many students, this may be a first experience using an off-the-shelf tool with an unknown running time. As a software engineer, you will need to be comfortable with scheduling and risk (especially with respect to schedules). Part of this homework is designed to give you a feeling for what it is like to employ a software engineering process in the face of uncertainty. We want to give you experience with this in a safe (classroom) setting, rather than having your first experience with this be on the job. Regretfully, there is no way for us to answer questions about whether or not it is normal that your particular machine took some particular time. I know students really wish we could reduce their anxiety or uncertainty about this process. In practice, the running time of AFL depends on many factors, including the side and number of the seed images, the speed of your CPU and disk, the load on the machine, and so on. There is no secret formula for how long it is supposed to take that we are hiding from you but will reveal if you ask such a question directly. Instead, living with this uncertainty — feeling uncomfortable about it, and having to complete the assignment anyway — is a key point of the assignment. Help! I can't open AFL's output! You will almost certainly find that AFL’s output queue folder does not contain files with the .png extension. In addition, you will almost certainly find that most of the files produced by AFL are “invalid” PNG files that cause program executions to cover error cases (e.g., libpng read error). This is normal. Double-check all of the instructions here, and the explanations in the course lectures for how these tools work: there’s no need to panic. In addition, you might try alternate image viewers (rather than just the default one). For example, multiple students have reported that uploading apparently-invalid images to GitHub (no, really) works well for viewing them. While AFL is running, you can read the technical whitepaper to learn about how it works and compare the techniques it uses to the basic theory discussed in class. Help! It looks like AFL has stalled! Is that normal? I am worried. Students are often worried that AFL appears to have stalled. Such students often wonder things like: “Should I restart AFL? Or is everything fine? Have I done something wrong? Or should I just leave it be?” . Making scheduling decisions in the face of uncertainty (i.e., unknown information) is a major theme in the course. It is explicitly part of the assignment. Once a student has AFL running correctly (e.g., following the instructions above, not forgetting the @@, etc.) and has seen AFL produce some new images (e.g., by inspecting the output directory from another shell terminal window), that student should feel confident allowing AFL to continue to run. It is very common for AFL to “plateau” or “get stuck” for a while and recover naturally. To reassure students, below is a cropped example plot from a previous semester (with the x-axis label intentionally removed). (If your plot does not have this shape, you are still fine.) Note how there are multiple periods where no new progress appears to be made. Students who find that AFL is taking too long also have the option of restarting with a smaller set of seed images, all of which are quite small. The running time of AFL strongly depends on the number and size of your seed images. Students are often tempted to ask the course staff questions akin to “Should I allow AFL to continue to run?” Unfortunately, we really don’t have any special information in such circumstances (cf. “Should I continue to wait on the waiting list?”). You must decide for yourself. Help! It looks like AFL's generated test images don't improve coverage (much)! Some students report that the AFL-generated test inputs do not seem to be improving branch coverage with respect to the seed images. This can definitely happen, but usually it means that the student is making a slight typo or similar mistake in the coverage computation. In previous semesters, the most common mistakes included: . | Not considering overlap. If your seed images (alone) get 10% coverage and the AFL-generated images (alone) get 11% coverage, it may be that putting them all together gets 15% coverage (or whatnot). | Using the wrong pngtest. The AFL-instrumented pngtest binary is not the same as the gcov-instrumented pngtest binary (even though they have the same filename) and will not generated gcov coverage information. | Running gcov-instrumented pngtest in the wrong directory. | Forgetting to remove gcov intermediate files between runs. | . To test their coverage process, students might take 15 of their files from HW2 and put them in a directory A. Then copy 1 of those files from A and also put it in directory B. Compute the coverage of the 15 files in A first. Then compute the coverage of the 1 file in B. The coverage of B should be less than A (which should also be less than HW2). AFL is not always a useful tool in all contexts. Many students find that “AFL-Generated + Seed” improves on “Seed” by two or three percentage points, but that is not universal, and if you get a different results you are fine. Your answer will vary based on how long you let AFL explore and the initial quality of your seed images. Submission: Written Report . You must create a written PDF report reflecting on your experiences with automatic test generation. You must include your name and NJIT email id (as well as your partner’s name and email id, if applicable). In particular (rubric notes are in []s): . | In a few sentences, your report should describe one test case that AFL created that covered part of libpng that your manual test suite from Homework 2 did not, and vice versa. (If no such tests exist, for example because you seeded AFL with all of your manual tests, instead describe what did happen. For example, if you seeded AFL with all of your manual tests, then AFL’s output will be a superset of yours.) You should also indicate how many tests your run of AFL created, your total runtime, and the final coverage of the AFL-created test suite (use the technique described in Homework 2 to compute coverage; note that AFL will include all of the original seed tests as well — yes, you should include or consider those). (Optional hint: when comparing two test suites, it sometimes clarifies things to report their two coverages separately and also the coverage obtained when putting them together. Two test suites that each get 10% coverage alone may get 10%, 15% or 20% coverage when combined depending on overlap. Did the “AFL+Seed” combined test suite yield higher coverage then just the Seed images test suite?) [2 points for AFL, 2 points for manual, 1 point for summary] . | Some students are uncertain about what it means to “describe” an image. This report is being read by a human, and the focus is on testing (not “artistry”). It may serve as helpful framing to imagine that you are writing this report to your boss at a company. The ultimate goal would be to determine if or under what circumstances AFL should be used. While some visual descriptions may be relevant, many find that the properties of the generated files also merit a mention. | Some students report being uncertain about how to determine the coverage of a test suite. We recommend that you use the techniques you learned in HW2, such as gcov, to compute coverage. The assignments in this course often build upon each other. | . | Your report should include, as inlined images, one or two “interesting” valid PNG files that AFL created and a one-sentence explanation of why they are “interesting”. [1 point for image(s), 1 point for explanation] . | Some students report difficulties in uploading certain images to Google Docs. One workaround is to load the image in another viewer, take a screenshot, and upload the screenshot to Google Docs. | . | Your report should include a scatterplot in which the x axis is “seconds” (or some other notion of total execution time, such as unix_time) and the y axis is paths_total as reported in the findings/plot_data CSV file produced by your run of AFL. You must create this plot yourself (using the program of your choice; I recommend gnuplot or a spreadsheet program like Excel or Google Sheets, but whatever you are comfortable with is fine. In a real engineering job, your manager won’t care how you generate plots, as long as they are pretty and contain the required information.). Your scatterplot must include data reaching at least 510 paths_total on the y axis — which means you must run AFL until you have at least that much data. (See here for plot examples that include much more detail than you are asked to include here. Note that this is not own finds but is instead total paths in the upper right corner. Include a sentence that draws a conclusion from this scatterplot. If you do not like scatterplots you can make a line graph (etc.) as long as it conveys the same information. [2 points for plot, 1 point for conclusion] . Note that it does not matter how many rows are in your plot_data file or if you are missing some rows at the start or middle as long as you got up to 510 paths_total (also called “paths total” in the GUI)— it is common to have fewer than 510 rows. Note that if you suspended afl-fuzz you may have a big time gap in your plot. We do not care how you handle that (e.g., ugly graph, big gap, fudge the times, whatever) — any approach is full credit. | In one paragraph, your report should compare and contrast your observations (e.g., usability, efficacy, test quality) of AFL. List at least one strength of AFL and at least one area for improvement. Which software engineering projects might benefit from the use of such a tool? Would you use it personally? Why or why not? [1 point for strengths and weaknesses, 2 points for insightful analysis] . | Although we do not have explicit formatting guidelines that we require you to follow, is is easier for the graders to interpret text that is presented clearly. We encourage you to format your results in a manner that you think would simplify reading later. (One way to double-check would be to write your report draft and then step back for a few minutes and then re-read the text or have your partner re-read the text.) [2 points for clear presentation and no typos that hinder understanding] | . This does not have to be a formal report; you need only answer the questions in the rubric. However, nothing bad happens if you include extra formality (e.g., sections, topic sentences, etc.). There is no explicit format (e.g., for headings or citations) required. For example, you may either use an essay structure or a point-by-point list of question answers. The grading staff will select a small number of excerpts from particularly high-quality or instructive reports and share them with the class. If your report is selected you will receive extra credit. For this assignment the written report is the primary artifact. There are no programmatic artifacts to submit (however, you will need to run the tools to create the required information for the report). (If you are working with a partner, you must select your partner on Canvas and submit one copy of the report. However, nothing fatal happens if you mistakenly submit two copies.) . Commentary . This assignment is perhaps a bit different than the usual CS homework assignment: instead of you, yourself, doing the “main activity” (i.e., creating test suites), you are asked to invoke tools that carry out that activity for you. This sort of automation (from testing to refactoring to documentation, etc.) is indicative of modern industrial software engineering. Asking you to submit the generated tests is, in some sense, uninteresting (e.g., we could rerun the tool on the grading server if we just wanted tool-generated tests). Instead, you are asked to write a report that includes information and components that you will only have if you used the tools to generate the tests. Writing reports (e.g., for consumption by your manager or team) is also a common activity in modern industrial software engineering. FAQ and Troubleshooting . In this section we detail previous student issues and resolutions: . | Question: Using AFL, I get: ERROR: PROGRAM ABORT : Test case 'xxxxxx/pngtest' is too big (2.25 MB, limit is 1.00 MB) . Answer: You are mistakenly passing the pngtest executable in as a testcase to itself. Try putting your pngtest executable one directory above from your testcase_dir. In other words, rather than having it in the same folder as your test images (testcase_dir), put it in the directory that testcase_dir is in, and adjust /path/to/pngtest accordingly. | Question: My AFL session has 0 cycles done but the total paths counter does increment. I am worried. Answer: Everything is fine. It is entirely possible to complete the assignment with 0 cycles done. (AFL can enumerate quite a few candidate test cases — enough for this assignment — before doing a complete cycle.) . | Question: My ssh sessions keep getting disconnected. How can I avoid losing my work from a long-running job? . Answer: Two common approaches are to use the nohup command or the screen command. There are a number of helpful tutorials online to get you started. | Question: Using AFL, I get: [-] SYSTEM ERROR : Unable to create './findings_dir/queue/id:000000,orig:pngbar.png' . Answer: This is apparently a WSL issue, but students running Linux who ran into it were able to fix things by making a new, fresh VM. | Question: Using AFL, I get: [-] PROGRAM ABORT : Program 'pngtest' not found or not executable . or . [-] PROGRAM ABORT : Program 'pngnow.png' is not an ELF binary . Answer: You need to use the right /path/to/pngtest instead of just pngtest. You must point to the pngtest executable (produced by “make”) and not, for example, pngtest.png. | Question: Using AFL, I get: [-] PROGRAM ABORT: Program 'pngtest' is a shell script . Answer: You must recompile libpng carefully following the instructions above, including the explanation about “CC=…” and “–disable-shared” and the like. Example showing that a normal build produces a shell script while a more careful AFL-based build produces an executable: . $ ./configure &gt;&amp; /dev/null ; make clean &gt;&amp; /dev/null ; make &gt;&amp; /dev/null ; file ./pngtest ./pngtest: Bourne-Again shell script, ASCII text executable $ CC=~/481/afl-2.52b/afl-gcc ./configure --disable-shared CFLAGS=\"-static\" &gt;&amp; /dev/null ; make clean &gt;&amp; /dev/null ; make &gt;&amp; /dev/null ; file ./pngtest ./pngtest: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/l, for GNU/Linux 3.2.0, BuildID[sha1]=bec3dc8e4b3feff6660f9339368f5c1ec5f55ab9, with debug_info, not stripped . | Question: When I try to run AFL, I get: [-] PROGRAM ABORT : No instrumentation detected . Answer: You are pointing AFL to the wrong pngtest executable. Double-check the instructions near $ CC=/path/to/afl-gcc ./configure --disable-shared CFLAGS=\"-static\", rebuild pngtest using “make”, and then point to exactly that executable and not a different one. | Question: When I try to run configure with AFL via something like CC=/home/vagrant/cs684/hw3/afl-2.52b/afl-gcc/ ./configure --disable-shared CFLAGS=\"-static\", I get: checking whether the C compiler works... no configure: error: in `/home/vagrant/cs684/hw3/libpng-1.6.40': configure: error: C compiler cannot create executables . Answer: You need to specify afl-gcc, not afl-gcc.c or afl-gcc/ (note trailing slash!). | Question: When I am running AFL, it gets “stuck” at 163 (or 72, or another small number) paths. Answer: In multiple instances, students had forgotten the @@ at the end of the AFL command. Double check the command you are running! . | Question: When trying to use AFL on Amazon EC2, I get: [ec2-user@ip-172-31-19-147 afl-2.52b]$ make [*] Checking for the ability to compile x86 code... /bin/sh: cc: command not found Oops, looks like your compiler can't generate x86 code. Answer: One student reported resolving this via sudo yum groupinstall \"Development Tools\" . | Question: When I try to compile libpng with AFL, I get: configure: error: C compiler cannot create executables . Answer: You need to provide the full path to the afl-gcc executable, not just the path to hw3/afl-2.52b/. | Question: When running AFL, I receive this error: SYSTEM ERROR : Unable to create './findings_dir/queue/id:000000,orig:pngbar.png' . Answer: One student reported that this happens when you try to use a shared folder in the VM to store your HW3 (or AFL) directory. The solution that worked for the student was to move the HW3 directory out of the shared folder. | Question: Some of the so-called “png” files that AFL produces cannot be opened by my image viewer and may not even be valid “png” files at all! . Answer: Yes, you are correct. (Thought question: why are invalid inputs sometimes good test cases for branch coverage?) . | Question: What does “interesting” mean for the report? Similarly, how should we “elaborate” or “reflect”? . Answer: We sympathize with students who are concerned that their grades may not reflect their mastery of the material. Being conscientious is a good trait for CS in general and SE in particular. However, this is not a calculus class. Software engineering involves judgment calls. I am not asking you to compute the derivatives of various polynomials (for which there is one known right answer). You are carrying out activities that are indicative of SE practices. Suppose you are tasked with evaluating a test generation tool for your company. You are asked to do a pilot study evaluating such a tool and prepare a report for your boss. One of the things the boss wants to know is: “What are the risks associated with using such a tool?” Similarly for the benefits or rewards. | Question: Can I use free cloud computing, like Amazon EC2, for this assignment? . Answer: Sure - we recommend it! Here’s what one student had to say: . If you can get over the hump of setting up AWS (pro-tip they have lots of documentation, use google. also here you go), their free-tier EC2 instances can get the AFL job done in a blink. Using their free-tier EC2 Ubuntu instance, I was able to run AFL up to &gt;500 paths in 5 minutes. Setup would probably take less than 30 minutes for a new user. IMO that more than balances the headache of having to run AFL for hours and hours and hours and hours. | Question: I am using WSL, and when I try to run AFL I get: $ CC=/mnt/c/users/.../684/hw3/afl-2.52b/afl-gcc ./configure --disable-shared CFLAGS=\"static\" checking for a BSD-compatible install... /usr/bin/install: setting permissions for '/mnt/c/users/.../hw3/libpng-1.6.40/conftest.dir/conftest.one': Operation not permitted ... configure: error: in `/mnt/c/users/.../684/hw3/libpng-1.6.40': configure: error: C compiler cannot create executables . Answer: Students were able to resolve this by not using WSL and instead using an Ubuntu virtual machine. | Question: How can I make AFL run faster? . Question: I’m getting “The program took more than 1000 ms to process” warnings from AFL. Answer: One anonymous student suggests: . Is your AFL running slow? Are you getting less than 30/sec on the exec speed? Have you been running for 21+ hours like me and are frustrated that you haven’t found any new paths in the last 4 hours? . Try making a copy of your test image directory, then remove any “large” test images from this new directory (I deleted all test images over 100KB), and then try running a new AFL session with this new input directory, and a new output directory. Each “session” of AFL basically runs in a single thread, so it seems to be fine running two different sessions at once, with different input/output directories. I watched as my new run (with small test image files) consistently ran with an exec speed of 500-1000, and achieved 600 total paths in under 7 minutes, all while safely letting my old session continue to run. tl;dr Don’t use lots of “large” images with AFL (large roughly being &gt;100KB) . | Question: When I try to compile libpng using the AFL compiler, I get an error like the following: C compiler cannot create executables. Answer: Make sure you have the libraries you need to compile libpng. You may want to refer back to the HW2 instructions. | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw3.html",
    "relUrl": "/projects/hw3.html"
  },"48": {
    "doc": "Homework 4: Generating Tests with EvoSuite",
    "title": "Homework 4: Generating Tests with EvoSuite",
    "content": "In this assignment you will use tools to automatically create a high-coverage test suite for a program. You may work with a partner for this assignment. Start Early . Professors often exhort students to start assignments early. Many students wait until the night before and then complete the assignments anyway. Students thus learn to ignore “start early” suggestions. This is not that sort of suggestion. Warning: the tools take hours! The tools you must use for this assignment literally take multiple hours to run. Some students reported that it took over 14 hours to run! (However, others were able to finish in about five minutes. Regardless of when you finish, everything is fine.) Even if you are fast and can finish your work at the last minute, the tools are not and can not. On a high-powered multi-core rack-mounted RAID-storage test machine it took 1.25 hours to run the EvoSuite tool. However, as soon as you get enough data (see below) you can stop early (just press Ctrl-C). However, once running, the tools are completely automated. Thus, you can start them running overnight, sleep and ignore them, and wake up to results. This means that even though the assignment may not take hours of your active personal attention, you must start it days before the due date to be able to complete it in time. (Unfortunately, there is no way to resume an interrupted EvoSuite session without restarting it from the beginning, so be careful about laptop power and the like.) . Installing, Compiling and Running Legacy Code It is your responsibility to download, compile, and run the subject programs in this assignment (and the other assignments in this course). Getting the code to work is part of the assignment. You can post on the forum for help and compare notes bemoaning various architectures (e.g., windows vs. mac vs. linux, etc.). Ultimately, however, it is your responsibility to read the documentation for these programs and utilities and use some elbow grease to make them work. Subject Program and Tool: JSoup (Java) + EvoSuite . The subject program is jsoup (v 1.11.2), a library for extracting real-world HTML data using DOM, CSS and jquery-like methods. A copy of the version of the source code known to work for this assignment is available here; you can also use git clone https://github.com/jhy/jsoup.git. It involves about 18,000 lines of code spread over 60 files. This program is a bit small for this course, but comes with a rich existing test suite. This existing test suite will serve as a baseline for comparison . The associated test input (and oracle!) generation tool is EvoSuite, version 1.0.5. Mirror copies of evosuite-1.0.5.jar and evosuite-standalone-runtime-1.0.5.jar are available, but you should visit the project webpage for documentation. EvoSuite generates unit tests (cf. JUnit) for Java programs. JSoup Installation Details . You can install jsoup and use cobertura to assess the statement and branch coverage of its built-in test suite (note that you may need to install Maven to run mvn): . $ unzip jsoup-1.11.2.zip $ cd jsoup-master/ $ mvn cobertura:cobertura ... [INFO] Cobertura: Saved information on 253 classes. Results : Tests run: 648, Failures: 0, Errors: 0, Skipped: 11 ... [INFO] Cobertura Report generation was successful. [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS $ firefox target/site/cobertura/index.html # this probably won't work on EC2 . Note that the supplied test suite is of high quality, with around 81% line coverage and 77% branch coverage overall. (If your coverage numbers are different, you are still fine. If you have a different number of classes you are fine.) . In some cases (such as students using Amazon EC2), you may find it difficult to view the HTML report (although you can use a command-line browser like elinks, which is discussed in the video linked from HW0, if you’d like). In that case students report that it is often easiest to copy the entire directory back to your local machine and view it there (e.g., scp -r, see HW0 for more information on scp. You might also consider learning rsync.). EvoSuite Installation and Use Details . EvoSuite includes some clear tutorials explaining its use. Mirror copies of hamcrest-core-1.3.jar and junit-4.12.jar are available if you need them. Once you have EvoSuite installed you can invoke it on jsoup via: . $ cd jsoup-master $ $EVOSUITE -criterion branch -target target/classes/ ... * Writing JUnit test case 'ListLinks_ESTest' to evosuite-tests * Done! * Computation finished . You can now find the EvoSuite tests in evosuite-tests/org/jsoup. In the report you are asked to compare the coverage of the developer-provided test suite to the EvoSuite-created test suite. One simple and common way to do this is by inspecting the evosuite-reports/statistics.csv file. However, you are also welcome to try integrating other coverage tools, such as clover or cobertura, with Maven, but this is not required (and may be tricky). Submission: Written Report . You must create a written PDF report reflecting on your experiences with automatic test generation. You must include your name and NJIT email id (as well as your partner’s name and email id, if applicable). In particular (rubric notes are in []s): . | Look at evosuite-report/statistics.csv and compare it to target/site/cobertura/index.html. In a few sentences, compare and contrast the branch coverage of the manually-created test suite to the EvoSuite-created test suite. [2 points for a comparison that does more than just list numbers] . | Choose one class for which EvoSuite produced higher coverage than the human tests (if no such class exists, choose EvoSuite’s “best” class). Look at the corresponding tests. (You will have to look carefully at the automatically- and manually-generated tests to answer this question.) In one paragraph, indicate the class and explain the discrepancy. For example, in your own words, what is EvoSuite testing that the humans did not? Why is EvoSuite more likely to generate such a test? What do you think of the quality of the tests? The readability? Suppose a test failed. Would the test’s failure help you find the bug? [4 points for a convincing analysis that shows actual insight] . | Choose one class for which EvoSuite produced lower coverage than the human tests (if no such class exists, choose EvoSuite’s “worst” class). Elaborate and reflect as above, but also offer a hypothesis for why EvoSuite was unable to produce such a test: bring in your knowledge of how EvoSuite works. [4 points for an analysis that shows insight, especially into EvoSuite’s limitations] . | In one paragraph, your report should compare and contrast your observations (e.g., usability, efficacy, test quality) of AFL (from HW3) and EvoSuite. List at least one strength of each tool and at least one area for improvement. Which software engineering projects might benefit from the use of such tools? Would you use them personally? Why or why not? [1 point for AFL strengths and weaknesses, 1 point for EvoSuite strengths and weaknesses, 3 points for insightful analysis] . | Although we do not have explicit formatting guidelines that we require you to follow, is is easier for the graders to interpret text that is presented clearly. We encourage you to format your results in a manner that you think would simplify reading later. (One way to double-check would be to write your report draft and then step back for a few minutes and then re-read the text or have your partner re-read the text.) . | . This does not have to be a formal report; you need only answer the questions in the rubric. However, nothing bad happens if you include extra formality (e.g., sections, topic sentences, etc.). There is no explicit format (e.g., for headings or citations) required. For example, you may either use an essay structure or a point-by-point list of question answers. The grading staff may select a small number of excerpts from particularly high-quality or instructive reports and share them with the class. If your report is selected you will receive extra credit. For this assignment the written report is the primary artifact. There are no programmatic artifacts to submit (however, you will need to run the tools to create the required information for the report). FAQ and Troubleshooting . | Question: Cobertura suggests that the project has 3,726 branches, but EvoSuite seems to think they sum up to 5,149 (or 4,985, or any other number). What gives? . Answer: Good observation! Everything is fine. Consider how the two tools might be implemented differently. What are some ways in which two tools could disagree about the number of “branches” in the same Java classes? . | Question: After I extract the archive and cd into my jsoup directory, I run mvn cobertura:cobertura. However, it doesn’t successfully compile:, COMPILATION ERROR: /home/.../jsoup/nodes/Element.java incompatible types: java.util.ArrayList...cannot be converted to java.util.ArrayList . Do I need to manually edit my files? . Answer: No, you do not need to edit your files. This is most likely because your version of maven is compiling with jdk-9. First, verify this with $ mvn -version. Then, run $ sudo update-alternatives --config java to set your version to jdk-8. Note the path as well to java-8-openjdk-amd64 (which should show up as one of the options). Then export the JAVA_HOME path as follows: $ export JAVA_HOME=/path/to/java-8-openjdk-amd64. Try to recompile and it should work now. Some students report that this Stack Overflow link and this explanation may be helpful for resolving this on a Mac. | Question: When trying to run EvoSuite, I get: -criterion: command not found . Answer: This almost always indicates some sort of typo in your export EVOSUITE=... setup line. | Question: Can I terminatie EvoSuite and resume it later? . Answer: Unfortunately, no. An instructor emailed the author who indicated that this is not currenltly possible. | Question: What does “interesting” mean for the report? Similarly, how should we “elaborate” or “reflect”? . Answer: We sympathize with students who are concerned that their grades may not reflect their mastery of the material. Being conscientious is a good trait for CS in general and SE in particular. However, this is not a calculus class. Software engineering involves judgment calls. I am not asking you to compute the derivatives of various polynomials (for which there is one known right answer). You are carrying out activities that are indicative of SE practices. Suppose you are tasked with evaluating a test generation tool for your company. You are asked to do a pilot study evaluating such a tool and prepare a report for your boss. One of the things the boss wants to know is: “What are the risks associated with using such a tool?” Similarly for the benefits or rewards. | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw4.html",
    "relUrl": "/projects/hw4.html"
  },"49": {
    "doc": "Homework 5: Invariants and Partial Oracles",
    "title": "Homework 5: Invariants and Partial Oracles",
    "content": "High-level goal . The high-level goal of this two-part assignment is to learn about program invariants and partial test oracles (property-based testing and metamorphic testing). Both of these were discussed in lecture this week. Each part of the assignment requires you to do a task and then answer questions about your findings, similar to HW3 and HW4. There is no autograder for this assignment. You may work with a partner for this assignment. Part 1: Invariants . Instructions . | Familiarize yourself with the Daikon Invariant Detector. | Then, run Daikon on a data structure example of your choice. You may choose to run Daikon for any supported programming language (see installation instructions). You may select any data structure, but we recommend choosing a standard data structure such as a tree, graph, heap, stack, queue, trie, or hash table. If the data structure comes with a test suite, you may use that test suite. You are also permitted to write (or generate, e.g. using one of the tools that we’ve discussed in this course) your own test suite. We strongly suggest selecting a data structure implementation that you are already familiar with. In particular, students are typically most successful at this assignment when they select a data structure that they implemented (usually, in a previous class, such as CS 610). You may not select a program that has already been a subject program in this course (in particular, you may not select avl.py from HW1) or that appears as an example in the Daikon user manual (linked above). Note that the data structure implementation you select does not need to be publicly available, but you will need to make it available to the course staff (so, for example, if you have some code from a prior course, you might include it with your submission on Canvas; I’ve configured Canvas to accept as many files as you want to provide for this assignment). | . Questions . Answer these questions as part of your writeup [rubric notes in these brackets]. | Provide a link to the chosen data structure or include the implementation of the data structure in your submission on Canvas (in your answer to this question, mention each extra file that you submit and its purpose). Also provide a link to the test suite you used (or include the test suite in your submission), and explain where you got the test suite. For this data structure and the corresponding Daikon output, give one example for a true invariant and one example for a discovered invariant that only holds for the given test suite. [1 point for true invariant, 1 point for invariant that only holds for the given test suite. Unbounded negative points for failing to provide all required information.] . | Briefly explain which (if any) types of invariants discovered by Daikon are generally useful for testing and/or debugging (alternatively, briefly explain which types are not useful). There are no wrong answers: the provided answer is evaluated based on its justification not the expressed believe. [4 points for well-reasoned argument.] . | For a software system that you are familiar with, briefly explain that system and state at least two types of invariants of interest (useful for testing and/or debugging). Briefly explain whether and how these invariants can be dynamically discovered. [1 point for each invariant and explanation.] . | . Part 2: Testing with Partial Oracles . This part has two variants (A and B). You only need to complete one of them. However, if you complete both, you’ll receive two bonus points on the assignment. Instruction: Variant A . | Clone an open-source repository of your choice for a non-trivial software system that is amenable to metamorphic testing. The software system may be written in any programming language, but it must provide a build system for compilation and testing. You may not select a program that was used as part of a previous assignment in this course as a subject program (so you could select AFL, but you could not select libpng). | For the chosen software system, design two metamorphic relations (MRs): . | The two MRs must hold for arbitrary, well-formed inputs. | For at least one MR, the output relation must not be the identity function. | . | Implement your two MRs as test-case generators, which take an initial test case as input and produce a follow-up test case as output. | Based on the designed MRs, automatically generate a few test cases and execute them. (For the initial test cases, you may rely on random input generation, any existing test cases, or manually created test cases.) | . Instructions: Variant B . | Choose a non-trivial online software system for classification (e.g., text, images, code, etc.). | For the chosen software system, design three metamorphic relations (MRs): . | The three MRs must hold for arbitrary, well-formed inputs. | For at least two MRs, the output relation must not be the identity function. | . | Based on the designed MRs, generate a few test cases, execute the online system, and observe its output. (You may automate the test-case generation.) | . Questions . Answer these questions as part of your writeup [rubric notes in these brackets]. | Describe the chosen software system and justify for each of the designed MRs why it must hold for arbitrary, well- formed inputs. [1 point for the description of the system, 2 points for the descriptions of the MRs.] . | Briefly summarize your observations about testing with MRs and state at least two characteristics of effective MRs. You may reason about the specific MRs you designed or MRs in general. [2 points for insightful observation, 1 point each for characteristics of effective MRs.] . | . Submission: Written Report . Write up your answers to the 5 questions above (Part 1 Questions 1-3, Part 2 Questions 1-2). Submit a plaintext (.txt) or PDF file to Canvas. Also submit any code or test cases that you used that are not publicly-available and linked from your report. Although we do not have explicit formatting guidelines that we require you to follow, is is easier for the graders to interpret text that is presented clearly. We encourage you to format your results in a manner that you think would simplify reading later. (One way to double-check would be to write your report draft and then step back for a few minutes and then re-read the text or have your partner re-read the text.) You may organize your report as paragraphs, bullet points, explicit answers to each question, or whatever other organization you think will be easiest for us to interpret. As usual in this class, you may use files, benchmarks or resources from the Internet (unlike in many other classes), provided you cite them in your written report. (If you use the same resource many times, such as StackOverflow, one citation per resource suffices.) . Frequently-asked Questions . | Question: I’m not sure what “non-trivial software system” means in Part 2. Answer: For Variant A, the software should be publicly-available (e.g., on Github) and actively-maintained (i.e., commits are regularly made to add features or fix bugs). It should also exist to accomplish some task - it must not be a toy or a course project (e.g., a “twitter clone” that is not actually deployed anywhere is not allowed). We recommend that you select a program in the same category as the subject programs from previous homeworks, (e.g., JSoup or libpng would be good choices, if they had not been used in previous homeworks). For Variant B, the software should be actively supported, and you should be able to point to a URL. We typically expect you to choose well-known online classification systems if you choose Variant B. | Question: Is it possible to start Part 2 before finishing Part 1? . Answer: There are no dependencies between Part 1 and Part 2, and you can complete them in either order. | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw5.html",
    "relUrl": "/projects/hw5.html"
  },"50": {
    "doc": "Homework 6: Mutation Testing",
    "title": "Homework 6: Mutation Testing",
    "content": "In this assignment you will write a tool to carry out simple mutation testing on Python programs. Given a program, your tool must generate mutants of that program such that the mutation adequacy score (i.e., the percentage of mutants that are killed by each test suite) correctly rank-orders a number of held-out test suites for that program in terms of their quality. You may work with a partner for this assignment. If you do you must use the same partner for all sub-components of this assignment. Use Gradescope and Canvas features to select your partner. Only one partner needs to submit the report on Canvas, but if you both do, nothing fatal happens. You are still allowed to use online (or \"on-this-webpage\") resources and the like as long as you cite them in your writeup. Cross-Platform Compatibility and Python . It is your responsibility to submit Python code that works on the grading server. This is true even if (indeed, especially if) the grading server uses a different version of Python than your development environment. This assignment uses Python because the focus is on the mutation algorithm and not the compiler front-end. In theory it would be just as easy to do this assignment on C++ code using LLVM (e.g., via clang) or the like. In practice that would just add out-of-scope overhead without reinforcing course concepts. If you are interested in such topics, consider taking an advanced Programming Languages or Compilers course (or make an appointment to talk to me about it!). The grading server uses Python 3.10.12 for this assignment. (Yes, this is a change from other homeworks.) . HW6a: Mutation Testing (Python) . Your mutation testing tool will take the form of a Python program called mutate.py. Your mutate.py accepts two command line arguments: first, the name of a Python source program to mutate; second, the number of mutants to produce (see below). Your mutate.py must create a number of new Python source files in the same directory that are mutants of the input program. The mutants must be named 0.py, 1.py, 2.py, and so on. Each mutant is a copy of the original program with one or more mutation operators (see below) applied. Any other output (e.g., logging to standard output) your mutate.py produces is ignored. The data structure used to represent Python source files is the abstract syntax tree (AST). You should use the ast module (to read Python source files into abstract syntax trees) as well as the astor module (to serialize abstract syntax trees out to Python source files). Many students report that the so-called \"missing Python AST docs\" are quite helpful here. Other students and instructors have found this quick Python AST Tutorial to be quite helpful (thanks S. Ajami) for the basic concepts. Your program must be deterministic in the sense that if it is run with the same arguments it should produce the same outputs. (So if you want to use \"random numbers\", either set the seed to zero or somesuch at the start or use the index of the file you are creating as the random number/seed.) . The ast.parse, ast.NodeVisitor, ast.NodeTransformer, and astor.to_source portions of the interface are all likely to be quite relevant for this assignment. Mutation Operators . At minimum, you must implement and support the following three mutation activities: . | Negate any single comparison operation type (e.g., &gt;= becomes &lt;). | (You should strongly consider handling more than one comparison type. You have free choice for what you do, if anything, for other “corner-case” booleans such as is or True.) | . | Swap binary operators + and -, as well as * and //. | (You have free choice of which AST node classes are relevant here, such as how or whether you deal with FloorDiv vs. regular division. Any non-empty choice is full credit. You should strongly consider handling more than binary operators as well.) | (You can swap operators “as you like”. The most obvious approach is to swap + with -, and so on, but you can try something more creative if you want to.) | . | Delete an assignment or function call statement (i.e., cause it to have no effect). | (You have free choice of which AST node classes are relevant here. For example, you might decide that ``assignment’’ means Assign, AnnAssign and AugAssign. You may also choose to deal with assignments, function calls, or both. Any non-empty choice is full credit.) | (Other edits that have the “effect” of deleting the assignment or function call but are not “officially” deletion are totally fine and are full credit.) | (Similarly, whether you interpret function call as func() or x = func() or both is up to you.) | . | . Notes: . | Note that you should implement these mutations, but they do not all have to be equally likely &mdash; or even occur at all. For example, you could have code that would correctly swap * to //, but you decide to make it run 0% of the time because you think that will be better for mutation testing. That's fine and full credit: we can see your source code to tell that you completed the assignment, but you get high marks on the autograder by not producing dangerous mutants. | Students are often anxious about adhering to this part of the specification. The quality of your mutation test generator will be assessed automatically by the autograder, regardless of which operators you use. Separately, whether or not you implemented the right operators will be assessed by a human &mdash; a live person who is not out to get you. Any reasonable choice you make here is fine, just document it. Please be reassured. The pedagogical goal is to get you experience with some different AST node types and mutations, not to make sure that you found exactly the AnnAssign vs. AugAssign node types and memorized the difference between them (in fact, we will not test you on any trivia like that, here or on an exam). | Note that implementing those three actions may not be enough to get full points on the autograder, but you do have to implement those three and describe them in your report to get full credit on the report. You may also need to implement more operators or heuristics to get full credit on the autograder. | Note also that you do not have to use all three with the same frequency (or even use them at all &mdash; you could set their probabilities to zero). You do, however, have to implement them as a minimal baseline. | . Mutation Testing . For this assignment we will make use of the FuzzyWuzzy string matching library as a subject program. A version of the library merged into one file is available here; it is 686 lines long. You could also do git clone https://github.com/seatgeek/fuzzywuzzy.git, but the merged-into-one-file version prevents you from having to write a mutator that handles multiple files, and is thus highly recommended. In addition, two public test suites are provided: publictest-full.py and publictest-half.py. The latter was produced by removing every other test from the former. They are thus not independent high-quality test suites, and you are encouraged to make your own higher-quality test suites (e.g., using the techniques from previous homeworks). Recall that one goal of mutation testing is to assess the adequacy of a test suite. We would thus like the automatic results of our mutation testing to agree with our intuitive assessment that the full test suite is of higher quality than the half test suite. Example Mutation Testing Details Here is how an example run might go: $ echo I must run this on the HW0 setup and not on my local machine $ pip3 install pydocstyle # you may need to install other libraries as well $ python3 mutate.py fuzzywuzzy.py 10 $ cp fuzzywuzzy.py saved.py ; for mutant in [0-9].py ; do rm -rf *.pyc *cache* ; cp $mutant fuzzywuzzy.py ; python3 publictest-full.py 2&gt; test.output ; echo $mutant ; grep FAILED test.output ; done ; cp saved.py fuzzywuzzy.py 0.py FAILED (failures=2) 1.py FAILED (errors=24) 2.py 3.py FAILED (errors=35) 4.py FAILED (failures=5) 5.py 6.py FAILED (failures=22, errors=1) 7.py FAILED (failures=1) 8.py 9.py FAILED (errors=40) $ echo I must run this on the HW0 setup and not on my local machine $ cp fuzzywuzzy.py saved.py ; for mutant in [0-9].py ; do rm -rf *.pyc *cache* ; cp $mutant fuzzywuzzy.py ; python3 publictest-half.py 2&gt; test.output ; echo $mutant ; grep FAILED test.output ; done ; cp saved.py fuzzywuzzy.py 0.py 1.py FAILED (errors=11) 2.py 3.py FAILED (errors=17) 4.py FAILED (failures=3) 5.py 6.py FAILED (failures=11) 7.py FAILED (failures=1) 8.py 9.py FAILED (errors=21) . In this example we first create ten mutants. We then run each of those ten mutants against the full test suite, and notice that seven of the mutants are \"killed\" by at least one test (i.e., fail at least one test). Finally, we run each of those mutants against the half test suite, and notice that only six of the mutants are killed. Thus, in this example, the mutation adequacy score for the full suite is 0.7 and the mutation adequacy score for the half suite is 0.6, so mutation testing has assigned test suite qualities that order the test suites in a way that matches our intuition. (If you see warnings like zsh: no matches found: *.pyc, there are two things to do. First, you are required to to use HW0 for the coding assignments, not a local machine. Second, double-check what is happening inside that long command that starts with cp. Unless you understand all of the sub-parts of it, you will not be able to interpret the warnings. Review HW0 or outside resources for more information on complex shell commands.) . (If you don't ever see FAILED when you run this locally, it typically means that your local installation doesn't have some Python libraries or modules installed. View the contents of the file test.output for more information.) . In the example above, note FAILED (failures=22, errors=1). The distinction between \"failures\" and \"errors\" is made by Python's Unit Testing framework and does not matter for our grading. Basically, a \"failure\" refers to failing the unit test while an \"error\" refers to any other exception. You are likely doing a better job if you get all failures and no errors, but our grading server just looks for FAILED (which includes both). See Python's Documentation for more information. Ten mutants is not a large number for randomized testing. We could gain additional confidence by using a larger sample: $ cp original_saved_fuzzywuzzy.py fuzzywuzzy.py $ python3 mutate.py fuzzywuzzy.py 100 $ echo I must run this on the HW0 setup and not on my local machine $ cp fuzzywuzzy.py saved.py ; for mutant in [0-9]*.py ; do rm -rf *.pyc *cache* ; cp $mutant fuzzywuzzy.py ; python3 publictest-full.py ; done &gt;&amp; test.output ; grep FAILED test.output | wc -l ; cp saved.py fuzzywuzzy.py 46 $ cp fuzzywuzzy.py saved.py ; for mutant in [0-9]*.py ; do rm -rf *.pyc *cache* ; cp $mutant fuzzywuzzy.py ; python3 publictest-half.py ; done &gt;&amp; test.output ; grep FAILED test.output | wc -l ; cp saved.py fuzzywuzzy.py 38 . In the example above, 46 of the mutants are killed by the full suite but only 38 are killed by the half suite. Held-Out Test Suites . Writing a mutation analysis that can tell high-quality test suites from low-quality test suites is the purpose of this assignment. If we give too many details about the held-out test suites there is a significant danger that students will \"overfit\" their answers, making something that satisfies the autograder rather than something that imparts useful software engineering knowledge. As a result, we intentionally give only vague information about what is in the held-out test suites: . | Test Suites A, B, C, D and E have 92%, 91%, 90%, 88% and 79% statement coverage of fuzzywuzzy, respectively. Test Suites A, B, C, D and E have 80, 57, 47, 32 and 9 tests, respectively. Remember that statement coverage is not the \"right answer\" or \"gold standard\" here, it is a cheap approximation. | Swapping Binary Operators can help distinguish Test Suites A and B from Test Suites C, D and E. | Swapping Comparison Operators can help distinguish between Test Suites B, C, D and E. | Deleting Assignments and Function Calls can, in theory, distinguish between all Test Suites, but is most likely to tease apart C, D and E. With care, it can also distinguish A from B. | Careful Higher-Order Mutation can help distinguish between Test Suites B, C and D. | Your Creativity may be help distinguish between Test Suites A and B. (Figuring this out is part of the assignment.) Test Suite A contains over 20 tests not found in B. | Remember that increasing the odds of one mutation operator also effectively reduces the odds of the others (since you can only produce a fixed number of mutants) &mdash; if you are not careful, you may see your results oscillate. Similarly, every invalid mutant you create (search for pylint below) hurts you here &mdash; some students report that not creating invalid mutants allowed them to distinguish between Suites A and B. | . The most common student questions for this assignment are along the lines of \"I'm not sure how to improve my score on the autograder. My mutation analysis cannot tell test suites X and Y apart &mdash; it gives them the same score. What's in those tests? What should I do?\" We explicitly will not tell you more that what you see on this page. Using the Library &mdash; Visitor Patterns and Starter Code . A very common source of student confusion relates to how the AST library is structured. It uses a visitor pattern, a way of structuring and interfacing code. Such \"design patterns\" should have been covered in your undergraduate software engineering class (for example, I spend one lecture on them in CS 490). This section is designed to assist students who aren't already familiar with the visitor pattern. A visitor pattern provides abstraction and modularity by hiding from you the exact fields and way in which a data structure is traversed or transformed. (This allows the library writer to change the internal representation of the data structure later, such as to move from Python 2 to Python 3 or whatever, without all of the client code needing to update.) . The following \"starter code\", adapted from wrap_integers.py online, may be useful to students who are not as familiar with visitor patterns. If you find yourself wondering \"How can I tell if this node is a number or a function call?\" or \"How can I change this node's value?\", double-check the starter code. Click to show starter code # This \"Starter Code\" shows how to use a visitor # pattern to replace nodes in an abstract syntax tree. # # Note well: # (1) It does not show you how to read input from a file. # (2) It does not show you how to write your resulting source # code to a file. # (3) It does not show you how to \"count up\" how many of # instances of various node types exist. # (4) It does not show you how to use random numbers. # (5) It does not show you how to only apply a transformation # \"once\" or \"some of the time\" based on a condition. # (6) It does not show you how to copy the AST so that each # mutant starts from scratch. # (7) It does show you how to execute modified code, which is # not relevant for this assignment. # # ... and so on. It's starter code, not finished code. :-) # # But it does highlight how to \"check\" if a node has a particular type, # and how to \"change\" a node to be different. import ast import astor class MyVisitor(ast.NodeTransformer): \"\"\"Notes all Numbers and all Strings. Replaces all numbers with 481 and strings with 'SE'.\"\"\" # Note how we never say \"if node.type == Number\" or anything like that. # The Visitor Pattern hides that information from us. Instead, we use # these visit_Num() functions and the like, which are called # automatically for us by the library. def visit_Num(self, node): print(\"Visitor sees a number: \", ast.dump(node), \" aka \", astor.to_source(node)) # Note how we never say \"node.contents = 481\" or anything like # that. We do not directly assign to nodes. Intead, the Visitor # Pattern hides that information from us. We use the return value # of this function and the new node we return is put in place by # the library. # Note: some students may want: return ast.Num(n=481) return ast.Num(value=481, kind=None) def visit_Str(self, node): print(\"Visitor sees a string: \", ast.dump(node), \" aka \", astor.to_source(node)) # Note: some students may want: return ast.Str(s=481) return ast.Str(value=\"SE\", kind=None) # Instead of reading from a file, the starter code always processes in # a small Python expression literally written in this string below: code = \"\"\"print(111 + len(\"hello\") + 222 + len(\"goodbye\"))\"\"\" # As a sanity check, we'll make sure we're reading the code # correctly before we do any processing. print(\"Before any AST transformation\") print(\"Code is: \", code) print(\"Code's output is:\") exec(code) # not needed for this homework... print() # Now we will apply our transformation. print(\"Applying AST transformation\") tree = ast.parse(code) tree = MyVisitor().visit(tree) # Add lineno &amp; col_offset to the nodes we created ast.fix_missing_locations(tree) print(\"Transformed code is: \", astor.to_source(tree)) co = compile(tree, \"&lt;ast&gt;\", \"exec\") print(\"Transformed code's output is:\") exec(co) # not needed for this homework... The output may look something like (but don’t panic if yours is a little different): . $ python3 starter.py Before any AST transformation Code is: print(111 + len(\"hello\") + 222 + len(\"goodbye\")) Code's output is: 345 Applying AST transformation Visitor sees a number: Constant(value=111, kind=None) aka (111) Visitor sees a string: Constant(value='hello', kind=None) aka \"\"\"hello\"\"\" Visitor sees a number: Constant(value=222, kind=None) aka (222) Visitor sees a string: Constant(value='goodbye', kind=None) aka \"\"\"goodbye\"\"\" Transformed code is: print(481 + len('SE') + 481 + len('SE')) Transformed code's output is: 966 . Hints, Advice and Doing Well . Many students report that they find it easy to get a few points on this assignment but hard to get a high score. That is, it is hard to write a mutate.py that produces mutants that rank-order the high- and low-quality test suites. If you find that your program is not producing enough high-quality mutants to assess the adequacy of a test suite, consider the hints and tips below: . Hints and Tips . | Try making a high-quality test suite locally and evaluating against it. The privatetest-a.py file is just a file that the instructor created that has a bunch of tests for fuzzywuzzy in it. The other test suites were just that test suite with many test cases removed. After the previous homeworks, you know a bunch of good ways to make a high quality test suite. You could do all of this yourself. The advantage of doing it yourself is that you can try things out “locally” as often as you want without hitting the submission limit. | Take a look at the mutation scores you are receiving from the autograder. If many of them are very high (e.g., around 80 or more) you are likely using mutation operators that are “too powerful” and are creating mutants that are killed by every test suite. If they are too low (e.g., around 20) you are likely using mutation operators that are too weak. | Make sure you actually have a chance of mutating every relevant node. For example, if you decide that your nth mutant will delete the nth statement in the original and you are asked to create 10 mutants for a 20-statement program, you will never touch the second half of the statements. (Doing this correctly may require you to count the number of relevant items before making any mutations.) | Consider carefully the number of mutation operators you apply to create a mutant. If you apply too few the mutant will not be killed by any tests. If you apply too many, the mutant will be killed by every test. In both cases such a mutant will not help to distinguish between high- and low-quality test suites. | You may want to implement additional mutation operators. See Section II.b of Jia and Harman’s An Analysis and Survey of the Development of Mutation Testing for ideas. | Thought question. Suppose your program is just one main method with a few if statements. Would you rather mutate the straight-line code at the beginning of the method, or a statement deeply nested inside some conditionals? Recall that your goal is to have the mutant killed by strong test suites but not weak ones. | . You may want to avoid generating “useless” or “stillborn” mutants, such as those that do not parse, always exit with an error, are equivalent to a previously-generated mutant, etc. See Sections III and IV of the Jia and Harman survey for ideas. Here are some common student pitfalls. You should check locally to see if you are making any of these. | Not running pylint! After creating your mutants, you can just run pylint -E [0-9]*.py. Change your mutation operations to minimize the number of linting errors reported. (Run pylint on its own, not inside some other shell script that is piping output somewhere.) . | Creating Python programs with bad indentation. Be careful about deletions. Since Python cares about indentation and the like, just removing something entirely can mess up the rest of the program. Perhaps instead of removing something you may want to replace it with a statement that has no effect, such as Expr(Num(1))? . | Creating Python programs that reference variables before those variables are defined. Hack: what if you kept track of the first time each variable was mentioned and never deleted the first instance and also never copied a reference before its first mention? . | Removing or changing something that looks like a function call, but isn’t really, such as the @functools.wraps(func) annotation on line 53. Take into account context and value when changing such nodes. | Mistakenly sharing the tree data structure between mutants and ending up with more edits than you thought. Try using something like ast = copy.deepcopy(original_ast) to make a deep copy.&lt;/li&gt; . | Flipping a coin at each statement to decide whether or not to mutate it. This is problematic, because you’ll end up with some mutants with 0 edits and some with 100. Instead, try fixing a budget in advance (e.g., “this time we will do 2 mutations”) and then choosing random places to apply them. | Spending too much time enumerating many possible mutations or mutation locations first. You will likely hit the timeout on the autograder — find a faster way to make a choice at random. | . HW6b &mdash; Written Report . You must also write a short three-paragraph PDF report reflecting on your experiences creating a mutation testing tool for this assignment. Your report must include your University email address(es). Consider addressing topics such as: . | Which mutation operators did you implement? | How does your program decide which operators to apply? | What was harder than you expected or different than you expected? | How would you compare and contrast mutation analysis with statement coverage as a test suite adequacy metric. | . Rubric: . | 5 points — a three-paragraph report reflecting on your activities creating a mutation testing tool for this assignment, including a discussion of mutation operators and your experiences and expectations | 4 points — a reasonable report, but lacking a solid description of one or more aspects or being rote rather than insightful or significantly exceeding the length limit | 3 points — a brief report, detailing only half of the required information | 2 points — a report drawing only the bare minimum of contrasts comparisons, and explanations | 1 point — a terse or uninformative report, perhaps describing only one activity or operator&lt; | -1 point (or more) — submitted source code does not implement the require operators (even loosely) | -1 point — English prose or grammatical errors | . The grading staff may select a small number of excerpts from particularly high-quality or instructive reports and share them with the class. If your report is selected you will receive extra credit. Submission . Submit a single mutate.py file to the autograder on Gradescope. Submit a single PDF report via Canvas. In your PDF report, you must include your name and NJIT UCID (as well as your partner's name and UCID, if applicable). For the autograder submission, we have manually prepared a number of private (i.e., held-out) test suites of known quality. For example, Private Test Suite A is known to be better than Private Test Suite B. You receive points if your mutant adequacy score shows that A is is better than B (i.e., if A kills more of your mutants than B). We check \"A &gt; B\" and \"A &gt;= B\" separately; the former is worth more points. While there are visible tests with private content (in that you don't get to see what they contain), there are no hidden tests (here or on any other homework in this course), so the score you see on the Autograder is your final score. Note that the autograder will reject your submission (and give you a score of zero) if your mutate.py does any of the following: . | crashes while producing mutants | does not produce the requested number of mutants or does not name the mutants as specified above | produces a “mutant” that is identical to the input program (that is, containing no mutations) | . You will be graded based on your highest autograder score from all submissions that you make. Note however that there is a soft limit of 5 autograder submissions per 24 hour period: we don’t want you to “play the lottery” by e.g., trying different random seeds. This limit is not enforced automatically, but we can see how many submissions that you’ve made on Gradescope; we’ll investigate any cases with unusually high numbers of submissions (in practice, this means as long as you are not abusing the autograder, you don’t need to keep track of this limit: if you accidentally make six submissions in 23 hours and 59 minutes, nothing bad will happen.). If you did egregiously violate this limit, your grade may be reduced as we see fit. If you egregiously violate this limit accidentally (i.e., you find this text just after spending an hour making submission after submission), contact the course staff immediately: while we may assess a penalty, we’ll look much more kindly on it if you admit your mistake. FAQ and Troubleshooting . In this section we detail previous student issues and resolutions: . | Question: When I try to create mutants, even locally, the to_source function complains. Answer: If you create a Python AST that is missing critical information (like an important tree child, or location information) or otherwise create something totally invalid, the library won't even let you print it out. For example, if you had \"x = y + z\" and you remove the \"z\" node entirely without doing anything else, the library might not even print out the result at all because it is not valid Python. Even something as simple as saying ast.GtE instead of ast.GtE() can cause this. | Question: It feels like the autograder is non-deterministic. I feel like I am submitting the same mutate.py twice and getting different results. Discussion: There are many possible issues here that all result in the same observed symptom. Answer 1: Your mutate.py may be non-deterministic. (This is rare, since student are careful about it.) . Answer 2: Your mutate.py may be creating mutants that are, themselves, non-deterministic. This is much trickier, and happens surprisingly often. Answer 3: Your test automation may be using stale information or cached values. Even with the rm -rf *.pyc *cache*, you may be testing on mutants created by a previous run of mutate.py if you are not careful. Answer 4: There may be differences between the autograder setup and your local setup. For example, the autograder uses export PYTHONHASHSEED=0 to try to determinize the order in which hashmaps are iterated. Discussion: Ultimately, it may not be worth your time to track this down. Remember that we use your best submission, not your last one. Start early. | Question: I am getting erors like TypeError: 'type' object is not subscriptable. Help! . Answer: Double-check the spelling on the AST pieces you are creating or manipulating. For example, use ast.GtE() not the incorrect ast.GtE (note the parentheses, which are required). | Question: When I run locally, I get ImportError: No module named 'astor' . Answer: Make sure you install (again!) with pip3 and python3 rather than pip and python. | Question: I am trying to delete things, but I get this error: assert node is None, node AssertionError: &lt;class '_ast.Pass'&gt; . Answer: You have ast.Pass but want ast.Pass() instead (note the parentheses). However, you may actually not want to \"delete\" things like this at all (look around for other hints). | Question: Is fuzzywuzzy.py being modified? When I run all of my mutants to test them it really looks like fuzzywuzzy is being changed. Answer: Good observation. Your mutate.py does not change it directly, but the example shell script commands we have above do (look for cp which means \"copy\"). Just copy a saved version back over the original. | Question: When I run my mutate.py, I get this error when trying to print out my mutants: \"AttributeError: 'Assign' object has no attribute 'value' \" . Answer: This error occurs when the AST library tries to pretty-print your abstract syntax tree data structure back out to (ASCII) Python source. The AST library expects each node object to have certain fields (properties) filled out. Sometimes a node operation that can look totally reasonable to you (e.g., making a new node, setting it as the child of some other node) can result in a node object not having all of the fields set. If you are changing the types of nodes directly, I would recommend that you instead use their friendly constructors &mdash; that may well end up fixing this problem for you. (This is explicitly a bit of a challenge; dig around first and get used to the AST library before asking for help here.) . | Question: How can I get the parts of an AST node? Suppose I want to figure out the identified on the left-hand side of an assignment: Assign(targets=[Name(id='x', ctx=Store())], value=Num(n=9)) . Answer: Check out the node documentation. In this particular example, some students report success with node.targets[0].id to extract the id from an instance of the the Assign class. Similarly, suppose you want to change the right-hand side of the assignment to \"None\", but leave the left-hand side alone. Have your node transformer do something like: return ast.copy_location(ast.Assign(targets=node.targets, value=ast.NameConstant(value=None)), node) . | Question: I've just started deleting statements, but now I get: AttributeError: module 'string' has no attribute 'strip' . Answer: If you look closely, you'll see that fuzzywuzzy.py has if PY3: string = str on lines 14-15. If you make big changes there you end up changing which module the code will use, which can have far-reaching effects. Be careful! . | Question: I'm getting errors like AttributeError: module 'ast' has no attribute 'Constant' . or AttributeError: 'Classdef' object has no attribute 'starargs' . Answer: The autograder uses Python 3.10.12 with astor version 0.8.1. You'll want to make sure you're using the same versions. | Question: Some online documentation makes a big deal about generic_visit, but I don't really understand it. Can you elaborate? . Answer: To some degree, using it or not is your choice. Suppose you want to change every assignment from \"x = y\" to \"x = y + 1\". In a language like C, you can write \"a = b = 3\". (Don't ever do this.) The interpretation of this statement is that you first assign b=3, and then that result (3 in this case) is also assigned into a. If you do not do the \"generic visit\" thing and instead replace the top-level assignment only, you'll end up with something like this: . a = (b = 3) + 1 . [ After this program, b=3 and a=4. ] . If you do the \"generic visit\" thing and recursively transform the child nodes as well, you'll end up with something like this: . a = (b = 3 + 1) + 1 . [ After this program, b=4 and a=5. ] . Which one do you want? It's your choice. If you have a theory about which one is a better mutation operator, do that. If you don't care, it's safe to default to the full recursive handling of all sub-nodes. | | . | . | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw6.html",
    "relUrl": "/projects/hw6.html"
  },"51": {
    "doc": "Homework 7: Static Analysis with Infer",
    "title": "Homework 7: Static Analysis with Infer",
    "content": "In this assignment you will use a static analysis tool to automatically detect potential defects in three subject programs. The static analysis tool is Facebook’s Infer, which focuses on memory errors, leaks, race conditions, and API issues. Infer is open source. You may work with a partner for this assignment. If you do you must use the same partner for all sub-components of this assignment. Warning: Infer Can Be Hard To Run You should use the setup from HW0 to run Infer. Previous students have reported that Infer does not run on the Windows Subsystem for Linux (WSL) or similar shortcuts for using Ubuntu- or Linux-like interfaces. Headless Virtual Box configurations are reported to work well. Officially, however, the HW0 setup is the (only) supported configuration for the class. It is your responsibility to download, compile, run and analyze the subject program and associated tools. Getting the code and tools to work in some manner is part of the assignment. You can post on the forum for help and compare notes bemoaning various architectures (e.g., windows vs. mac vs. linux, etc.). Ultimately, however, it is your responsibility to read the documentation for these programs and tools and use some elbow grease to make them work. The Static Analysis Tool: Infer . The Infer tool is a static analyzer — it detects bugs in programs without running them. The primary website is fbinfer.com. Unfortunately, some versions of Infer can be obnoxious to build and/or install, despite their handy installation guide. We recommend that you use Infer’s latest binary release, which we have tested on the HW0 setup on the subject programs. While times will vary, some students have reported that running Infer on jfreechart can take five hours. Start early! . You can find Infer’s output in the infer-out folder. First Subject Program: lighttpd Webserver . We will make use of the lighttpd webserver (pronounced \"lighty\"), version 1.4.17, as our first subject program for this homework. A local mirror copy of lighttpd-1.4.17.tar.gz is available, but you can also get it from the original website (but note that the specific version number is important: if you use a more recent version of lighttpd, you may struggle on some parts of the report). It is about 55,000 lines of code in about 90 files. While not as large or popular as apache, at various points lighttpd has been used by YouTube, xkcd and Wikimedia. Much like apache, old verisons of it have a number of known security vulnerabilities. The Common Vulnerabilities and Exposures system is one approach for tracking security vulnerabilities. A CVE is basically a formal description, prepared by security experts, of a software bug that has security implications. There are at least ten CVEs associated with lighttpd 1.4.17 tracked in various lists (such as cvedetails or mitre). For example, CVE-2014-2324 has the description \"Multiple directory traversal vulnerabilities in (1) mod_evhost and (2) mod_simple_vhost in lighttpd before 1.4.35 allow remote attackers to read arbitrary files via a .. (dot dot) in the host name, related to request_check_hostname.\" You can dig into the information listed in, or linked from, a CVE (or just look at subsequent versions of the program where the bug is fixed!) to track down details. Continuing the above example, mod_evhost refers to source file mod_evhost.c, mod_simple_vhost refers to file mod_simple_vhost.c, and request_check_hostname is in file request.c. You will want such information when evaluating the whether or not the tools find these security bugs. Infer on lighttpd . Once you have Infer built or downloaded, applying it to lighttpd should be as simple as: . $ sudo apt install make $ sudo apt install python2-minimal $ sudo apt install zlib1g zlib1g-dev $ cd lighttpd-1.4.17 $ sh configure $ /path/to/infer/bin/infer run -- make . That should produce output similar to (but everything is fine if you get very different numbers): . Lighttpd Output Sample make[1]: Leaving directory '/home/weimer/src/lighttpd-1.4.17' Found 88 source files to analyze in /home/weimer/src/lighttpd-1.4.17/infer-out Starting analysis... legend: \"F\" analyzing a file \".\" analyzing a procedure FFFFFFFFFF.....F...FF....F..FF.F..F....................................................................................FF.................................................F...........F..................F..................F...........................................................................F....................................................................F........................................................F.......F.................F...............F.......FF.............F...................F.............F.........F...F.................F...................................F............FF.F.....F.......................F.....FF..............F..F........FF..........FF.............FF.......FF.F....F......F......FFF..............F.........F...F......F...........F.......FF..........F.F...........F...F..F.......F..F...F........................F..F.........F....F........F.....F..F..........F............F....F...................F................................................................................................................................................ Found 308 issues src/joblist.c:19: error: NULL_DEREFERENCE pointer `srv-&gt;joblist-&gt;ptr` last assigned on line 16 could be null and is dereferenced at line 19, column 2. 17. } 18. 19. &gt; srv-&gt;joblist-&gt;ptr[srv-&gt;joblist-&gt;used++] = con; 20. 21. return 0; ... Summary of the reports NULL_DEREFERENCE: 145 DEAD_STORE: 94 MEMORY_LEAK: 65 RESOURCE_LEAK: 3 QUANDARY_TAINT_ERROR: 1 . (Before you worry about getting different numbers, double-check the prose above: it is fine to get different numbers. Similarly, it is common for this tool to only report a few \"types\" of defects: if you only see a few \"types\" of defects, you are running the tool correctly.) You will have to read through the output carefully and analyze the reported defects. Some will be true positives (i.e., real bugs in the code) and some will be false positives (i.e., spurious warnings that do not correspond to real bugs). Second Subject Program: JFreeChart . The second subject program is the JFreeChart chart creation library. It is used to produce quality charts for a variety of applications and files. It contains about 300,000 lines of Java code spread over about 640 files. We will use JFreeChart version 1.5.0, which is available here. Running Infer on JFreeChart similarly direct to running Infer on lighttpd: . JFreeChart Output Sample $ cd jfreechart-1.5.0 $ /path/to/infer/bin/infer run -- mvn compile Capturing in maven mode... [INFO] Scanning for projects... [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building JFreeChart 1.5.0 ... Found 640 source files to analyze in /home/weimer/src/jfreechart-1.5.0/infer-out Starting analysis..... Found 69 issues src/main/java/org/jfree/data/xml/DatasetReader.java:73: error: RESOURCE_LEAK resource of type `java.io.FileInputStream` acquired to `in` by call to `FileInputStream(...)` at line 72 is not released after line 73. 71. throws IOException { 72. InputStream in = new FileInputStream(file); 73. &gt; return readPieDatasetFromXML(in); 74. } ... Summary of the reports THREAD_SAFETY_VIOLATION: 43 NULL_DEREFERENCE: 22 RESOURCE_LEAK: 4 . Third Subject Program: Your Choice . Run Infer on one other substantial subject program of your choice. The target program must fulfill the following criteria: . | it must be open-source | it must be “substantial”: that is, it must have a real use and not be a toy or example, and it should be reasonably complicated in the sense that you cannot read the whole program easily in one sitting | it should be written in a language supported by Infer | . Otherwise, the choice is up to you. Note, however, that the report will ask you to justify why it is interesting to run Infer on the program that you choose. If you’re unsure of what sort of project to choose, the subject programs from other assignments in this class are a good place to look (although not all subject programs are acceptable: for example, fuzzywuzzy.py from HW6 is not an acceptable choice, because it is not “substantial”). Written Report . Write a detailed report reflecting on your experience running Infer on the three subject programs. Your report must include your NJIT UCID (and your partner’s, if you choose to work in a group). Keep in mind that you need to cite any outside sources that you used during the assignment (besides the tool itself and its documentation). Your report must address at least the following topics: . | [Setup] In a few sentences, describe your setup experience with Infer. This might include dependencies, installation, run time, etc. [1 point for description] | [Usability] In a few sentences, describe your usability experience with Infer. This might include locating the reports, navigating the report or documentation website, etc. You should also contrast your usability experience with Infer versus at least one other tool that we have used in this course (of your choice). [1 point for description, 1 point for contrast, 1 point for insightful analysis] | [Overall] At a high level, what did Infer do well? How might it be improved? Comment on defect report categorizations (e.g., NULL_DEREFERENCE). Did you observe any “duplicate” defect reports (i.e., the same underlying issue was reported in terms of multiple different symptoms)? What are the costs (in general, including developer time, monetary cost, risks, training, etc., and anything else mentioned at any point in class) associated with using Infer? [2 points for overall description, 1 point for categories, 1 point for duplicates, 1 point for costs] | [CVE] Choose two of the CVEs associated with lighttpd. For each CVE, describe whether or not the tool reported the issue associated with the CVE (or would otherwise have pointed you to it). You must choose at least one CVE such that the tool points out the CVE in some manner. Overall, how effective is this tool at finding security defects? [1 point for each CVE, 1 point for conclusion] | [Additional] Briefly describe the additional subject program that you chose. Why might it be interesting to run a static analysis on this program? What sort of defects might you expect to find (or not find), and why? [1 point for description, 1 point for why it would be interesting] | [Comparison] Compare and contrast the defect reports produced for the three subject programs. On which did you find it most useful? Consider false positives, false negatives, and issues that you would consider to have high priority or severity. Include (copy-and-paste, screenshot, etc.) part of one report you found particularly noteworthy (good, bad, complex: your choice) and explain it. [3 point for compare/contrast, 1 point for inlined report and analysis, 2 point for other insights] | . Note that the above grading rubric sums to 20 points, but the assignment is worth 10 points on Canvas. Your score on the assignment is the number of points that you get from the rubric above divided by 2, to normalize effort vs the other homeworks. Students are often anxious about a particular length requirement for this report. Unfortunately, some students include large screenshots and others do not, so raw length counts are not as useful as one might hope. Instead, I will say that in this homework we often see varying levels “insight” or “critical thinking” from students. I know that’s the sort of wishy-washy phrasing that students hate to hear (“How can I show insight?”). But some of the questions (e.g., “what does cost mean in this report?”) highlight places where some students give one direct answer and some students consider many nuances. Often considering many nuances is a better fit (but note that if you make things too long you lose points for not being verbose or readable – yes, this is tough). Let us consider an example from the previous homework. Suppose we had asked you whether mutation testing worked or not. Some students might be tempted to respond with something like “Yes, mutation testing worked because it put test suite A ahead of test suite B, and we know A is better than B because it has more statement coverage.” That’s a decent answer … but it overlooks the fact that statement coverage is not actually the ground truth. (It is somewhat akin to saying “yes, we know the laser range finder is good because it agrees with my old bent ruler”.) Students who give that direct answer get most of the credit, but students who explain that nuance, perhaps finding some other ways to indicate whether mutation testing worked or not, and what that even means, would get the most credit (and will also have longer reports). Students are often concerned about length, but from a grading perspective, the real factor is the insight provided. Submission . Submit a single PDF report via Canvas. You must include your name and UCID (and your partner’s, if applicable). There is no explicit format required. For example, you may use either an essay structure or a point-by-point list of questions and answers, or any other structure that communicates your point. FAQ and Troubleshooting . | Question: When I run infer.exe run -- make or infer run -- mvn compile I get errors like InferModules__SqliteUtils.Error or Maven command failed. Answer: The most common issue is that Infer does not always run well on Windows Subsystem for Linux (WSL) or similar shortcuts to get a Linux- or Ubuntu-like interface on another OS. We strongly recommend a headless Virtual Box setup or a cloud machine (as recommended in HW0). | Question: When I try to run Infer, I get cannot execute binary file: Exec format error.. Answer: One student reports: \"Finally got it. Turns out I was using a 32 bit processor (i386) so even when I set up my vm as 64 bit, it couldn’t run any x86-64 binaries. Fixed it by installing a 64 bit vdi. https://appuals.com/fix-cannot-execute-binary-file-exec-format-error-ubuntu/ | Question: I see Maven command failed: *** mvn compile -P infer-capture when I try to run Infer. Answer: Some students have seen success with: sudo apt-get install cobertura maven sudo apt-get install openjdk-8-jdk . Others reported that \"I ended up having to setup an Ubuntu VM in VirtualBox\". | Question: When I try to run Infer on JFreeChart, I get a `Compilation failure` including the following text (but compilation succeeds if I try to just run `mvn compile` on its own): Usage Error: *** Maven command failed: *** mvn compile -P infer-capture *** exited with code 1 . Answer: The problem is usually that there is a Java Runtime Environment (JRE) installed on your machine, but not a Java Development Kit (JDK). Try running `which javac`; if you get no output, then you need to install a JDK. You can install a JDK with `sudo apt-get install openjdk-11-jdk` (or similar for other Java versions). | Question: When I try to run infer on lighttpd, it dies when trying to build the first file with an error like: External Error: *** capture command failed: *** make *** existed with code 2 Run the command again with `--keep-going` to try and ignore this error. Answer: Some students have reported that starting over and being careful to run all of the commands resolved this issue. It may be caused by missing some required command from the instructions. | Question: When I try to run infer, I get some output but then Fatal error: out of memory. What can I do? . Answer: You may need to assign your virtual machine more memory (see HW0 for setup). You may also need to choose a different subject progam. Some students have reported this when analyzing cpython &mdash; perhaps a different program would work for you. | Question: When I try to run infer on libpng, it dies when trying to build the first file with an error like: External Error: *** capture command failed: *** make *** existed with code 2 Run the command again with `--keep-going` to try and ignore this error. Answer: One student reported that being careful to install all of the required build utilities, such as with this exact sequences, resolved the issue: sudo apt install make sudo apt install python-minimal . | Question: When I try to run infer on a program (e.g., lighttpd), it seems to produce no reports or output when I run infer run -- make. Instead, if I look very carefully at the output, hidden near the bottom is a warning like: ** Error running the reporting script: . Answer: You must have your directories set up so that infer/bin/infer is \"next to\" other files like infer/lib/python/report.py. Infer uses those extra scripts to actually generate human-readable reports. If you tried to copy the infer binary somewhere else, it won't work. Make sure you have all of the components of infer in consistent locations. | Question: I'm not certain why \"false positives\" and \"false negatives\" are relevant for comparing the tools. I'm also not certain how we tell if something is a false positive or a false negative. Can you elaborate? . Answer: We can elaborate a bit, but I will note that this aspect of the assignment is assessing your mastery of course concepts. That is, why false positives and false negative might be important, and how to distinguish between them, are critical software engineering concepts and might come up on exams as well. You may want to double-check your notes on these, including on the readings. Now for more detail: . Suppose you are able to determine the false positive rate of one tool &mdash; or approximate it. For example, suppose you find that Tool #1 produces twice as many false positives as Tool #2. Well, then you might combine that with some of the reading for the class. For example, this week's FindBugs reading notes \"Our ranking and false positive suppression mechanisms are crucial to keeping the displayed warnings relevant and valuable, so that users don’t start ignoring the more recent, important warnings\" (among other comments on false alarms), while another (not assigned, but interesting nonetheless!) similar paper notes \"False positives do matter. In our experience, more than 30% easily cause problems. People ignore the tool. True bugs get lost in the false. A vicious cycle starts where ...\" among other comments on false alarms. Something similar could be considered for false negatives. To give a prose example rather than a reading list this time, a report might include a claim like: \"Many developers will dislike a tool that claims to find Race Conditions but actually misses 99% of them. If the tool has that many false negatives, developers will feel they cannot gain confidence in the quality of the software and will instead turn to other techniques, such as testing, that increase confidence in quality assurance.\" I'm not saying that is a good or a bad argument, but it is an example of the sort of analytic text or line of reasoning that might be applicable here. Students often wonder: \"How do I know if the tool is missing a bug?\" Unfortunately, that's a real challenge. There are at least two ways students usually approach that problem, and both require labor or effort. Similarly, determining if a report is a false alarm usually requires reading it and comprehending the code nearby. I can't really say much more here without giving away too much of what we expect from you on this part of the assignment, but I can reiterate the soundness and completeness (false positives and false negatives) are significant concepts in this course and that you should include them, coupled with your knowledge of the human element of such tools, in your assessment of the tools. | . | . | . | . | . | . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw7.html",
    "relUrl": "/projects/hw7.html"
  },"52": {
    "doc": "Homework 8: Abstract Interpretation Design",
    "title": "Homework 8: Abstract Interpretation Design",
    "content": "Complete Exercise 29 from the reading. The text of the exercise is copied below for your convenience: . Give an abstract interpretation that catches possible divide-by-zero errors statically. You do not need to give transfer functions for every integer operation; addition, multiplication, and division will suffice. Think carefully about your choices; the design space is quite large! You may assume that (1) we only care about integers (not floating-point values), and (2) overflow does not happen. Briefly contrast your design to an alternative you chose. Describe one way in which your design is better than the alternative, and one way in which it is worse. Submit a single PDF which answers this prompt to the HW8 assignment on Canvas. As usual, cite any outside sources that you used in your work. Unlike prior homework assignments, this assignment is explicitly individual: you may not work with a partner. HW9 builds on this assignment: you will not be able to complete HW9 unless you have completed HW8. Therefore, you will automatically receive a zero on HW9 if you have not had your HW8 submission graded. For this reason, we will accept late submissions for HW8 until the HW9 deadline (you will receive feedback but not credit if you turn in HW8 late). We will try to provide feedback within 24 hours on late HW8 submissions, but you should really submit it on-time instead :) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw8.html",
    "relUrl": "/projects/hw8.html"
  },"53": {
    "doc": "Homework 9: Abstract Interpretation Implementation",
    "title": "Homework 9: Abstract Interpretation Implementation",
    "content": "Complete Exercise 30 from the reading. The text of the exercise is copied below for your convenience: . Implement your design (or a simplified version of it, as stated above) for integer division in Java. You can find skeleton code and detailed instructions here: https://github.com/kelloggm/div-by-zero-checker/blob/master/INSTRUCTIONS.md. Please fork this repository, and submit a link to your forked repository, which contains your implemented analysis. Submit a text file with the link to your fork of the repository. We will grade the last commit that you make before the deadline, so you can upload this file even before you’re done. In your submitted text file, cite any sources that you used (as usual). You may (but are not required to) make your fork a private repository. If you do, invite both members of the course staff to the repository; our GitHub usernames are @kelloggm and @thoriumrobot. Unlike prior homework assignments, this assignment is explicitly individual: you may not work with a partner. This assignment builds on HW8: you will not be able to complete HW9 unless you have completed HW8. Therefore, you will automatically receive a zero on HW9 if you have not had your HW8 submission graded. For this reason, we will accept late submissions for HW8 until the HW9 deadline (you will receive feedback but not credit if you turn in HW8 late). We will try to provide feedback within 24 hours on late HW8 submissions, but you should really submit it on-time instead :) . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/hw9.html",
    "relUrl": "/projects/hw9.html"
  },"54": {
    "doc": "Homeworks",
    "title": "Homeworks",
    "content": " ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/projects/",
    "relUrl": "/projects/"
  },"55": {
    "doc": "Staff",
    "title": "Course Staff",
    "content": " ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/staff/#course-staff",
    "relUrl": "/staff/#course-staff"
  },"56": {
    "doc": "Staff",
    "title": "Instructors",
    "content": "Martin Kellogghe/him . martin.kellogg@njit.edu . Office Hours: by appointment. To schedule an appointment with me, check my calendar and add a calendar event in any open spot that works for you during regular business hours (Monday to Friday, 9:30-6:00). You must schedule meetings at least 24 hours in advance, or I will automatically decline them. In your invitation, you must, at a minimum, 1) invite me to the event, 2) add a note to the event description that mentions CS 684 and what you’d like to meet about, and 3) specify whether you would prefer the meeting to be in-person or remote. It is unprofessional to schedule a meeting with me unless you have exhausted your other options to solve the issue (for example, don’t schedule a meeting with me about a homework issue until you have tried to solve the issue yourself, asked on Discord, attended a TA’s office hours and asked there, or ideally all of the above). ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/staff/#instructors",
    "relUrl": "/staff/#instructors"
  },"57": {
    "doc": "Staff",
    "title": "Teaching Assistants",
    "content": "Kazi Siddiquihe/him . ks225@njit.edu . Office Hours: Mondays 3:30-5:00PM, online . ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/staff/#teaching-assistants",
    "relUrl": "/staff/#teaching-assistants"
  },"58": {
    "doc": "Staff",
    "title": "Staff",
    "content": " ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/staff/",
    "relUrl": "/staff/"
  },"59": {
    "doc": "Tutorials",
    "title": "Tutorials",
    "content": " ",
    "url": "/~martinjkellogg.com/teaching/cs684-sp24/tutorials/",
    "relUrl": "/tutorials/"
  }
}
