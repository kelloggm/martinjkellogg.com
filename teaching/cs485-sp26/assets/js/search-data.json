{"0": {
    "doc": "CS 485/698 AI-Assisted Software Engineering (Sp26)",
    "title": "CS 485: AI-Assisted Software Engineering",
    "content": "Modern generative artificial intelligence tools are astonishingly effective at generating code, given natural language specifications. The software engineering industry is rapidly adopting these tools to improve engineers’ productivity: instead of writing all of their code themselves, many engineers are now effectively “team leaders”, managing a “team” of artificial intelligence tools. In this course, students will get hands-on experience in using such artificial intelligence tools for software engineering in a semester-long course project. Topics will include agents, requirements elicitation and specification in the AI era, AI code generation and how to ensure that AI-generated code is correct, and discussions of how other traditional software engineering practices like code review and static analysis can help with AI-assisted software engineering. The course meets on Mondays and Wednesdays at 11:30am. The course is open to students at all levels: bachelor’s, master’s, and PhD. Graduate students will be expected to engage with current research in the topic; see this description in the syllabus for the specific requirements for graduate students. On this website, you can find: . | the syllabus, | a course calendar (which includes links to the required readings and all assignment due dates), | links to assignment descriptions for the course project and individual reflection essays, | a staff page, and | useful tutorials. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/#cs-485-ai-assisted-software-engineering",
    "relUrl": "/#cs-485-ai-assisted-software-engineering"
  },"1": {
    "doc": "CS 485/698 AI-Assisted Software Engineering (Sp26)",
    "title": "CS 485/698 AI-Assisted Software Engineering (Sp26)",
    "content": ". ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/",
    "relUrl": "/"
  },"2": {
    "doc": "A1: LLMs for Code Experience Reflection",
    "title": "A1: LLMs for Code Experience Reflection",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience vibe coding programs from scratch, use LLMs to modify existing code, and using LLMs to help you understand how the codebase works. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This assignment is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a1.html",
    "relUrl": "/assignments/a1.html"
  },"3": {
    "doc": "A2: Requirements Engineering Reflection Essay",
    "title": "A2: Requirements Engineering Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing user discovery, creating user stories, or create development specifications using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a2.html",
    "relUrl": "/assignments/a2.html"
  },"4": {
    "doc": "A3: Frontend Development Reflection Essay",
    "title": "A3: Frontend Development Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing frontend development using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a3.html",
    "relUrl": "/assignments/a3.html"
  },"5": {
    "doc": "A4: Backend Development Reflection Essay",
    "title": "Submission",
    "content": "Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a4.html#submission",
    "relUrl": "/assignments/a4.html#submission"
  },"6": {
    "doc": "A4: Backend Development Reflection Essay",
    "title": "A4: Backend Development Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing backend development using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a4.html",
    "relUrl": "/assignments/a4.html"
  },"7": {
    "doc": "A5: Testing Reflection Essay",
    "title": "A5: Testing Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing testing using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a5.html",
    "relUrl": "/assignments/a5.html"
  },"8": {
    "doc": "A6: Deployment Reflection Essay",
    "title": "A6: Deployment Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience deploying a system to production using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a6.html",
    "relUrl": "/assignments/a6.html"
  },"9": {
    "doc": "A7: Special Topic Reflection Essay (Graduate Students Only)",
    "title": "A7: Special Topic Reflection Essay (Graduate Students Only)",
    "content": "This is an individual assignment. Learning Goals . Read a paper about an interesting way to use an LLM in software engineering and try it out yourself. Reflect on your experience. The task . Write a 1000-word essay on a reflection question of your choice from this Google Sheet. Only one class member may choose each reflection question. Write your name down in the sheet next to the question you have chosen. Each question is based on one of the “special topic” readings throughout the semester. You should read the “special topic” article in detail. Then, you should try to replicate something discussed in the reading yourself, using your own LLM. For example, if the article is about using LLMs for code review, you should spend some time trying to use an LLM to review a change to an existing codebase. It’s up to you exactly how you interpret this requirement, but your essay should clearly explain what you did and why. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Unlike the other reflection essays, for this one only one student will answer each question. You will be called on in class to describe how you answered the question, so you should be prepared for that. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 200 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 900-1100 words. 10 pts. | Essay answers your reflection question. 35 pts. | Essay shows that you have read and reflected on the article. 50 pts. | Essay clearly describes what you did to test out the article’s claims and why. 50 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 50 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a7.html",
    "relUrl": "/assignments/a7.html"
  },"10": {
    "doc": "Syllabus",
    "title": "Syllabus",
    "content": "Modern generative artificial intelligence tools are astonishingly effective at generating code, given natural language specifications. The software engineering industry is rapidly adopting these tools to improve engineers’ productivity: instead of writing all of their code themselves, many engineers are now effectively “team leaders”, managing a “team” of artificial intelligence tools. In this course, students will get hands-on experience in using such artificial intelligence tools for software engineering in a semester-long course project. Topics will include agents, requirements elicitation and specification in the AI era, AI code generation and how to ensure that AI-generated code is correct, and discussions of how other traditional software engineering practices like code review and static analysis can help with AI-assisted software engineering. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/",
    "relUrl": "/about/"
  },"11": {
    "doc": "Syllabus",
    "title": "Prerequisites",
    "content": "Officially, none. Students will be expected to know how to program well enough to understand and debug code generated by an AI tool. Students without significant prior exposure to software engineering concepts (e.g., in CS 490 or an internship) will be expected to do additional background reading. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#prerequisites",
    "relUrl": "/about/#prerequisites"
  },"12": {
    "doc": "Syllabus",
    "title": "Topics",
    "content": ". | How LLMs Work, “Vibe Coding”, and Agents | Requirements Elicitation and Specification in the AI Era | AI Code Generation and Correctness | Frontend Development with LLMs | Backend Development with LLMs | Testing with LLMs | Deployment Strategies | Code Review with LLMs | Static Analysis and LLMs | Traditional Software Engineering Practices in an AI-Assisted Context | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#topics",
    "relUrl": "/about/#topics"
  },"13": {
    "doc": "Syllabus",
    "title": "Grading and Assignments",
    "content": "Your grade is composed of the following sub-scores (in no particular order): . | 50%: Course Project (consisting of 7 sub-assignments, with the final submission worth 25% of the total course grade) | 18%: Reflection Essays | 32%: In-class Activities, Participation, and Professionalism | . This class will be curved: when grading, I prefer to use the whole range available rather than scores in a tight range. That is, if an assignment is worth 10 points, I will give grades at all the points between 0 and 10. I will project your raw scores onto the final distribution once in the middle of the semester; you will be notified of your current projected class grade via email at this point. Programming Projects and Other Assignments . There will be a semester-long course project that will involve a significant software development effort. Students will work in small, self-selected teams. The scale of the project will be intentionally absurd: it will be so much work that no reasonable professor could ask their students to write the code themselves. Instead, students will be expected to use AI models to generate most of the code. The project will involve using LLMs as part of every step of the engineering process, from requirements gathering to coding to testing to deployment. As part of your submission for each assignment, you will be required to submit the logs of all of your interactions with your AI tools. Be sure to keep these logs. This page has information collected by the course staff about how to acquire the necessary logs from different model providers. The course project is broken down into seven sub-assignments, with the final submission being the largest component. Students will also complete several reflection essays throughout the semester, which are designed to encourage critical thinking about the use of AI in software engineering. These essays must be completed without the assistance of AI tools. Textbook . This course has no required textbook. Students will make heavy use of generative AI tools via APIs, so a subscription to one of them is recommended. In particular, a web-based LLM is not sufficient, because students will be expected to run their LLMs in “agentic” loops, where an automated process (e.g., a test suite) provides feedback to the LLM until some condition is met. Student- or free-tier plans are often available. I expect students will need at least one of Claude Code, Cursor, OpenAI Codex, etc. Topic-specific reading materials for software engineering topics (e.g., software architecture, various testing techniques, code review, etc.) will be provided; these will be officially optional, but strongly recommended for students who have not taken CS 490. List of known student plans for AI tools: . | Figma Make | Cursor Pro | TODO: add more as we become aware of them | . Participation &amp; Professionalism . Your participation &amp; professionalism grade is based on your interactions with the instructors and TAs: in-class, on the course discussion forum, in office hours, etc. Remote Participation . Generally this class does not support remote participation: teaching is much more effective, in my experience, when everyone is physically present. However, I understand that sometimes you are sick, traveling, or otherwise unable to come to class. I will arrange for remote participation in any particular lecture as long as you request it at least one hour in advance (if you’re sick or in some other emergency) or 24 hours in advance (if you’re traveling or otherwise planning to be unable to come to class). Notify the instructor via email if you need to participate in a particular class remotely. Asking Questions . There is a course Discord server which you can use to ask (and answer) questions about any of the course topics or for help with the homework. Participating on Discord is optional, but if you do participate in a productive manner (especially by answering other student’s questions!), it will have a positive impact on your participation score. Exams . This course does not have traditional exams. Your understanding will be assessed through your project work, reflection essays, and in-class participation. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#grading-and-assignments",
    "relUrl": "/about/#grading-and-assignments"
  },"14": {
    "doc": "Syllabus",
    "title": "BS vs MS/PhD students:",
    "content": "MS/PhD students will be expected to 1) work in teams only with other MS students, and 2) choose more ambitious course projects. I will also provide a set of readings in the current literature on this topic throughout the semester, called “Special topics readings” on the calendar; for the undergrads, these readings will be optional, but for the graduate students they will be required. I will also require an additional reflective essay from each graduate student on one of the papers from throughout the semester, to be presented to the whole class during one of the last class sessions. Otherwise, all students will be held to the same standards. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#bs-vs-msphd-students",
    "relUrl": "/about/#bs-vs-msphd-students"
  },"15": {
    "doc": "Syllabus",
    "title": "Collaboration Policy",
    "content": "Collaboration is generally encouraged in this course, as is consulting online resources. You are permitted to copy small amounts of code from any source except someone else’s copy of an assignment, as long as you cite your source. “Someone else’s copy of an assignment” also includes students not currently enrolled in the course - e.g., students who took this class in previous semesters or took classes that used similar projects at other institutions. To make this more clear, here are some examples of acceptable and unacceptable collaboration on assignments in this course: . Acceptable collaborations: . | Discuss problems/solutions/anything with any number of other students (as long as you don’t look at each other’s code or text). | Copy a short (about 10 lines or fewer - use your judgment) snippet from stackoverflow.com or a similar source, as long as you include a comment with the source URL. | Copy code written by one of your teammates during a group project for another part of the group project. | Copy code from the output of a generative AI tool such as ChatGPT that you prompted yourself (as long as you include a log of your interaction with your assignment submission). | . Unacceptable collaborations: . | Copy text from another student’s reflection essay. | Copy code from another group on a group project. | Copy any code or text from the internet without citing your source. | Copy code from the output of a generative AI tool (such as ChatGPT) without including a log of your interaction with the AI tool, or otherwise implying that it is your own work. | Copy code from the output of a generative AI tool prompted by someone other than you or your teammates, for the group project. | . These rules are intended to mimic what is acceptable in industry when working as a software engineer: using the resources available to you, such as your teammates and the wider internet, is always allowed. But, it would be illegal to copy code from a competing company working on a similar product. Generative AI Policy . You are permitted (or, sometimes, even required) to use generative AI tools on many assignments in this course. Whenever you do, you are required to include a log of your interaction with the tool: in particular, you must ensure that the course staff has access to both your prompts and the model’s responses while grading. For assignments or parts of assignments where you are explicitly forbidden from using a generative AI tool (e.g., on the reflection essays), using one is a violation of the collaboration policy. The course staff have intentionally limited the number of times that we ask you not to use generative AI tools; please respect it. If you are caught using a generative AI tool for such an assignment, you will at a minimum fail the course. Consequences of Violating the Collaboration Policy . (From the University) . “Academic Integrity is the cornerstone of higher education and is central to the ideals of this course and the university. Cheating is strictly prohibited and devalues the degree that you are working on. As a member of the NJIT community, it is your responsibility to protect your educational investment by knowing and following the academic code of integrity policy that is found at: http://www5.njit.edu/policies/sites/policies/files/academic-integrity-code.pdf. Please note that it is my professional obligation and responsibility to report any academic misconduct to the Dean of Students Office. Any student found in violation of the code by cheating, plagiarizing or using any online software inappropriately will result in disciplinary action. This may include a failing grade of F, and/or suspension or dismissal from the university. If you have any questions about the code of Academic Integrity, please contact the Dean of Students Office at dos@njit.edu” . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#collaboration-policy",
    "relUrl": "/about/#collaboration-policy"
  },"16": {
    "doc": "Syllabus",
    "title": "Late Policy",
    "content": "Most assignments may be submitted late, with an escalating “Fibonacci” penalty for each day beyond the due date. More specifically: . | Days Late | Penalty | . | 1 | 2% | . | 2 | 3% | . | 3 | 5% | . | 4 | 8% | . | 5 | 13% | . | 6 | 21% | . | n | fib(n + 2)% | . “Days Late” is always computed AoE, so if the assignment is due on a Monday and you submit it while it is still Thursday anywhere on Earth (e.g., at 5am Friday in Newark), you will be assessed a 5% penalty (3 days late). The final project submission may not be submitted late, because it is due at the end of the semester. After that point, the course is over and I will be computing final grades. No exceptions to this policy will be made. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#late-policy",
    "relUrl": "/about/#late-policy"
  },"17": {
    "doc": "Syllabus",
    "title": "Research",
    "content": "Your class work might be used for research purposes. For example, we may use anonymized student assignments to design algorithms or build tools to help programmers. Any student who wishes to opt out can contact the instructor or TA to do so after final grades have been issued. This has no impact on your grade in any manner. Students interested in considering undergraduate research should make an appointment with the professor to talk about it. I am happy to discuss independent study projects, paid research work over the summer, research work for credit, graduate school, or any other research related topic. To make an appointment with the professor, send a calendar invitation at a time when my calendar shows that I’m free during “regular business hours” (roughly 9-5, Monday through Friday). Include enough information in the invite so that I know why you want to talk to me. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#research",
    "relUrl": "/about/#research"
  },"18": {
    "doc": "Syllabus",
    "title": "Acknowledgments",
    "content": "This course is inspired by and indebted to similar courses offered at other institutions, including those at the University of Washington, University of Virginia, University of Maryland, and Carnegie Mellon University. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#acknowledgments",
    "relUrl": "/about/#acknowledgments"
  },"19": {
    "doc": "Assignments",
    "title": "Assignments",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/",
    "relUrl": "/assignments/"
  },"20": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/",
    "relUrl": "/calendar/"
  },"21": {
    "doc": "Calendar",
    "title": "Week 1",
    "content": "Mon Jan 19 No class, MLK day Wed Jan 21 Introduction Mandatory reading: the syllabus ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-1",
    "relUrl": "/calendar/#week-1"
  },"22": {
    "doc": "Calendar",
    "title": "Week 2",
    "content": "Mon Jan 26 LLM Code Generation: Modifying an Existing Codebase Mandatory reading: Willison’s 2025: The year in LLMs Before class on Jan 28 Reflection essay on experience w/ LLM code generation due Wed Jan 28 LLM Code Generation: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-2",
    "relUrl": "/calendar/#week-2"
  },"23": {
    "doc": "Calendar",
    "title": "Week 3",
    "content": "Sun Feb 1 Project team declaration due Mon Feb 2 Requirements Engineering: User Discovery Lab Mandatory reading: Synthetic Users: If, When, and How to Use AI-Generated “Research” Background reading: The Mom Test by Rob Fitzpatrick. (Note: this is a book; it costs $10. You’re not required to read this, but you should be familiar with the ideas in it before class.) . Special topics reading: Analysis of LLMs vs Human Experts in Requirements Engineering . Wed Feb 4 Requirements Engineering: Creating Effective User Stories Background reading: INVEST in Good Stories, and SMART Tasks Special topics reading: When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-3",
    "relUrl": "/calendar/#week-3"
  },"24": {
    "doc": "Calendar",
    "title": "Week 4",
    "content": "Sun Feb 8 Project requirements doc due Mon Feb 9 Requirements Engineering: Creating Dev Specs Mandatory reading: Development Spec Guidelines Background reading: How To Be A Program Manager and Design Docs at Google . Special topics reading: Aligning Requirement for Large Language Model’s Code Generation . Before class Feb 11 Reflection essay on requirements gathering w/ LLMs due Wed Feb 11 Requirements Engineering: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-4",
    "relUrl": "/calendar/#week-4"
  },"25": {
    "doc": "Calendar",
    "title": "Week 5",
    "content": "Sun Feb 15 Project specification doc due Mon Feb 16 Frontend: Introduction Mandatory reading: TBD Special topics reading: Inside Out: Uncovering How Comment Internalization Steers LLMs for Better or Worse . Wed Feb 18 Frontend: Creating the UI Code Reading: TBD ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-5",
    "relUrl": "/calendar/#week-5"
  },"26": {
    "doc": "Calendar",
    "title": "Week 6",
    "content": "Mon Feb 23 Frontend: Creating UI Behaviors Mandatory reading: Good Vibrations? A Qualitative Study of Co-Creation, Communication, Flow, and Trust in Vibe Coding Before class on Feb 25 Reflection essay on LLMs for frontend dev due Wed Feb 25 Frontend: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-6",
    "relUrl": "/calendar/#week-6"
  },"27": {
    "doc": "Calendar",
    "title": "Week 7",
    "content": "Sun Mar 1 Project frontend code initial submission due Mon Mar 2 Backend: Coding Lab Mandatory reading: TBD Special topics reading: A Causal Perspective on Measuring, Explaining and Mitigating Smells in LLM-Generated Code . Wed Mar 4 Backend: Notifications Special topics reading: Smoke and Mirrors: Jailbreaking LLM-based Code Generation via Implicit Malicious Prompts ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-7",
    "relUrl": "/calendar/#week-7"
  },"28": {
    "doc": "Calendar",
    "title": "Week 8",
    "content": "Mon Mar 9 Backend: Understanding Backends Special topics reading: From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging Before class on Mar 11 Reflection essay on LLMs for backend dev due Wed Mar 11 Backend: Discussion No reading Fri Mar 13 Project backend code initial submission due Mar 14 to Mar 22 Spring Break, no classes ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-8",
    "relUrl": "/calendar/#week-8"
  },"29": {
    "doc": "Calendar",
    "title": "Week 9",
    "content": "Mon Mar 23 Testing w/ LLMs: Intro Mandatory reading: Software Testing with Large Language Models: An Interview Study with Practitioners Special topic reading: An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software . Wed Mar 25 Testing w/ LLMs: TDD and CI Background reading: The Art of Agile Development: Test-Driven Development Special topic reading: E-Test: E’er-Improving Test Suites . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-9",
    "relUrl": "/calendar/#week-9"
  },"30": {
    "doc": "Calendar",
    "title": "Week 10",
    "content": "Mon Mar 30 Testing w/ LLMs: Mutation Testing Background reading: Mutation Testing Before class on Apr 1 Reflection essay on LLMs for testing due Wed Apr 1 Testing w/ LLMs: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-10",
    "relUrl": "/calendar/#week-10"
  },"31": {
    "doc": "Calendar",
    "title": "Week 11",
    "content": "Sun Apr 5 Project synthetic tests submission due Mon Apr 6 Deployment: Intro Reading: TBD Wed Apr 8 Deployment: Backend Reading: TBD ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-11",
    "relUrl": "/calendar/#week-11"
  },"32": {
    "doc": "Calendar",
    "title": "Week 12",
    "content": "Mon Apr 13 Deployment: CD Reading: TBD Before class on Apr 15 Reflection essay on deployment due Wed Apr 15 Deployment: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-12",
    "relUrl": "/calendar/#week-12"
  },"33": {
    "doc": "Calendar",
    "title": "Week 13",
    "content": "Sun Apr 19 Project deployment due Mon Apr 20 Static analysis + LLMs: Intro Mandatory reading: TBD Special topics reading: PredicateFix: Repairing Static Analysis Alerts with Bridging Predicates . Wed Apr 22 Static analysis + LLMs: Discussion Special topics reading: LLM-Based Repair of Static Nullability Errors ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-13",
    "relUrl": "/calendar/#week-13"
  },"34": {
    "doc": "Calendar",
    "title": "Week 14",
    "content": "Mon Apr 27 Slack or class’ choice Reading: TBD Before class on Apr 29 Reflection essay on special topic due (graduate students only) Wed Apr 29 Special topics discussion + course wrapup No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-14",
    "relUrl": "/calendar/#week-14"
  },"35": {
    "doc": "Calendar",
    "title": "Week 15",
    "content": "Mon May 4 Project presentations No reading Mon May 4 Project final submission + postmortem due ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-15",
    "relUrl": "/calendar/#week-15"
  },"36": {
    "doc": "How to Read a Paper",
    "title": "What is a research paper?",
    "content": "In computer science, original research is typically published at peer-reviewed conferences. Typically these papers have between two and ten authors, and the paper typically reports on about a person-year’s worth of work (though this can vary widely). The authors will be a mix of junior and senior researchers: anyone who contributed something “intellectually significant” to the paper is typically listed as an author. In most CS sub-disciplines (including software engineering, which is the source for most of the “Optional” readings), author order is indicative: the first author is usually the person who did most of the technical work (e.g., implementing the tool, running the experiments, etc.), and the last author is typically the project leader (often, but not always, the first author’s research advisor). Often, but not always, the first author is a PhD student. To be accepted at a peer-reviewed conference, a research paper must be novel: that is, it must contain some new knowledge or evidence that the research community wasn’t aware of before. This requirement impacts how they are written: a research paper must focus on the specific thing that is novel about it, rather than surveying the field as a whole (though you can find “survey” papers that give an overview of a research area, and if you need to know the current state of a sub-field, looking for a survey paper is the way to go). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/reading-papers.html#what-is-a-research-paper",
    "relUrl": "/tutorials/reading-papers.html#what-is-a-research-paper"
  },"37": {
    "doc": "How to Read a Paper",
    "title": "External Resources",
    "content": "I highly recommend Keshav’s How to Read a Paper if you’re not sure where to start. This short (3-page) article gives a specific strategy for attacking a research paper. I recommend Griswold’s How to Read an Engineering Research Paper. This short article is more aimed at PhD students. but it helps to explain how a research paper is structured (and might be useful to you to help understand the anatomy of a research paper). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/reading-papers.html#external-resources",
    "relUrl": "/tutorials/reading-papers.html#external-resources"
  },"38": {
    "doc": "How to Read a Paper",
    "title": "How to Read a Paper",
    "content": "Many of the readings for this course are papers from the research literature. These papers can be intimidating if you haven’t encountered them before. This page contains some suggestions on how to read a research paper, along with links to useful external resources. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/reading-papers.html",
    "relUrl": "/tutorials/reading-papers.html"
  },"39": {
    "doc": "How to Save Logs From Your LLM",
    "title": "How to Save Logs From Your LLM",
    "content": "It is a requirement for all project assignments that you submit logs of all of your interactions with your AI assistant(s), not just the final result. This page contains information about how to gather the required logs from different model providers, but it is ultimately your responsibility to submit the required logs. The logs you submit should include, for every project member: . | a record of each prompt you sent to the model | a record of the model’s output | a record of the results of any tools that the model ran (e.g., if the model ran your project’s tests and looked at the terminal output, you’d need to make sure the terminal output is included in the log) | . The rest of this page is arranged by model provider. If your preferred model provider isn’t present, we encourage you to try to figure out how to get the required logs on your own and then let us know how you did so, so that other students can benefit from your exploration. Google Gemini Code Assist . See this page from Google. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/llm-logs.html",
    "relUrl": "/tutorials/llm-logs.html"
  },"40": {
    "doc": "P0: Choose a Project Team",
    "title": "P0: Choose a Project Team",
    "content": "Submit a text file containing a list of the UCIDs of your proposed project team members, separated by newlines. Everyone on the proposed team must submit the same list. For example, if Michael and Martin want to be team members, both must submit the following text file (order doesn’t matter): . mjk76 cc255 . We will never put two people on the same team unless both named the other in their submission to this assignment. You may work in a team of any size, but the course staff will expect that larger teams will produce projects with larger scopes. For example, if you choose to work with a six-person team, we will expect twice as much work as we’d expect if you chose to work in a three-person team. We recommend teams of size 3 or 4. Teams may split at any time, for any reason, but after you submit this assignment you can never add more team members. For example, if Michael and Martin realize they don’t get along after submitting P3, either one of them can send an email to the course staff requesting that their team be split up. At that point, they’d both be entitled to the work of the group up to that point (i.e., their P1, P2, and P3 submissions, along with their existing codebase up to that point), but they’d be expected to work alone going forward. If you want to split a team that’s larger than two people, you should make an appointment with the course staff to discuss the situation first. In general, our policy is that teams require mutual consent, and that if that consent isn’t present on one side then the team should be broken up. The course staff are not responsible for finding you willing teammates. You are permitted to work alone, if you choose. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p0.html",
    "relUrl": "/projects/p0.html"
  },"41": {
    "doc": "P1: Requirements Engineering",
    "title": "Project 1: Requirements Engineering",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#project-1-requirements-engineering",
    "relUrl": "/projects/p1.html#project-1-requirements-engineering"
  },"42": {
    "doc": "P1: Requirements Engineering",
    "title": "Learning Goals",
    "content": ". | Learn how to do effective user discovery interviews to learn about the problems your users have, how they are willing to have you solve them, and what value they ascribe your solution | Learn how to get an LLM to create sound user stories that accurately reflect your planning goals | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#learning-goals",
    "relUrl": "/projects/p1.html#learning-goals"
  },"43": {
    "doc": "P1: Requirements Engineering",
    "title": "Project Context",
    "content": "You and your team will be spending the rest of the semester building all of the features that are present in the main product of the startup you have chosen. This assignment is intended to help you design a viable imitation of this product. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#project-context",
    "relUrl": "/projects/p1.html#project-context"
  },"44": {
    "doc": "P1: Requirements Engineering",
    "title": "Deliverables",
    "content": "1. Initial value proposition/product description . Please answer the following questions: . | What is the big idea of the startup you have chosen? What problem is it solving? What is its solution? What makes their solution special and distinguishes it from the competition? Do not use an LLM for this part. (1-2 paragraphs) | What is/are the value proposition(s) for your product? Do not use an LLM for this part. (1-2 sentences) | Ask an LLM to describe the value proposition(s) for your product (1-2 sentences). | What is the difference between the human and LLM-generated value propositions? Which one is more compelling? (3-4 sentences) | . Turn-in instructions . | Answers to question 1. (1-2 paragraphs) | The value proposition(s) for your product, written by humans. (1-2 sentences) | The value proposition(s) for your product, written by the LLM. (1-2 sentences) | Describe the difference in the value propositions written by humans and LLMs. Explain which one is more compelling and why. (3-4 sentences) | Turn in your chat log with the LLM. | . 2. Viability analysis: why do people want it? . In these exercises, you’ll collect some initial viability data, and make a plan for collecting more as you build out your project. 2a. Figure out why people want the product . Create a list of 10 questions that will you learn about the problems that people have that could be addressed by the main product of the startup you chose. Heed these lessons from The Mom Test: . | Talk about their life instead of your idea. | Ask about specifics in the past, instead of generic questions or opinions about the future. | . 2b. Measure/demonstrate that people want the product . Have four or more conversations with real people (not LLMs) who are somewhat engaged in your product’s area of focus. For example, if you’re interested in solving pain points around coding apps, all four people should at least know how to code. Use your questions from the prior section as a starter script. However, ask followup questions to discover what problems your interviewees are having. You may record these if you like so you have transcripts to refer back to, but this is not required. You must interview real humans for this assignment. Interviews with LLMs will not be accepted. Recall the lessons you learned in our user discovery class about adapting your question style for the specific personality type in front of you. | Describe where you found these four people and how you talked to them (e.g., formally over zoom, informally in the gym, etc.). | Describe one mistake you made during your discovery conversations, and one exchange that went well (and why). | . 2c. Summarize what you learned . What problems did people have? How were they solving them? What wasn’t a problem? Summarize what you learned from your discovery conversations. What might this mean for the product/focus area/problem of choice? . Optional: If you recorded and transcribed your interviews, you may turn in two summaries. | Summarize the interviews using only human brain power. | Put away your original summary, and then ask the LLM to summarize the lessons you learned from the transcripts. | . Turn-in instructions . Please turn in: . | The 10 interview questions you created. | Your raw notes and transcripts, demonstrating that every group member participated in at least two interviews. | Where you found your four interviewees and how you interviewed them. | One thing that went well and one thing that went poorly in any interview. | The five most useful questions you asked. (1 paragraph) | The five most useful pieces of concrete data you collected. (1 paragraph) | The summary, written by humans, of what you learned about the people you interviewed. (2 paragraphs) | Optional: The summary, written by an LLM, of what you learned about the people you interviewed. Also turn in the LLM chat log. (2 paragraphs) | . 3. User Stories . In this section, you will create user stories that correspond to the primary use cases of the product. However, you may not write the user stories themselves. You have to use an LLM to do this for you. The user stories should be customized by your understanding of the primary use cases of your startup’s main product as well as the lessons you learned from the user discovery exercise above. These may not turn out identical to the product already in production, but that’s ok. With everything we learn here, we can make it better! . | Get an LLM to create 10 user stories for your product. Make sure it uses the proper template: - As a &lt;user&gt;, I want &lt;action&gt; so that &lt;benefit&gt;. - Have the LLM add an explanation of what each user story is really about. - Have the LLM estimate each user story’s size as a t-shirt (Small, Medium, Large, Xtra-Large) - Be sure to tell the LLM that each user story must fit integrally into a 2-week sprint. | Ask the LLM to evaluate the user stories according to the INVEST framework we learned in class. - Throw out the 5 lowest ranked user stories. | Have the LLM to prioritize the remaining 5 user stories into a product backlog. Ask it to assign the user stories to be accomplished to one of the next 5 2-week-long sprints (10 weeks of work). | . Turn-in instructions . Please turn in: . | The original list of 10 user stories. | The five user stories that were eliminated and what reason the LLM gave (and you agreed with) for dropping them. (1 paragraph each) | List the top five user stories that you kept, in the order that they were assigned to sprints, and for each one, answer why it this the right story to work on and why do it in the sprint it was assigned to? (1 paragraph each) | The chat log from all LLM interactions you had in doing this work. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#deliverables",
    "relUrl": "/projects/p1.html#deliverables"
  },"45": {
    "doc": "P1: Requirements Engineering",
    "title": "P1: Requirements Engineering",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html",
    "relUrl": "/projects/p1.html"
  },"46": {
    "doc": "P2: Development Specification",
    "title": "Project 2: Development Specification",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#project-2-development-specification",
    "relUrl": "/projects/p2.html#project-2-development-specification"
  },"47": {
    "doc": "P2: Development Specification",
    "title": "Learning Goals",
    "content": ". | Learn how to translate user stories into a structured development specification. | Learn how to guide an LLM to generate architecture diagrams, class diagrams, flow charts, and other technical artifacts. | Learn how to critically assess risks, interfaces, and technologies when planning software implementation. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#learning-goals",
    "relUrl": "/projects/p2.html#learning-goals"
  },"48": {
    "doc": "P2: Development Specification",
    "title": "Project Context",
    "content": "In Project 1, you performed user discovery and created user stories with the help of LLMs. In Project 2, you will take three of those stories and expand them into a complete development specification (dev spec). This spec should serve as a blueprint for how you would build the product. By the end of this milestone, you will have a concrete technical plan, informed by your interviews, user stories, and the practices we’ve learned in class. Your dev spec will also be a test of how effectively you can collaborate with LLMs on technical writing, while still applying your own engineering judgment. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#project-context",
    "relUrl": "/projects/p2.html#project-context"
  },"49": {
    "doc": "P2: Development Specification",
    "title": "Deliverables",
    "content": "Choose 3 user stories from your user stories in P1 and have an LLM expand them into dev specs. Your team must produce a spec for each of the 3 that includes the following sections with enough detail that you (or someone else) could implement it: . | Header | Architecture Diagram . | Specify where the components run (e.g., client, server, cloud, etc.). | Specify which information flows between components. | . | Class Diagram | List of Classes | State Diagrams | Flow Chart | Development Risks and Failures | Technology Stack | APIs | Public Interfaces | Data Schemas | Security and Privacy | Risks to Completion | . Two of the three user stories should be independent of one another, however, the all dev specs must reflect that they are implemented in the same application. The third user story must be dependent on one of other two, i.e., the stories are intertwined somehow (e.g., one implements a shared text editor and the other implements a way to make text in that editor bold). Practically for this assignment, the third user story’s dev spec may require you to make modifications to the dependent user story’s dev spec in order to add it to the plan. We noticed that it’s easy for the LLM to create inconsistencies between the sections in the dev spec. For example, there may be more classes shown in the class diagram than described in the List of Classes. That’s something you’ll have to look for and fix before turning in your assignment. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#deliverables",
    "relUrl": "/projects/p2.html#deliverables"
  },"50": {
    "doc": "P2: Development Specification",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The three user stories from P1 that you chose to expand into a dev spec, listed at the beginning of your document. | Add the user stories to GitHub and turn in the links to each user story. | . | First dev spec document containing all the sections above. Each section should have rationale to justify your decisions. After each section, copy-paste the chat log showing your prompts and the LLM’s responses. | Commit this dev spec into your GitHub repo and turn in the link to it. | . | Second dev spec document containing all the sections above. Each section should have rationale to justify your decisions. After each section, copy-paste the chat log showing your prompts and the LLM’s responses. | Commit this dev spec into your GitHub repo and turn in the link to it. | . | Third dev spec document (this is the one dependent on one of the previous two user stories) containing all the sections above. Each section should have rationale to justify your decisions. After each section, copy-paste the chat log showing your prompts and the LLM’s responses. | Add an explanation of how the other user story’s dev spec was modified to accommodate this user story’s features. | Commit this dev spec into your GitHub repo and turn in the link to it. | . | A 1–2 paragraph reflection on how useful the LLM was in helping you create the dev specs, and what parts required the most human correction/reprompting. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#turn-in-instructions",
    "relUrl": "/projects/p2.html#turn-in-instructions"
  },"51": {
    "doc": "P2: Development Specification",
    "title": "P2: Development Specification",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html",
    "relUrl": "/projects/p2.html"
  },"52": {
    "doc": "P3: Frontend Development",
    "title": "Project 3: Frontend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#project-3-frontend-development",
    "relUrl": "/projects/p3.html#project-3-frontend-development"
  },"53": {
    "doc": "P3: Frontend Development",
    "title": "Learning Goals",
    "content": ". | Learn how to transform development specifications into a working user interface. | Learn how to use Figma’s AI tools to create mockups. | Learn how to collaborate with LLMs to generate frontend code, while refining and debugging the output, with a mocked backend. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#learning-goals",
    "relUrl": "/projects/p3.html#learning-goals"
  },"54": {
    "doc": "P3: Frontend Development",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you will use an LLM to implement the front end of your application. Begin by creating polished UI/UX mockups in Figma for your user stories. Then, you’ll use those mockups and the development specifications to use LLMs to generate the frontend. Since the backend isn’t fully implemented yet, you will need to mock the backend to simulate functionality. The emphasis here is on getting something real and visual, even if it’s only partially functional. By the end of this sprint, you’ll have mockups, a working frontend implementation, and mocked backend to power the interface. Remember, use the LLMs as much as possible to generate the deliverables. You may not modify any generated graphics or code directly, only by prompting the LLM. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#project-context",
    "relUrl": "/projects/p3.html#project-context"
  },"55": {
    "doc": "P3: Frontend Development",
    "title": "Deliverables",
    "content": "Choose two of the three user stories from P2: Development Specification whose front end you will implement. They must include one independent user story and one user story dependent on the first one. Note: If you are having second thoughts about the user stories you submitted for P1, you may update them. 1. UI Mockups in Figma . Create high-fidelity mockups for each of your two chosen user stories. | Include all states of the interface: e.g., empty state, loading, error, success, etc. | Include enough detail about the intended graphical design in your Figma project to help a developer to implement the appropriate CSS and layout code. For example, if your design needs to relayout in a specific way when the window is stretched or zoomed, please annotate the design with the behavior you want to see. | Write up the rationale for major design choices (e.g., navigation flow, component reuse, accessibility). | . Check in high-resolution screenshots of your mockups into your project’s GitHub repository. 2. Frontend Implementation . Implement the user stories in code using a popular frontend framework (e.g., React, Svelte). | Using your LLM, generate the front end code from your user stories, Figma mockups (with their design rationale and developer implementation guides), and development specifications. | Include responsive design for at least two screen sizes. | Ensure accessibility compliance with WCAG and alt-text for images where appropriate. | Ensure any backend functionality or data is mocked such that the frontend functionality can be demonstrated. | . Important: The code for both user stories must be generated into the same frontend application. Watch out for duplicated functionality, inconsistent class names, and incomplete interfaces. | Screen record yourself testing the frontend implementation in a web browser (include appropriate voiceover narration so we can follow what you’re trying to show). It should display correctly at your two different screen sizes. Use the browser’s debugger to accurately set the screen size during testing. Resize the browser window with your mouse/finger to test for proper layout logic. | Upload the screen recording to YouTube. | . Check in the frontend implementation to your GitHub repository. 3. Reflection . Write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in generating the frontend code? What did you like about the result? | What was wrong with what the LLM generated? What were you able to fix it easily? What problems were more difficult to fix? | How did you validate that the implementation was complete and correct? Did you use the LLM to help? | How did you test the functionality of the implementation? Explain the steps you took and why you did them. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#deliverables",
    "relUrl": "/projects/p3.html#deliverables"
  },"56": {
    "doc": "P3: Frontend Development",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The two user stories that you implemented. | Provide a link to the Figma project with your mockups. Be sure that the instructors have read access to this project or you will receive no points for this deliverable. | Provide links to each of the mockup’s high-resolution screenshots as they are checked into GitHub. | Link to the folder with the code in GitHub. | Link to the YouTube video of your application test. You may set its visibility to private, but be sure that the instructors have read access to it or you will receive no points for this deliverable. | A 1-page reflection. | Copy-paste logs of all LLM interactions you used during this sprint. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#turn-in-instructions",
    "relUrl": "/projects/p3.html#turn-in-instructions"
  },"57": {
    "doc": "P3: Frontend Development",
    "title": "P3: Frontend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html",
    "relUrl": "/projects/p3.html"
  },"58": {
    "doc": "P4: Backend Development",
    "title": "Project 4: Backend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#project-4-backend-development",
    "relUrl": "/projects/p4.html#project-4-backend-development"
  },"59": {
    "doc": "P4: Backend Development",
    "title": "Learning Goals",
    "content": ". | Learn how to transform development specifications into a working backend. | Learn how to collaborate with LLMs to generate backend code, while refining and debugging the output, with a real or mocked frontend. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#learning-goals",
    "relUrl": "/projects/p4.html#learning-goals"
  },"60": {
    "doc": "P4: Backend Development",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you implemented two user stories for the front end of your application. In P4, you will implement the backend of your application. Begin by reading over the user stories you chose to implement for P3. For each of these user stories, you had the LLM generate development specifications in P2. Look over the architecture plans for each of these development specs. First, if you haven’t done it yet, have the LLM harmonize the two architecture plans and diagrams to ensure that the LLM knows you are building a single backend for the application that can support both user stories. For each module in your architecture, decide whether it will be part of the frontend or backend. Recall that frontend components usually handle the application’s user interfaces and the business logic. The backend often handles data storage (separate data stores for each tenant), compute-intensive algorithms (e.g. machine learning, audio/video codecs, path routing), calls out to external backend services (e.g. speech transcription, image recognition, authentication, cryptography, etc.), and networking to and from other frontend UIs connected to the same backend. In P4, you only need to specify and implement the backend modules. By the end of this sprint, you’ll have a working backend implementation plus loads of documentation describing how it works. Recall that every module lives in a single backend and should make the same technical choices to minimize the number of redundant internal and external dependencies. Remember to use the LLMs as much as possible to generate your deliverables. You may not modify any generated code directly, only by prompting the LLM. !!! note Make sure your backend supports 10 simultaneous frontend users. Simultaneity means that all of those users’ frontend UIs are talking to the backend at the same time. Do not attempt to make your backend scale to more users. !!! note Consider whether you need to have a working frontend to tell if your backend works or not. It is ok to mock the frontend (from the backend’s point of view) if it helps you make timely progress. !!! note Your backends will (eventually) be deployed to Amazon Web Services (AWS). Let that influence your choice of external backend services, especially if the cost is zero or minimal. In P4, you need to mock any calls to external services. However in P5, you will be able to create an AWS account with $100-200 free credits and will be usable for 6 months (or until the credits are exhausted) to call those services. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#project-context",
    "relUrl": "/projects/p4.html#project-context"
  },"61": {
    "doc": "P4: Backend Development",
    "title": "Deliverables",
    "content": "You will implement the backend for the same two user stories that you implemented in P3. Remember that one of these user stories is independent and the other is dependent on the first one. 1. Update your Development Specs . Create new development specs for each of your two chosen user stories that have a single, harmonized backend specification, i.e. the specs assume that there’s a single backend that powers both user stories. | Include the entire development spec for each user story. | Have the LLM generate mermaid diagrams for any required diagram and add photos of those diagrams to your submission. | . 2. Specify the Backend . Architecture . | Create a single, unified architecture for the backend that supports both user stories. Write down a text description to describe it and draw it as a Mermaid diagram. Justify your design choices as if you were speaking to a senior architect with your company. | . Backend Modules . For every backend module in this architecture, do the following (with assistance from the LLM): . | Specify the module’s features. What can it do? What does it not do? These should be written to be understandable by a professional backend developer. | Design the internal architecture for the module. Write down a text description to describe it and draw it as a Mermaid diagram. Justify your design choices as if you were speaking to a senior architect with your company. | Define the data abstraction used in the module. If it helps you or the LLM to think about this formally, take a look at Reading 13 from MIT’s 6.005 class. | Determine the stable storage mechanism for the module (i.e. you can’t just use an in-memory data structure because your app might crash and lose its memory. Customers really hate data loss.) . | Define any data schemas required to communicate with any storage databases. | . | Define a clear, unambiguous API for external callers of this module. We suggest employing a REST API for any services accessible over the web. | Provide a list of all class, method, and field declarations. Identify which are externally visible and which are private to the module. | Draw a Mermaid class hierarchy diagram that shows the module-internal view of each class. | Use the LLM to generate the code for each class. | . Wrap it up . | Write and run the minimum required testing code to ensure that the user stories whose program path uses each module’s API works as expected. Don’t worry about exceptional cases for now. | Check your code into the GitHub repository for your project. | Check in any code you write to test the functionality of your module. | Create a README for your backend source code. | Describe every dependency on an external library, framework, technology, or service required (or optionally required) by the module. | What databases does this module create, read from, and write to? | Describe how to intall, startup, stop, and reset the backend services and data storage. Assume the user of these docs is a site reliability engineer who has been newly assigned to work with your team. | . | . 3. Reflection . Write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in generating the backend code? What did you like about the result? | What was wrong with what the LLM first generated? What were you able to fix it easily? What problems were more difficult to fix? | How did you convince yourself that the implementation was complete and accomplished your user stories? Did you use the LLM to help? | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#deliverables",
    "relUrl": "/projects/p4.html#deliverables"
  },"62": {
    "doc": "P4: Backend Development",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The two user stories that you implemented. | The two (updated) development specifications and mermaid diagrams for those user stories as in the Update your Development Specs section. | The specification and description of the unified backend architecture and its mermaid diagram. | For each module in your backend, provide its specification as in the Backend Modules section. | Provide a link to your source code in GitHub | Provide a link to your test code in GitHub | Provide a link to your backend’s README in GitHub | A 1-page reflection as in the Reflection section. | Copy-paste logs of all LLM interactions you used during this sprint. Identify the name and version of the LLM used. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#turn-in-instructions",
    "relUrl": "/projects/p4.html#turn-in-instructions"
  },"63": {
    "doc": "P4: Backend Development",
    "title": "P4: Backend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html",
    "relUrl": "/projects/p4.html"
  },"64": {
    "doc": "P5: Testing",
    "title": "Project 5: Testing",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#project-5-testing",
    "relUrl": "/projects/p5.html#project-5-testing"
  },"65": {
    "doc": "P5: Testing",
    "title": "Learning Goals",
    "content": ". | Learn how to write unit tests using multi-shot prompting. | Learn how to run tests locally. | Learn how to automate test runs using GitHub continuous integration. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#learning-goals",
    "relUrl": "/projects/p5.html#learning-goals"
  },"66": {
    "doc": "P5: Testing",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you implemented two user stories for the front end of your application. In P4, you implemented two dev specs for the back end of your application. In P5, you will write unit tests for two core frontend and two core backend files/classes. By the end of this sprint, you’ll create four test files that unit test your application’s features. You will also create a test script to run the tests on your local machine. Finally, you will automate test execution so that it runs on GitHub every time someone commits code to the repository. You will learn to look at the results of those tests to make sure your code doesn’t break the build without you knowing about it right away. Remember to use the LLMs as much as possible to generate your deliverables. You may not modify any generated code directly, only by prompting the LLM. You should use formalized LLM prompts, such as those we introduced in class. These will make the LLM output more reliable. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#project-context",
    "relUrl": "/projects/p5.html#project-context"
  },"67": {
    "doc": "P5: Testing",
    "title": "Deliverables",
    "content": "You will begin by writing a test specification for two code files in the frontend of your codebase and unit tests for code files in the backend of your codebase. You should choose the most important core code files that enable your user stories to run. A test specification is an English-language document that describes the purpose of each function to be tested along with every program path that should be tested with a unique unit test. For each unit test, the document should describe the inputs to the function that are required to engage the desired program path and the expected output. Your goal should be 80% code coverage. This means that for each function to be tested, your unit tests will exercise at least 80% of the function’s possible execution paths. Don’t forget about exceptions! . Next, you will implement the spec by creating Javascript (or Typescript) unit tests for each function. Ensure that your tests are isolated to the frontend or backend; they should not test functionality that requires connecting across the network from the frontend to the backend or vice versa. If the function under test requires connecting to the other end, you must create mock objects that simulate the other end’s public interface. You will then create scripts to setup the application and run the unit tests on your own machine. Finally, you will create a GitHub Action that sets up and runs all of your unit tests whenever anyone commits code to the GitHub repository. 1. Choose the files you want to test . Look through the source code of your frontend and identify two code files that contain the most core functionality that implements the two frontend user stories. There must be at least 5 functions in each file. Look through the source code of your backend and identify two code files that contain the most core functionality that implements the two backend user stories. There must be at least 5 functions in each file. 2. Write the test specification . Ask your LLM to write one English-language test specification for each code file you plan to test. Each specification should contain a list of all functions in the code file, followed by a table of tests. Each row of the table should describe the purpose of the test, the test inputs to the function, and the test output that is expected if the test passes. You must write at least one unit test for every function. For example, you have a validateEmail(string address) function to test. One possible test may check whether GMail addresses are considered valid. The input address would be “realemailaddress@gmail.com” and the expected output would be the boolean “true”. 2. Create your unit tests . Most projects that are written in Javascript or TypeScript should use the Jest unit testing framework. You may use another framework, but you may not simply manually test the code. You must use a testing framework. If you are building a VS Code extension, you must use VS Code’s preferred testing framework, Mocha. See VS Code’s Extension Testing Instructions on how to set it up. First, install the test framework into your application. Create a tests/ folder and keep all of your test files there. Next, have your LLM read the test specification document and generate the required unit tests. If a mock is needed, have your test framework do it for you. | Jest | Mocha uses SinonJS to generate mocks. | . Generate unit tests for each test specification using your LLM. At the end, you should have four test files. !!! note We strongly suggest that you use the LLM to generate only one unit test at a time. We have learned from experience that trying to get the LLM to do the entire thing in one prompt will lead to incorrect output. !!! note You will be graded on how well you prevent the LLM from hallucinating nonsensical test cases or creating duplicate or significantly overlapping test cases. The LLM must not generate test cases for functions and functionalities that do not exist. 3. Run the tests on your own machine . Ask the LLM to generate an npm script to setup the frontend or backend of your application, as needed, and then execute the tests with your testing framework. How did it go? Did every test pass? If not, use your LLM to give you a plan on how it wants to fix the bugs (ask it for three alternative fixes). Choose the bug fix you like and have the LLM make the change. Did your test case pass? Congratulations! If not, try again. 4. Check code coverage . Check to make sure that you have achieved at least 80% code coverage in each test file. Use your test framework to do this — the LLM will not be able to check this for you. | For Jest, read through this blog post to see how to check coverage. | For Mocha, read through this blog post. | . Check in your test code to the GitHub repository for your project. 5. Automate your tests . Adding continuous integration for quality assurance is a critical part of software development. Although you have tested your system manually, you are now setting out to establish sustained practices that can be used moving forward as you iterate over and continue to improve your system. Create GitHub Actions that run your tests on every commit. You will need to create two YAML workflow files in the .github/workflows directory. The first, for your frontend code, should be named run-frontend-tests.yml and the second, for your backend code, named run-backend-tests.yml. Each YAML file should check out your code, set up the application environment (e.g., install Node.js if needed), install dependencies, and then execute your tests. | For CI instructions to run tests with Jest, check out Dennis O’Keefe’s blog. | For CI instructions with VS Code extensions, check out these instructions. | . Check in your YAML files to the GitHub repository. Test out your CI code by making a change to one of the source code files in the frontend and one backend source code file. Commit the change to Git, push to the remote repository, create a pull request on GitHub, and accept the pull request. Finally, go to the GitHub repository on the web and click on teh Actions tab on the navigation bar. You’ll see all the workflows on the left and workflow runs on the right. If you have a green checkmark next to a workflow run, that means it worked! If there is a red cross, then it did not. Click on the workflow run to see exactly what got executed in GitHub’s “terminal window” and find out what went wrong. Fix the problem and try again until each of your two GitHub actions run successfully. Wrap it up . Edit the README.md file for your project. | Provide all the instructions needed for how to manually run the frontend tests on a developer’s local machine. Don’t forget to explain what frameworks and libraries need to be installed! | Provide all the instructions needed for how to manually run the backend tests on a developer’s local machine. Don’t forget to explain what frameworks and libraries need to be installed! | . 6. Reflection . Write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in generating the test specification? What did you like about the result? What was wrong with what the LLM first generated? What were you able to fix it easily? What problems were more difficult to fix? | How effective was the LLM in generating unit tests from the test specification? What did you like about the result? What was wrong with what the LLM first generated? What were you able to fix it easily? What problems were more difficult to fix? | How did you verify that the LLM correctly did what you asked? How did you use the test framework or the LLM to help you understand if everything was done correctly? | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#deliverables",
    "relUrl": "/projects/p5.html#deliverables"
  },"68": {
    "doc": "P5: Testing",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The two code files you chose to test for your frontend. | The frontend test specifications. | Provide a Git repository link to the test code files that implement your frontend test specs. | Copy-paste in the test output from running your frontend tests. | Copy-paste in the code coverage report for your frontend test files. | The two code files you chose to test for your backend. | The backend test specifications. | Provide a Git repository link to the test code files that implement your backend test specs. | Copy-paste in the test output from running your backend tests. | Copy-paste in the code coverage report for your backend test files. | Provide a Git repository link to your run-frontend-tests.yml file. | Provide a Git repository link to your run-backend-tests.yml file. | Provide a GitHub link to a workflow run of run-frontend-tests that shows it ran successfully after frontend code was committed. | Provide a GitHub link to a workflow run of run-backend-tests that shows it ran successfully after backend code was committed. | Provide a link to your project’s README in GitHub. | A 1-page reflection as in the Reflection section. | Copy-paste logs of all LLM interactions you used during this sprint. Identify the name and version of the LLM used. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#turn-in-instructions",
    "relUrl": "/projects/p5.html#turn-in-instructions"
  },"69": {
    "doc": "P5: Testing",
    "title": "P5: Testing",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html",
    "relUrl": "/projects/p5.html"
  },"70": {
    "doc": "P6: Deployment",
    "title": "Project 6: Deployment",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#project-6-deployment",
    "relUrl": "/projects/p6.html#project-6-deployment"
  },"71": {
    "doc": "P6: Deployment",
    "title": "Learning Goals",
    "content": ". | Learn how to package an application for deployment to the cloud. | Learn how to deploy a frontend and backend application to Amazon Web Services (AWS) | Learn how to automate deployment using GitHub continuous deployment. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#learning-goals",
    "relUrl": "/projects/p6.html#learning-goals"
  },"72": {
    "doc": "P6: Deployment",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you implemented two user stories for the front end of your application. In P4, you implemented two dev specs for the back end of your application. In P5, you wrote unit tests for two core frontend and two core backend files/classes. In P6, you will deploy the frontend and backend of your application to AWS. By the end of this sprint, you will set up a publicly visible deployment of your application. You will then automate deployment so that every time you commit code to your repository, GitHub will run the test cases and if successful, will deploy the updated application to AWS. Remember to use the LLMs as much as possible to generate your deliverables. You may not modify any generated code directly, only by prompting the LLM. You should use formalized LLM prompts, such as those we introduced in class. These will make the LLM output more reliable. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#project-context",
    "relUrl": "/projects/p6.html#project-context"
  },"73": {
    "doc": "P6: Deployment",
    "title": "Deliverables",
    "content": "You will begin by setting up your AWS account. You will need AWS access for all steps of this project. None of the steps in P6 should cost you any money, however the AWS account setup will likely require a credit card to be charged in case you incur any costs. Be assured that whenever we’ve done this before, we’ve spent at most 20-30 cents total. If you find that AWS has billed you anywhere near USD $1, immediately turn off any applications you have already deployed and reach out to the instructors for help. Next, you will set up your application to run with AWS Lambda. AWS Lambda lets you run server code without having to deal with actual server machines. It’s a “serverless” computing service. You will modify your backend to run on AWS Lambda. Your backend should publish its public interfaces via REST API. You will use AWS API Gateway to expose your public endpoints for web users (or applications) to interact with. Next, you will use AWS Amplify to host your frontend application. Amplify will store and serve static web assets, like HTML, CSS, and JS files, that comprise your application frontend. !!! note If you are building a VS Code Extension, you will deploy your frontend to the VS Code Extension Marketplace. Now is the time to implement integration tests. These are tests that exercise the frontend to backend (and vice versa) code paths in your app. You will learn to run these integration tests on localhost and in the cloud and run them on every checkin. At the end, you will set up GitHub actions to deploy your frontend code to Amplify and your backend code to Lambda after each pull request has been approved. 1. Create an AWS account . Go to the AWS Console and create an account. If one person on your team already has an AWS account, you can use that one. Log into the AWS Console with your new account. 2. Use AWS Lambda to run your backend code . To use Lambda, you will . | Write (slightly stylized) code that executes functions on certain events (e.g., the invocation of a given REST endpoint) | Package up your code (i.e., put it all in a ZIP file) | Upload the packaged code to AWS | . Ask your LLM to modify your backend code so that it executes as a lambda function. Eventually, that lambda function will execute when your REST API’s public interface endpoints receive post requests. To start with, though, you should become familiar with Lambda, then package up your Lambda code, deploy it, and make sure you can invoke it using the AWS command-line interface (CLI). 1. Use the AWS console to experiment with Lambda . Ask your LLM for detailed instructions on how to use AWS Lambda to set up a dummy application that you can invoke. This will help you get familiar with AWS Lambda when you have to set up your own application. If your LLM proves unhelpful, read the official AWS documentation. 2. Package and invoke your Lambda code using the AWS CLI . Ask your LLM to teach you how to package your Javascript code for deployment on AWS and upload it with the AWS CLI. If your LLM is unhelpful, you can read the official AWS documentation. There is some additional documentation in the Lambda section of the official AWS API Gateway tutorial. 3. Integrate your Lambda code with the REST API . Ask your LLM to teach you how to modify the Lambda code so that it is invoked by requests to your API’s public interface functions. If your LLM is not helpful, read the Lambda section of the official AWS API Gateway tutorial. 3. Use API Gateway to create a REST API . AWS API Gateway makes it simple to spin up an API. A web API exposes endpoints that users (or applications) can interact with. You are going to create a REST API for the backend of your app that exposes all of your public interfaces functions. Ask your LLM to teach you how to create your REST API with AWS API Gateway. If your LLM is unhelpful, read through this tutorial. After setting up AWS API Gateway, locate the API call logic in your frontend code (where it currently calls localhost). Replace the localhost URL with the API Gateway endpoint URL. Note, edit the code carefully to preserve a version of the app that runs locally for easier testing. 4. Host your frontend code . AWS Amplify makes it easy to e.g., deploy app frontends and integrate with version control. In this assignment, you will use Amplify to manage deployment of the frontend of your calculator application. Your task is to set up Amplify to host the application frontend. To complete this part of the assignment, refer to the AWS Amplify tutorial for deploying a web application by connecting Amplify to your GitHub repository. If you are building a VS Code Extension, do not follow the AWS Amplify directions. Instead, you will deploy the frontend of your extension to the VS Code Extension Marketplace. To complete this deployment, you will follow these instructions. First, install the vsce command line tool, create an Azure DevOps personal access token, define your team as a publisher, and publish your extension. Make sure to say that the cost of your extension is USD $0. Be sure to have your LLM do all this work for you! . !!! note When this course is over, please remember to unpublish your extension from the VS Code Extension Marketplace. 5. Integration testing . Ask your LLM to write an English-language test specification for the code pathways that require the execution of frontend and backend code together. Each specification should contain a list of all functionality that needs to be tested, followed by a table of tests. Each row of the table should describe the purpose of the test, the test inputs to the function, and the test output that is expected if the test passes. You must write at least one integration test for every code pathway that spans frontend and backend functionality. Generate integration tests for each row of your test specification using your LLM. Test out your full app on your local machine first. Run your npm scripts to setup and start the frontend and backend of your application on localhost, then execute the integration tests with your testing framework. !!! note Some integrations tests will fail when run on localhost, but work fine when deployed on the Internet. Please take a note of these and condition their execution to run only when deployed in the desired environment. Finally, create a new test configuration that uses the URLs of the deployed frontend and backend hosted by the AWS Cloud. Rerun your integration tests on your deployed app and fix any bugs that pop up until the entire app is working as desired. 6. Automate your integration tests . Ask your LLM to create a new GitHub Action that runs your integration tests on every commit. Store the YAML workflow file in the .github/workflows directory. Name it run-integration-tests.yml. It should check out your code, set up the application environment for frontend and backend (e.g., install Node.js if needed), install dependencies, and then execute your tests. | For CI instructions to run tests with Jest, check out Dennis O’Keefe’s blog. | For CI instructions with VS Code extensions, check out these instructions. | . Check in your YAML file to the GitHub repository. Ask your LLM to test out your CI code by making a change to one of the source code files in the frontend and one backend source code file. Commit the change to Git, push to the remote repository, create a pull request on GitHub, and accept the pull request. Finally, go to the GitHub repository on the web and click on the Actions tab on the navigation bar. You’ll see all the workflows on the left and workflow runs on the right. If you have a green checkmark next to a workflow run, that means it worked! If there is a red cross, then it did not. Click on the workflow run to see exactly what got executed in GitHub’s “terminal window” and find out what went wrong. Fix the problem and try again until each of your two GitHub actions run successfully. 7. Adopt good GitHub hygiene . Git is a very powerful and flexible version control system. One best practice you will follow is to create a new feature branch whenever you start working on a new coding task. Never work directly on the main branch. When your feature is done and your CI GitHub Actions (unit tests and integration tests) have passed their tests, create a pull request on GitHub to push the changes from the feature branch to main. As configured by default, anyone with access to your repo can push whatever garbage they want to the main branch. That’s not good! It’s important to make sure code that actually gets deployed has been thoroughly tested and reviewed (to catch everything from mistakes to intentional back doors!). In this assignment, you must block merges to main until your code is reviewed and passes CI. To protect your main branch, navigate to the Settings tab in your GitHub repo and click on Branches (on the lefthand side). You’ll see two options: (1) Add branch ruleset and (2) Add classic branch protection rule. Add a classic branch protection rule that protects main from direct, unreviewed commits: first check the box to require a pull request before merging and second check the box to require status checks to pass before merging. Select your CI testing workflows here as the relevant status checks. Finally, . 8. Use Github actions to automatically deploy on each push to main . After getting hands on experience with each service, you will use a Github action to deploy updates automatically on each push to your main branch. The CD pipeline will perform the following tasks: . | Deploy the packaged backend Lambda code. | Redeploy the frontend (to Amplify or the VS Code Extension Marketplace). | . In order to do this, you will need to allow Github to authenticate to AWS. Follow the Github documentation to safely use your AWS secrets in CD. This AWS blog post describes some (basic) best practices for generating and handling AWS authentication secrets in CI; navigate to the “Configuring AWS credentials in GitHub” section of the tutorial. Deploying backend code . Your LLM should create a Github workflow named deploy-aws-lambda.yml that takes the follow steps: . | Checks out the code, sets up Node, and installs dependencies. | Packages the code for lambda deployment. | Uses the AWS CLI to update the lambda code (giving the CLI access to your authentication secret and AWS region through the environment). | . Deploying frontend code . Your LLM should create a Github workflow named deploy-aws-amplify.yml that takes the following steps: . | Checks out the code, sets up Node, and builds the code. | Triggers AWS Amplify to redeploy the latest frontend version from your repository. See the AWS documentation for more. | . If you are publishing a VS Code Extension, your workflow will be named deploy-extension.yml. It should simply package up your extension and publish it to the marketplace. 9. Wrap it up . Edit the README.md file for your project. | Provide instructions for web users of your app to run your application. | Provide all the instructions needed for a random person on the Internet who forks your codebase to set up AWS to deploy your application. | . 10. Reflection . Without your LLM, write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in helping you understand how to deploy your app? What did you like about it? What was wrong with it? How many times did you have to change your prompt to get it to explain the information in a way you could understand? | How difficult was it to change habits and stop committing directly to main? Did you have to ask your team to change their practices to ensure minimal delays for accepting your pull requests? How do you feel about this feature branch practice? What are the pros and cons? | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#deliverables",
    "relUrl": "/projects/p6.html#deliverables"
  },"74": {
    "doc": "P6: Deployment",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | Deploy your app. Keep it deployed until the instructors let you know that they’ve checked this part out. | Provide a link to your Amplify frontend deployment or VS Code Extension Marketplace extension URL. | Provide a link to your Lambda backend REST function. | . | The integration test specification. | Provide a Git repository link to the test code files that implement your integration test specs. | Copy-paste in the test output from running your integration tests on localhost. | Copy-paste in the test output from running your integration tests in the cloud. | Provide a Git repository link to your run-integration-tests.yml file. | Provide a Git repository link to your deploy-aws-amplify.yml file (or deploy-extension.yml as appropriate). | Provide a Git repository link to your deploy-aws-lambda.yml file. | Provide a link to your project’s README in GitHub. | A 1-page reflection as in the Reflection section. | Copy-paste logs of all LLM interactions you used during this sprint. Identify the name and version of the LLM used. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#turn-in-instructions",
    "relUrl": "/projects/p6.html#turn-in-instructions"
  },"75": {
    "doc": "P6: Deployment",
    "title": "P6: Deployment",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html",
    "relUrl": "/projects/p6.html"
  },"76": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Project 7: Final Demo &amp; Postmortem",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#project-7-final-demo--postmortem",
    "relUrl": "/projects/p7.html#project-7-final-demo--postmortem"
  },"77": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Learning Goals",
    "content": ". | Learn how to clearly and professionally present a technical software project. | Learn how to communicate architectural decisions, deployment processes, and CI/CD pipelines. | Learn how to conduct a structured postmortem analyzing team practices, project successes, and failure points. | Learn how to prepare a high-level demo of a deployed application. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#learning-goals",
    "relUrl": "/projects/p7.html#learning-goals"
  },"78": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Project Context",
    "content": "Across P1–P6, you designed, implemented, tested, and deployed a full-stack application. Project 7 is your final sprint, in which you demonstrate your deployed app and present a reflective postmortem on your development process. You will give a 12-minute team presentation that includes: . | A live demo of your deployed application | An overview of your testing &amp; deployment process | A structured postmortem (lessons learned, surprises, team process, what you’d do differently) | . This presentation is your opportunity to demonstrate both your functional application and your mastery of the engineering practices taught in this course. The presentation itself will happen either during the last day of class or during the course’s scheduled final exam slot. You’ll be notified of your presentation slot at least one week in advance by the course staff. As with prior sprints, you should use LLMs to generate materials, including slides, scripts, and outlines. You may revise only through prompting. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#project-context",
    "relUrl": "/projects/p7.html#project-context"
  },"79": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Deliverables",
    "content": "1. Final Presentation (12 minutes per team) . Your presentation must follow this structure: . (1) Live Demo (6 minutes) . Show the core features of your deployed application. At minimum: . | Walk through your primary user stories. | Demonstrate frontend → backend integration. | If applicable, demonstrate any nontrivial workflows (authentication, complex functionality, etc.). | Show that your frontend is active on Amplify (or VS Code Extensions Marketplace). | Show that your backend Lambda/API Gateway endpoints are live. | . (Have a backup plan or recorded demo in case AWS decides to be mischievous during your time slot.) . (2) Testing &amp; Deployment Process (2 minutes) . Explain the engineering behind your deployment environment: . | How your GitHub Actions workflows run your tests. | How your CD pipeline deploys your backend to Lambda and your frontend to Amplify (or the Extension Marketplace). | Where secrets are stored and how permissions are granted. | How integration tests run in CI and how failures impact deployment. | . (3) Postmortem (4 minutes) . Reflect on your engineering process: . | Successes: What went well in development, testing, deployment, and team collaboration? | Failures / surprises: What broke? What caused major delays? What took far longer than expected? | Process evaluation: . | Did LLM-driven development help? | Did your feature-branch workflow work smoothly? | How did your testing strategy evolve? | . | Lessons learned: . | What would you do differently if starting again? | What best practices will you adopt in future software projects? | . | . Your postmortem should be honest, analytical, and reflective. 2. Slide Deck . Prepare a slide deck (Google Slides, PowerPoint, or PDF) containing: . | Title slide: team name, app name, team members | App overview: problem statement, target user | Demo roadmap | CI/CD overview with diagrams and workflow charts | Deployment overview (LLM-generated AWS architecture diagram encouraged) | Postmortem: successes, failures, lessons | Future work: 3–5 possible next features | . All slides must be generated using LLMs and refined only through prompting. 3. Postmortem Write-Up (1-2 pages) . Submit a written postmortem expanding on your presentation reflection. Include: . | Problem summary: what you built and why | Technical accomplishments: features, architecture, test coverage, deployment stack | Team workflow: branching strategy, communication, division of labor | Bottlenecks &amp; failures | LLM usage analysis . | How effective were LLMs? | How many prompt iterations were needed for key tasks? | How did you improve confusing or incorrect outputs? | . | Roadmap for future work | . This document must be drafted entirely with LLM support. 4. Turn-In Instructions . Submit a single document or folder containing: . | Link to your deployed frontend | Link to your deployed backend API endpoint | Link to your slide deck | PDF or MD version of your postmortem write-up | Copy-paste of all prompts used for slides, scripts, diagrams, and the write-up | Names and versions of all LLMs used | A short statement verifying that all artifacts were LLM-generated and edited only via prompting | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#deliverables",
    "relUrl": "/projects/p7.html#deliverables"
  },"80": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Evaluation Criteria",
    "content": "Your grade will be based on: . | Technical clarity of your application, testing, and deployment | Completeness and smoothness of your live demo | Depth and insight of your postmortem reflection | Professionalism of your presentation and slides | Compliance with LLM-generation requirements | Adherence to the 12-minute time limit | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#evaluation-criteria",
    "relUrl": "/projects/p7.html#evaluation-criteria"
  },"81": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "P7: Final Demo & Postmortem",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html",
    "relUrl": "/projects/p7.html"
  },"82": {
    "doc": "Project",
    "title": "Project",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/",
    "relUrl": "/projects/"
  },"83": {
    "doc": "Staff",
    "title": "Course Staff",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/#course-staff",
    "relUrl": "/staff/#course-staff"
  },"84": {
    "doc": "Staff",
    "title": "Instructors",
    "content": "Martin Kellogghe/him . martin.kellogg@njit.edu . Office Hours: Wednesdays, 1:30-2:30pm, GITC 4314; or by appointment. To schedule an appointment with me, check my calendar and add a calendar event in any open spot that works for you during regular business hours (Monday to Friday, 9:30-5:30). You must schedule meetings at least 24 hours in advance, or I will automatically decline them. In your invitation, you must, at a minimum, 1) invite me to the event, 2) add a note to the event description that mentions the code of this class (e.g., “CS 485”) and what you’d like to meet about, and 3) specify whether you would prefer the meeting to be in-person or remote. It is unprofessional to schedule a meeting with me unless you have exhausted your other options to solve the issue (for example, don’t schedule a meeting with me about a homework issue until you have attended a TA’s office hours and asked there). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/#instructors",
    "relUrl": "/staff/#instructors"
  },"85": {
    "doc": "Staff",
    "title": "Teaching Assistants",
    "content": "Chun Jie (Michael) Chonghe/him . cc255@njit.edu . Office Hours: Mondays, 2:30-3:30pm, location TBD . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/#teaching-assistants",
    "relUrl": "/staff/#teaching-assistants"
  },"86": {
    "doc": "Staff",
    "title": "Staff",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/",
    "relUrl": "/staff/"
  },"87": {
    "doc": "Tutorials",
    "title": "Tutorials",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/",
    "relUrl": "/tutorials/"
  }
}
