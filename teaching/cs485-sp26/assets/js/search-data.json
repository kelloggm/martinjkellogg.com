{"0": {
    "doc": "CS 485/698 AI-Assisted Software Engineering (Sp26)",
    "title": "CS 485: AI-Assisted Software Engineering",
    "content": "Modern generative artificial intelligence tools are astonishingly effective at generating code, given natural language specifications. The software engineering industry is rapidly adopting these tools to improve engineers’ productivity: instead of writing all of their code themselves, many engineers are now effectively “team leaders”, managing a “team” of artificial intelligence tools. In this course, students will get hands-on experience in using such artificial intelligence tools for software engineering in a semester-long course project. Topics will include agents, requirements elicitation and specification in the AI era, AI code generation and how to ensure that AI-generated code is correct, and discussions of how other traditional software engineering practices like code review and static analysis can help with AI-assisted software engineering. This website is under construction! . Any and all of its contents may change before the start of the spring semester. The course will meet on Mondays and Wednesdays at 11:30am. The course is open to students at all levels: bachelor’s, master’s, and PhD. Graduate students will be expected to engage with current research in the topic; see this description in the syllabus for the specific requirements for graduate students. When it is complete, the course website will consist of: . | the syllabus, | a course calendar (which includes links to the required readings), | links to assignment descriptions, | a staff page, and | useful tutorials. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/#cs-485-ai-assisted-software-engineering",
    "relUrl": "/#cs-485-ai-assisted-software-engineering"
  },"1": {
    "doc": "CS 485/698 AI-Assisted Software Engineering (Sp26)",
    "title": "CS 485/698 AI-Assisted Software Engineering (Sp26)",
    "content": ". ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/",
    "relUrl": "/"
  },"2": {
    "doc": "A1: LLMs for Code Experience Reflection",
    "title": "A1: LLMs for Code Experience Reflection",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience vibe coding programs from scratch, use LLMs to modify existing code, and using LLMs to help you understand how the codebase works. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This assignment is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a1.html",
    "relUrl": "/assignments/a1.html"
  },"3": {
    "doc": "A2: Requirements Engineering Reflection Essay",
    "title": "A2: Requirements Engineering Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing user discovery, creating user stories, or create development specifications using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a2.html",
    "relUrl": "/assignments/a2.html"
  },"4": {
    "doc": "A3: Frontend Development Reflection Essay",
    "title": "A3: Frontend Development Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing frontend development using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a3.html",
    "relUrl": "/assignments/a3.html"
  },"5": {
    "doc": "A4: Backend Development Reflection Essay",
    "title": "Submission",
    "content": "Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a4.html#submission",
    "relUrl": "/assignments/a4.html#submission"
  },"6": {
    "doc": "A4: Backend Development Reflection Essay",
    "title": "A4: Backend Development Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing backend development using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a4.html",
    "relUrl": "/assignments/a4.html"
  },"7": {
    "doc": "A5: Testing Reflection Essay",
    "title": "A5: Testing Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience doing testing using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a5.html",
    "relUrl": "/assignments/a5.html"
  },"8": {
    "doc": "A6: Deployment Reflection Essay",
    "title": "A6: Deployment Reflection Essay",
    "content": "This is an individual assignment. Learning Goals . Reflect on your experience deploying a system to production using LLMs. The task . Write a 500-word essay on a reflection question of your choice from this Google Sheet. Up to 4 class members may choose the same reflection question. Write your name down in the sheet next to the question you have chosen. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 100 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 450-550 words. 10 pts. | Essay answers your reflection question. 20 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 65 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a6.html",
    "relUrl": "/assignments/a6.html"
  },"9": {
    "doc": "A7: Special Topic Reflection Essay (Graduate Students Only)",
    "title": "A7: Special Topic Reflection Essay (Graduate Students Only)",
    "content": "This is an individual assignment. Learning Goals . Read a paper about an interesting way to use an LLM in software engineering and try it out yourself. Reflect on your experience. The task . Write a 1000-word essay on a reflection question of your choice from this Google Sheet. Only one class member may choose each reflection question. Write your name down in the sheet next to the question you have chosen. Each question is based on one of the “special topic” readings throughout the semester. You should read the “special topic” article in detail. Then, you should try to replicate something discussed in the reading yourself, using your own LLM. For example, if the article is about using LLMs for code review, you should spend some time trying to use an LLM to review a change to an existing codebase. It’s up to you exactly how you interpret this requirement, but your essay should clearly explain what you did and why. Write your essay. Good essays have concrete examples, e.g., it did x but I expected y in the context of z. Bad essays are vague and employ generic sentiments, like “I like it!”, or “It’s helpful.”. Be sure to write down your name, UCID, and the reflection question that you chose to answer at the top of the page. AI Constraints . You should not use any AI, GenAI, or LLM to write this essay. You may use any tool you wish to proofread your essay for grammar, but do not use any tool that creates or changes the meaning of what you have written. Note: You will be on the hook for understanding and defending the opinions you write in these reflection essays during in-class activities. You must understand and buy into the contents of your essay at the time you turn it in. Unlike the other reflection essays, for this one only one student will answer each question. You will be called on in class to describe how you answered the question, so you should be prepared for that. Submission . Submit as a PDF file to Canvas. If you prepare the response in some other software (like Tex, Word, or Google Docs), please export as PDF before submitting. Rubric . This homework is worth 200 points. You will receive points for accomplishing the following: . | Name, UCID, and reflection question are written at the top of the page: 5 pts. | Essay is between 900-1100 words. 10 pts. | Essay answers your reflection question. 35 pts. | Essay shows that you have read and reflected on the article. 50 pts. | Essay clearly describes what you did to test out the article’s claims and why. 50 pts. | Essay contains meaningful reflections that derive from your personal experience in this class. 50 pts. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/a7.html",
    "relUrl": "/assignments/a7.html"
  },"10": {
    "doc": "Syllabus",
    "title": "Syllabus",
    "content": "Modern generative artificial intelligence tools are astonishingly effective at generating code, given natural language specifications. The software engineering industry is rapidly adopting these tools to improve engineers’ productivity: instead of writing all of their code themselves, many engineers are now effectively “team leaders”, managing a “team” of artificial intelligence tools. In this course, students will get hands-on experience in using such artificial intelligence tools for software engineering in a semester-long course project. Topics will include agents, requirements elicitation and specification in the AI era, AI code generation and how to ensure that AI-generated code is correct, and discussions of how other traditional software engineering practices like code review and static analysis can help with AI-assisted software engineering. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/",
    "relUrl": "/about/"
  },"11": {
    "doc": "Syllabus",
    "title": "Prerequisites",
    "content": "Officially, none. Students will be expected to know how to program well enough to understand and debug code generated by an AI tool. Students without significant prior exposure to software engineering concepts (e.g., in CS 490 or an internship) will be expected to do additional background reading. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#prerequisites",
    "relUrl": "/about/#prerequisites"
  },"12": {
    "doc": "Syllabus",
    "title": "Topics",
    "content": ". | How LLMs Work, “Vibe Coding”, and Agents | Requirements Elicitation and Specification in the AI Era | AI Code Generation and Correctness | Frontend Development with LLMs | Backend Development with LLMs | Testing with LLMs | Deployment Strategies | Code Review with LLMs | Static Analysis and LLMs | Traditional Software Engineering Practices in an AI-Assisted Context | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#topics",
    "relUrl": "/about/#topics"
  },"13": {
    "doc": "Syllabus",
    "title": "Grading and Assignments",
    "content": "Your grade is composed of the following sub-scores (in no particular order): . | 50%: Course Project (consisting of 7 sub-assignments, with the final submission worth 25% of the total course grade) | 18%: Reflection Essays | 32%: In-class Activities, Participation, and Professionalism | . This class will be curved: when grading, I prefer to use the whole range available rather than scores in a tight range. That is, if an assignment is worth 10 points, I will give grades at all the points between 0 and 10. I will project your raw scores onto the final distribution once in the middle of the semester; you will be notified of your current projected class grade via email at this point. Programming Projects and Other Assignments . There will be a semester-long course project that will involve a significant software development effort. Students will work in small, self-selected teams. The scale of the project will be intentionally absurd: it will be so much work that no reasonable professor could ask their students to write the code themselves. Instead, students will be expected to use AI models to generate most of the code. The project will involve using LLMs as part of every step of the engineering process, from requirements gathering to coding to testing to deployment. As part of your submission for each assignment, you will be required to submit the logs of all of your interactions with your AI tools. Be sure to keep these logs. TODO: add more details here for students about how to do this to avoid surprises. The course project is broken down into seven sub-assignments, with the final submission being the largest component. Students will also complete several reflection essays throughout the semester, which are designed to encourage critical thinking about the use of AI in software engineering. These essays must be completed without the assistance of AI tools. Textbook . This course has no required textbook. Students will make heavy use of generative AI tools via APIs, so a subscription to one of them is recommended. In particular, a web-based LLM is not sufficient, because students will be expected to run their LLMs in “agentic” loops, where an automated process (e.g., a test suite) provides feedback to the LLM until some condition is met. Student- or free-tier plans are often available. I expect students will need at least one of Claude Code, Cursor, OpenAI Codex, etc. Topic-specific reading materials for software engineering topics (e.g., software architecture, various testing techniques, code review, etc.) will be provided; these will be officially optional, but strongly recommended for students who have not taken CS 490. List of known student plans for AI tools: . | Figma Make | TODO: add more as we become aware of them | . Participation &amp; Professionalism . Your participation &amp; professionalism grade is based on your interactions with the instructors and TAs: in-class, on the course discussion forum, in office hours, etc. Remote Participation . Generally this class does not support remote participation: teaching is much more effective, in my experience, when everyone is physically present. However, I understand that sometimes you are sick, traveling, or otherwise unable to come to class. I will arrange for remote participation in any particular lecture as long as you request it at least one hour in advance (if you’re sick or in some other emergency) or 24 hours in advance (if you’re traveling or otherwise planning to be unable to come to class). Notify the instructor via email if you need to participate in a particular class remotely. Asking Questions . There is a course Discord server which you can use to ask (and answer) questions about any of the course topics or for help with the homework. Participating on Discord is optional, but if you do participate in a productive manner (especially by answering other student’s questions!), it will have a positive impact on your participation score. Exams . This course does not have traditional exams. Your understanding will be assessed through your project work, reflection essays, and in-class participation. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#grading-and-assignments",
    "relUrl": "/about/#grading-and-assignments"
  },"14": {
    "doc": "Syllabus",
    "title": "BS vs MS/PhD students:",
    "content": "MS/PhD students will be expected to 1) work in teams only with other MS students, and 2) choose more ambitious course projects. I will also provide a set of readings in the current literature on this topic throughout the semester, called “Special topics readings” on the calendar; for the undergrads, these readings will be optional, but for the graduate students they will be required. I will also require an additional reflective essay from each graduate student on one of the papers from throughout the semester, to be presented to the whole class during one of the last class sessions. Otherwise, all students will be held to the same standards. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#bs-vs-msphd-students",
    "relUrl": "/about/#bs-vs-msphd-students"
  },"15": {
    "doc": "Syllabus",
    "title": "Collaboration Policy",
    "content": "Collaboration is generally encouraged in this course, as is consulting online resources. You are permitted to copy small amounts of code from any source except someone else’s copy of an assignment, as long as you cite your source. “Someone else’s copy of an assignment” also includes students not currently enrolled in the course - e.g., students who took this class in previous semesters or took classes that used similar projects at other institutions. To make this more clear, here are some examples of acceptable and unacceptable collaboration on assignments in this course: . Acceptable collaborations: . | Discuss problems/solutions/anything with any number of other students (as long as you don’t look at each other’s code or text). | Copy a short (about 10 lines or fewer - use your judgment) snippet from stackoverflow.com or a similar source, as long as you include a comment with the source URL. | Copy code written by one of your teammates during a group project for another part of the group project. | Copy code from the output of a generative AI tool such as ChatGPT that you prompted yourself (as long as you include a log of your interaction with your assignment submission). | . Unacceptable collaborations: . | Copy text from another student’s reflection essay. | Copy code from another group on a group project. | Copy any code or text from the internet without citing your source. | Copy code from the output of a generative AI tool (such as ChatGPT) without including a log of your interaction with the AI tool, or otherwise implying that it is your own work. | Copy code from the output of a generative AI tool prompted by someone other than you or your teammates, for the group project. | . These rules are intended to mimic what is acceptable in industry when working as a software engineer: using the resources available to you, such as your teammates and the wider internet, is always allowed. But, it would be illegal to copy code from a competing company working on a similar product. Generative AI Policy . You are permitted (or, sometimes, even required) to use generative AI tools on many assignments in this course. Whenever you do, you are required to include a log of your interaction with the tool: in particular, you must ensure that the course staff has access to both your prompts and the model’s responses while grading. For assignments or parts of assignments where you are explicitly forbidden from using a generative AI tool (e.g., on the reflection essays), using one is a violation of the collaboration policy. The course staff have intentionally limited the number of times that we ask you not to use generative AI tools; please respect it. If you are caught using a generative AI tool for such an assignment, you will at a minimum fail the course. Consequences of Violating the Collaboration Policy . (From the University) . “Academic Integrity is the cornerstone of higher education and is central to the ideals of this course and the university. Cheating is strictly prohibited and devalues the degree that you are working on. As a member of the NJIT community, it is your responsibility to protect your educational investment by knowing and following the academic code of integrity policy that is found at: http://www5.njit.edu/policies/sites/policies/files/academic-integrity-code.pdf. Please note that it is my professional obligation and responsibility to report any academic misconduct to the Dean of Students Office. Any student found in violation of the code by cheating, plagiarizing or using any online software inappropriately will result in disciplinary action. This may include a failing grade of F, and/or suspension or dismissal from the university. If you have any questions about the code of Academic Integrity, please contact the Dean of Students Office at dos@njit.edu” . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#collaboration-policy",
    "relUrl": "/about/#collaboration-policy"
  },"16": {
    "doc": "Syllabus",
    "title": "Late Policy",
    "content": "Most assignments may be submitted late, with an escalating “Fibonacci” penalty for each day beyond the due date. More specifically: . | Days Late | Penalty | . | 1 | 2% | . | 2 | 3% | . | 3 | 5% | . | 4 | 8% | . | 5 | 13% | . | 6 | 21% | . | n | fib(n + 2)% | . “Days Late” is always computed AoE, so if the assignment is due on a Monday and you submit it while it is still Thursday anywhere on Earth (e.g., at 5am Friday in Newark), you will be assessed a 5% penalty (3 days late). The final project submission may not be submitted late, because it is due at the end of the semester. After that point, the course is over and I will be computing final grades. No exceptions to this policy will be made. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#late-policy",
    "relUrl": "/about/#late-policy"
  },"17": {
    "doc": "Syllabus",
    "title": "Research",
    "content": "Your class work might be used for research purposes. For example, we may use anonymized student assignments to design algorithms or build tools to help programmers. Any student who wishes to opt out can contact the instructor or TA to do so after final grades have been issued. This has no impact on your grade in any manner. Students interested in considering undergraduate research should make an appointment with the professor to talk about it. I am happy to discuss independent study projects, paid research work over the summer, research work for credit, graduate school, or any other research related topic. To make an appointment with the professor, send a calendar invitation at a time when my calendar shows that I’m free during “regular business hours” (roughly 9-5, Monday through Friday). Include enough information in the invite so that I know why you want to talk to me. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#research",
    "relUrl": "/about/#research"
  },"18": {
    "doc": "Syllabus",
    "title": "Acknowledgments",
    "content": "This course is inspired by and indebted to similar courses offered at other institutions, including those at the University of Washington, University of Virginia, University of Maryland, and Carnegie Mellon University. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/about/#acknowledgments",
    "relUrl": "/about/#acknowledgments"
  },"19": {
    "doc": "Assignments",
    "title": "Assignments",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/assignments/",
    "relUrl": "/assignments/"
  },"20": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/",
    "relUrl": "/calendar/"
  },"21": {
    "doc": "Calendar",
    "title": "Week 1",
    "content": "Mon Jan 19 No class, MLK day Wed Jan 21 Introduction Mandatory reading: the syllabus ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-1",
    "relUrl": "/calendar/#week-1"
  },"22": {
    "doc": "Calendar",
    "title": "Week 2",
    "content": "Mon Jan 27 LLM Code Generation: Modifying an Existing Codebase Mandatory reading: Willison’s 2025: The year in LLMs Before class on Jan 29 Reflection essay on experience w/ LLM code generation due Wed Jan 29 LLM Code Generation: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-2",
    "relUrl": "/calendar/#week-2"
  },"23": {
    "doc": "Calendar",
    "title": "Week 3",
    "content": "Mon Feb 2 Requirements Engineering: User Discovery Lab Mandatory reading: Synthetic Users: If, When, and How to Use AI-Generated “Research” Background reading: The Mom Test by Rob Fitzpatrick. (Note: this is a book; it costs $10. You’re not required to read this, but you should be familiar with the ideas in it before class.) . Special topics reading: Analysis of LLMs vs Human Experts in Requirements Engineering . Wed Feb 4 Requirements Engineering: Creating Effective User Stories Background reading: INVEST in Good Stories, and SMART Tasks Special topics reading: When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-3",
    "relUrl": "/calendar/#week-3"
  },"24": {
    "doc": "Calendar",
    "title": "Week 4",
    "content": "Mon Feb 9 Requirements Engineering: Creating Dev Specs Mandatory reading: Development Spec Guidelines Background reading: How To Be A Program Manager and Design Docs at Google . Special topics reading: Aligning Requirement for Large Language Model’s Code Generation . Before class Feb 11 Reflection essay on requirements gathering w/ LLMs due Wed Feb 11 Requirements Engineering: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-4",
    "relUrl": "/calendar/#week-4"
  },"25": {
    "doc": "Calendar",
    "title": "Week 5",
    "content": "Sun Feb 15 Project requirements doc due Mon Feb 16 Frontend: Introduction Mandatory reading: TBD Special topics reading: Inside Out: Uncovering How Comment Internalization Steers LLMs for Better or Worse . Wed Feb 18 Frontend: Creating the UI Code Mandatory reading: TBD Optional reading: TBD . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-5",
    "relUrl": "/calendar/#week-5"
  },"26": {
    "doc": "Calendar",
    "title": "Week 6",
    "content": "Sun Feb 22 Project specification doc due Mon Feb 23 Frontend: Creating UI Behaviors Mandatory reading: Good Vibrations? A Qualitative Study of Co-Creation, Communication, Flow, and Trust in Vibe Coding Optional reading: TBD . Before class on Feb 25 Reflection essay on LLMs for frontend dev due Wed Feb 25 Frontend: Discussion Mandatory reading: TBD Optional reading: TBD . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-6",
    "relUrl": "/calendar/#week-6"
  },"27": {
    "doc": "Calendar",
    "title": "Week 7",
    "content": "Sun Mar 1 Project frontend code initial submission due Mon Mar 2 Backend: Coding Lab Mandatory reading: TBD Special topic reading: A Causal Perspective on Measuring, Explaining and Mitigating Smells in LLM-Generated Code . Wed Mar 4 Backend: Notifications Mandatory reading: TBD Special topics reading: Smoke and Mirrors: Jailbreaking LLM-based Code Generation via Implicit Malicious Prompts . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-7",
    "relUrl": "/calendar/#week-7"
  },"28": {
    "doc": "Calendar",
    "title": "Week 8",
    "content": "Mon Mar 9 Backend: Understanding Backends Special topic reading: From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging Before class on Mar 11 Reflection essay on LLMs for backend dev due Wed Mar 11 Backend: Discussion Mandatory reading: TBD Optional reading: TBD . Fri Mar 13 Project backend code initial submission due Mar 14 to Mar 22 Spring Break, no classes ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-8",
    "relUrl": "/calendar/#week-8"
  },"29": {
    "doc": "Calendar",
    "title": "Week 9",
    "content": "Mon Mar 23 Testing w/ LLMs: Intro Mandatory reading: Software Testing with Large Language Models: An Interview Study with Practitioners Special topic reading: An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software . Wed Mar 25 Testing w/ LLMs: TDD and CI Background reading: The Art of Agile Development: Test-Driven Development Special topic reading: E-Test: E’er-Improving Test Suites . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-9",
    "relUrl": "/calendar/#week-9"
  },"30": {
    "doc": "Calendar",
    "title": "Week 10",
    "content": "Mon Mar 30 Testing w/ LLMs: Mutation Testing Background reading: Mutation Testing Before class on Apr 1 Reflection essay on LLMs for testing due Wed Apr 1 Testing w/ LLMs: Discussion No reading ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-10",
    "relUrl": "/calendar/#week-10"
  },"31": {
    "doc": "Calendar",
    "title": "Week 11",
    "content": "Sun Apr 5 Project synthetic tests submission due Mon Apr 6 Deployment: Intro Mandatory reading: TBD Optional reading: TBD . Wed Apr 8 Deployment: Backend Mandatory reading: TBD Optional reading: TBD . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-11",
    "relUrl": "/calendar/#week-11"
  },"32": {
    "doc": "Calendar",
    "title": "Week 12",
    "content": "Mon Apr 13 Deployment: CD Mandatory reading: TBD Optional reading: TBD . Before class on Apr 15 Reflection essay on deployment due Wed Apr 15 Deployment: Discussion Mandatory reading: TBD Optional reading: TBD . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-12",
    "relUrl": "/calendar/#week-12"
  },"33": {
    "doc": "Calendar",
    "title": "Week 13",
    "content": "Sun Apr 19 Project deployment due Mon Apr 20 Static analysis + LLMs: Intro Mandatory reading: TBD Special topic reading: PredicateFix: Repairing Static Analysis Alerts with Bridging Predicates . Wed Apr 22 Static analysis + LLMs: Discussion Special topic reading: LLM-Based Repair of Static Nullability Errors ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-13",
    "relUrl": "/calendar/#week-13"
  },"34": {
    "doc": "Calendar",
    "title": "Week 14",
    "content": "Mon Apr 27 Slack or class’ choice Mandatory reading: TBD Optional reading: TBD . Before class on Apr 29 Reflection essay on special topic due (graduate students only) Wed Apr 29 Special topics discussion + course wrapup Mandatory reading: none ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-14",
    "relUrl": "/calendar/#week-14"
  },"35": {
    "doc": "Calendar",
    "title": "Week 15",
    "content": "Mon May 5 Project presentations Mandatory reading: TBD Mon May 5 Project final submission + postmortem due ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/calendar/#week-15",
    "relUrl": "/calendar/#week-15"
  },"36": {
    "doc": "How to Read a Paper (Useful for \"Optional\" Readings)",
    "title": "What is a research paper?",
    "content": "In computer science, original research is typically published at peer-reviewed conferences. Typically these papers have between two and ten authors, and the paper typically reports on about a person-year’s worth of work (though this can vary widely). The authors will be a mix of junior and senior researchers: anyone who contributed something “intellectually significant” to the paper is typically listed as an author. In most CS sub-disciplines (including software engineering, which is the source for most of the “Optional” readings), author order is indicative: the first author is usually the person who did most of the technical work (e.g., implementing the tool, running the experiments, etc.), and the last author is typically the project leader (often, but not always, the first author’s research advisor). Often, but not always, the first author is a PhD student. To be accepted at a peer-reviewed conference, a research paper must be novel: that is, it must contain some new knowledge or evidence that the research community wasn’t aware of before. This requirement impacts how they are written: a research paper must focus on the specific thing that is novel about it, rather than surveying the field as a whole (though you can find “survey” papers that give an overview of a research area, and if you need to know the current state of a sub-field, looking for a survey paper is the way to go). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/reading-papers.html#what-is-a-research-paper",
    "relUrl": "/tutorials/reading-papers.html#what-is-a-research-paper"
  },"37": {
    "doc": "How to Read a Paper (Useful for \"Optional\" Readings)",
    "title": "External Resources",
    "content": "I highly recommend Keshav’s How to Read a Paper if you’re not sure where to start. This short (3-page) article gives a specific strategy for attacking a research paper. I recommend Griswold’s How to Read an Engineering Research Paper. This short article is more aimed at PhD students. but it helps to explain how a research paper is structured (and might be useful to you to help understand the anatomy of a research paper). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/reading-papers.html#external-resources",
    "relUrl": "/tutorials/reading-papers.html#external-resources"
  },"38": {
    "doc": "How to Read a Paper (Useful for \"Optional\" Readings)",
    "title": "How to Read a Paper (Useful for \"Optional\" Readings)",
    "content": "Many of the readings for this course are papers from the research literature. These papers can be intimidating if you haven’t encountered them before. This page contains some suggestions on how to read a research paper, along with links to useful external resources. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/reading-papers.html",
    "relUrl": "/tutorials/reading-papers.html"
  },"39": {
    "doc": "P1: Requirements Engineering",
    "title": "Project 1: Requirements Engineering",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#project-1-requirements-engineering",
    "relUrl": "/projects/p1.html#project-1-requirements-engineering"
  },"40": {
    "doc": "P1: Requirements Engineering",
    "title": "Learning Goals",
    "content": ". | Learn how to do effective user discovery interviews to learn about the problems your users have, how they are willing to have you solve them, and what value they ascribe your solution | Learn how to get an LLM to create sound user stories that accurately reflect your planning goals | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#learning-goals",
    "relUrl": "/projects/p1.html#learning-goals"
  },"41": {
    "doc": "P1: Requirements Engineering",
    "title": "Project Context",
    "content": "You and your team will be spending the rest of the semester building all of the features that are present in the main product of the startup you have chosen. This assignment is intended to help you design a viable imitation of this product. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#project-context",
    "relUrl": "/projects/p1.html#project-context"
  },"42": {
    "doc": "P1: Requirements Engineering",
    "title": "Deliverables",
    "content": "1. Initial value proposition/product description . Please answer the following questions: . | What is the big idea of the startup you have chosen? What problem is it solving? What is its solution? What makes their solution special and distinguishes it from the competition? Do not use an LLM for this part. (1-2 paragraphs) | What is/are the value proposition(s) for your product? Do not use an LLM for this part. (1-2 sentences) | Ask an LLM to describe the value proposition(s) for your product (1-2 sentences). | What is the difference between the human and LLM-generated value propositions? Which one is more compelling? (3-4 sentences) | . Turn-in instructions . | Answers to question 1. (1-2 paragraphs) | The value proposition(s) for your product, written by humans. (1-2 sentences) | The value proposition(s) for your product, written by the LLM. (1-2 sentences) | Describe the difference in the value propositions written by humans and LLMs. Explain which one is more compelling and why. (3-4 sentences) | Turn in your chat log with the LLM. | . 2. Viability analysis: why do people want it? . In these exercises, you’ll collect some initial viability data, and make a plan for collecting more as you build out your project. 2a. Figure out why people want the product . Create a list of 10 questions that will you learn about the problems that people have that could be addressed by the main product of the startup you chose. Heed these lessons from The Mom Test: . | Talk about their life instead of your idea. | Ask about specifics in the past, instead of generic questions or opinions about the future. | . 2b. Measure/demonstrate that people want the product . Have four or more conversations with real people (not LLMs) who are somewhat engaged in your product’s area of focus. For example, if you’re interested in solving pain points around coding apps, all four people should at least know how to code. Use your questions from the prior section as a starter script. However, ask followup questions to discover what problems your interviewees are having. You may record these if you like so you have transcripts to refer back to, but this is not required. You must interview real humans for this assignment. Interviews with LLMs will not be accepted. Recall the lessons you learned in our user discovery class about adapting your question style for the specific personality type in front of you. | Describe where you found these four people and how you talked to them (e.g., formally over zoom, informally in the gym, etc.). | Describe one mistake you made during your discovery conversations, and one exchange that went well (and why). | . 2c. Summarize what you learned . What problems did people have? How were they solving them? What wasn’t a problem? Summarize what you learned from your discovery conversations. What might this mean for the product/focus area/problem of choice? . Optional: If you recorded and transcribed your interviews, you may turn in two summaries. | Summarize the interviews using only human brain power. | Put away your original summary, and then ask the LLM to summarize the lessons you learned from the transcripts. | . Turn-in instructions . Please turn in: . | The 10 interview questions you created. | Your raw notes and transcripts, demonstrating that every group member participated in at least two interviews. | Where you found your four interviewees and how you interviewed them. | One thing that went well and one thing that went poorly in any interview. | The five most useful questions you asked. (1 paragraph) | The five most useful pieces of concrete data you collected. (1 paragraph) | The summary, written by humans, of what you learned about the people you interviewed. (2 paragraphs) | Optional: The summary, written by an LLM, of what you learned about the people you interviewed. Also turn in the LLM chat log. (2 paragraphs) | . 3. User Stories . In this section, you will create user stories that correspond to the primary use cases of the product. However, you may not write the user stories themselves. You have to use an LLM to do this for you. The user stories should be customized by your understanding of the primary use cases of your startup’s main product as well as the lessons you learned from the user discovery exercise above. These may not turn out identical to the product already in production, but that’s ok. With everything we learn here, we can make it better! . | Get an LLM to create 10 user stories for your product. Make sure it uses the proper template: - As a &lt;user&gt;, I want &lt;action&gt; so that &lt;benefit&gt;. - Have the LLM add an explanation of what each user story is really about. - Have the LLM estimate each user story’s size as a t-shirt (Small, Medium, Large, Xtra-Large) - Be sure to tell the LLM that each user story must fit integrally into a 2-week sprint. | Ask the LLM to evaluate the user stories according to the INVEST framework we learned in class. - Throw out the 5 lowest ranked user stories. | Have the LLM to prioritize the remaining 5 user stories into a product backlog. Ask it to assign the user stories to be accomplished to one of the next 5 2-week-long sprints (10 weeks of work). | . Turn-in instructions . Please turn in: . | The original list of 10 user stories. | The five user stories that were eliminated and what reason the LLM gave (and you agreed with) for dropping them. (1 paragraph each) | List the top five user stories that you kept, in the order that they were assigned to sprints, and for each one, answer why it this the right story to work on and why do it in the sprint it was assigned to? (1 paragraph each) | The chat log from all LLM interactions you had in doing this work. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html#deliverables",
    "relUrl": "/projects/p1.html#deliverables"
  },"43": {
    "doc": "P1: Requirements Engineering",
    "title": "P1: Requirements Engineering",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p1.html",
    "relUrl": "/projects/p1.html"
  },"44": {
    "doc": "P2: Development Specification",
    "title": "Project 2: Development Specification",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#project-2-development-specification",
    "relUrl": "/projects/p2.html#project-2-development-specification"
  },"45": {
    "doc": "P2: Development Specification",
    "title": "Learning Goals",
    "content": ". | Learn how to translate user stories into a structured development specification. | Learn how to guide an LLM to generate architecture diagrams, class diagrams, flow charts, and other technical artifacts. | Learn how to critically assess risks, interfaces, and technologies when planning software implementation. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#learning-goals",
    "relUrl": "/projects/p2.html#learning-goals"
  },"46": {
    "doc": "P2: Development Specification",
    "title": "Project Context",
    "content": "In Project 1, you performed user discovery and created user stories with the help of LLMs. In Project 2, you will take three of those stories and expand them into a complete development specification (dev spec). This spec should serve as a blueprint for how you would build the product. By the end of this milestone, you will have a concrete technical plan, informed by your interviews, user stories, and the practices we’ve learned in class. Your dev spec will also be a test of how effectively you can collaborate with LLMs on technical writing, while still applying your own engineering judgment. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#project-context",
    "relUrl": "/projects/p2.html#project-context"
  },"47": {
    "doc": "P2: Development Specification",
    "title": "Deliverables",
    "content": "Choose 3 user stories from your user stories in P1 and have an LLM expand them into dev specs. Your team must produce a spec for each of the 3 that includes the following sections with enough detail that you (or someone else) could implement it: . | Header | Architecture Diagram . | Specify where the components run (e.g., client, server, cloud, etc.). | Specify which information flows between components. | . | Class Diagram | List of Classes | State Diagrams | Flow Chart | Development Risks and Failures | Technology Stack | APIs | Public Interfaces | Data Schemas | Security and Privacy | Risks to Completion | . Two of the three user stories should be independent of one another, however, the all dev specs must reflect that they are implemented in the same application. The third user story must be dependent on one of other two, i.e., the stories are intertwined somehow (e.g., one implements a shared text editor and the other implements a way to make text in that editor bold). Practically for this assignment, the third user story’s dev spec may require you to make modifications to the dependent user story’s dev spec in order to add it to the plan. We noticed that it’s easy for the LLM to create inconsistencies between the sections in the dev spec. For example, there may be more classes shown in the class diagram than described in the List of Classes. That’s something you’ll have to look for and fix before turning in your assignment. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#deliverables",
    "relUrl": "/projects/p2.html#deliverables"
  },"48": {
    "doc": "P2: Development Specification",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The three user stories from P1 that you chose to expand into a dev spec, listed at the beginning of your document. | Add the user stories to GitHub and turn in the links to each user story. | . | First dev spec document containing all the sections above. Each section should have rationale to justify your decisions. After each section, copy-paste the chat log showing your prompts and the LLM’s responses. | Commit this dev spec into your GitHub repo and turn in the link to it. | . | Second dev spec document containing all the sections above. Each section should have rationale to justify your decisions. After each section, copy-paste the chat log showing your prompts and the LLM’s responses. | Commit this dev spec into your GitHub repo and turn in the link to it. | . | Third dev spec document (this is the one dependent on one of the previous two user stories) containing all the sections above. Each section should have rationale to justify your decisions. After each section, copy-paste the chat log showing your prompts and the LLM’s responses. | Add an explanation of how the other user story’s dev spec was modified to accommodate this user story’s features. | Commit this dev spec into your GitHub repo and turn in the link to it. | . | A 1–2 paragraph reflection on how useful the LLM was in helping you create the dev specs, and what parts required the most human correction/reprompting. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html#turn-in-instructions",
    "relUrl": "/projects/p2.html#turn-in-instructions"
  },"49": {
    "doc": "P2: Development Specification",
    "title": "P2: Development Specification",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p2.html",
    "relUrl": "/projects/p2.html"
  },"50": {
    "doc": "P3: Frontend Development",
    "title": "Project 3: Frontend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#project-3-frontend-development",
    "relUrl": "/projects/p3.html#project-3-frontend-development"
  },"51": {
    "doc": "P3: Frontend Development",
    "title": "Learning Goals",
    "content": ". | Learn how to transform development specifications into a working user interface. | Learn how to use Figma’s AI tools to create mockups. | Learn how to collaborate with LLMs to generate frontend code, while refining and debugging the output, with a mocked backend. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#learning-goals",
    "relUrl": "/projects/p3.html#learning-goals"
  },"52": {
    "doc": "P3: Frontend Development",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you will use an LLM to implement the front end of your application. Begin by creating polished UI/UX mockups in Figma for your user stories. Then, you’ll use those mockups and the development specifications to use LLMs to generate the frontend. Since the backend isn’t fully implemented yet, you will need to mock the backend to simulate functionality. The emphasis here is on getting something real and visual, even if it’s only partially functional. By the end of this sprint, you’ll have mockups, a working frontend implementation, and mocked backend to power the interface. Remember, use the LLMs as much as possible to generate the deliverables. You may not modify any generated graphics or code directly, only by prompting the LLM. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#project-context",
    "relUrl": "/projects/p3.html#project-context"
  },"53": {
    "doc": "P3: Frontend Development",
    "title": "Deliverables",
    "content": "Choose two of the three user stories from P2: Development Specification whose front end you will implement. They must include one independent user story and one user story dependent on the first one. Note: If you are having second thoughts about the user stories you submitted for P1, you may update them. 1. UI Mockups in Figma . Create high-fidelity mockups for each of your two chosen user stories. | Include all states of the interface: e.g., empty state, loading, error, success, etc. | Include enough detail about the intended graphical design in your Figma project to help a developer to implement the appropriate CSS and layout code. For example, if your design needs to relayout in a specific way when the window is stretched or zoomed, please annotate the design with the behavior you want to see. | Write up the rationale for major design choices (e.g., navigation flow, component reuse, accessibility). | . Check in high-resolution screenshots of your mockups into your project’s GitHub repository. 2. Frontend Implementation . Implement the user stories in code using a popular frontend framework (e.g., React, Svelte). | Using your LLM, generate the front end code from your user stories, Figma mockups (with their design rationale and developer implementation guides), and development specifications. | Include responsive design for at least two screen sizes. | Ensure accessibility compliance with WCAG and alt-text for images where appropriate. | Ensure any backend functionality or data is mocked such that the frontend functionality can be demonstrated. | . Important: The code for both user stories must be generated into the same frontend application. Watch out for duplicated functionality, inconsistent class names, and incomplete interfaces. | Screen record yourself testing the frontend implementation in a web browser (include appropriate voiceover narration so we can follow what you’re trying to show). It should display correctly at your two different screen sizes. Use the browser’s debugger to accurately set the screen size during testing. Resize the browser window with your mouse/finger to test for proper layout logic. | Upload the screen recording to YouTube. | . Check in the frontend implementation to your GitHub repository. 3. Reflection . Write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in generating the frontend code? What did you like about the result? | What was wrong with what the LLM generated? What were you able to fix it easily? What problems were more difficult to fix? | How did you validate that the implementation was complete and correct? Did you use the LLM to help? | How did you test the functionality of the implementation? Explain the steps you took and why you did them. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#deliverables",
    "relUrl": "/projects/p3.html#deliverables"
  },"54": {
    "doc": "P3: Frontend Development",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The two user stories that you implemented. | Provide a link to the Figma project with your mockups. Be sure that the instructors have read access to this project or you will receive no points for this deliverable. | Provide links to each of the mockup’s high-resolution screenshots as they are checked into GitHub. | Link to the folder with the code in GitHub. | Link to the YouTube video of your application test. You may set its visibility to private, but be sure that the instructors have read access to it or you will receive no points for this deliverable. | A 1-page reflection. | Copy-paste logs of all LLM interactions you used during this sprint. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html#turn-in-instructions",
    "relUrl": "/projects/p3.html#turn-in-instructions"
  },"55": {
    "doc": "P3: Frontend Development",
    "title": "P3: Frontend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p3.html",
    "relUrl": "/projects/p3.html"
  },"56": {
    "doc": "P4: Backend Development",
    "title": "Project 4: Backend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#project-4-backend-development",
    "relUrl": "/projects/p4.html#project-4-backend-development"
  },"57": {
    "doc": "P4: Backend Development",
    "title": "Learning Goals",
    "content": ". | Learn how to transform development specifications into a working backend. | Learn how to collaborate with LLMs to generate backend code, while refining and debugging the output, with a real or mocked frontend. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#learning-goals",
    "relUrl": "/projects/p4.html#learning-goals"
  },"58": {
    "doc": "P4: Backend Development",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you implemented two user stories for the front end of your application. In P4, you will implement the backend of your application. Begin by reading over the user stories you chose to implement for P3. For each of these user stories, you had the LLM generate development specifications in P2. Look over the architecture plans for each of these development specs. First, if you haven’t done it yet, have the LLM harmonize the two architecture plans and diagrams to ensure that the LLM knows you are building a single backend for the application that can support both user stories. For each module in your architecture, decide whether it will be part of the frontend or backend. Recall that frontend components usually handle the application’s user interfaces and the business logic. The backend often handles data storage (separate data stores for each tenant), compute-intensive algorithms (e.g. machine learning, audio/video codecs, path routing), calls out to external backend services (e.g. speech transcription, image recognition, authentication, cryptography, etc.), and networking to and from other frontend UIs connected to the same backend. In P4, you only need to specify and implement the backend modules. By the end of this sprint, you’ll have a working backend implementation plus loads of documentation describing how it works. Recall that every module lives in a single backend and should make the same technical choices to minimize the number of redundant internal and external dependencies. Remember to use the LLMs as much as possible to generate your deliverables. You may not modify any generated code directly, only by prompting the LLM. !!! note Make sure your backend supports 10 simultaneous frontend users. Simultaneity means that all of those users’ frontend UIs are talking to the backend at the same time. Do not attempt to make your backend scale to more users. !!! note Consider whether you need to have a working frontend to tell if your backend works or not. It is ok to mock the frontend (from the backend’s point of view) if it helps you make timely progress. !!! note Your backends will (eventually) be deployed to Amazon Web Services (AWS). Let that influence your choice of external backend services, especially if the cost is zero or minimal. In P4, you need to mock any calls to external services. However in P5, you will be able to create an AWS account with $100-200 free credits and will be usable for 6 months (or until the credits are exhausted) to call those services. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#project-context",
    "relUrl": "/projects/p4.html#project-context"
  },"59": {
    "doc": "P4: Backend Development",
    "title": "Deliverables",
    "content": "You will implement the backend for the same two user stories that you implemented in P3. Remember that one of these user stories is independent and the other is dependent on the first one. 1. Update your Development Specs . Create new development specs for each of your two chosen user stories that have a single, harmonized backend specification, i.e. the specs assume that there’s a single backend that powers both user stories. | Include the entire development spec for each user story. | Have the LLM generate mermaid diagrams for any required diagram and add photos of those diagrams to your submission. | . 2. Specify the Backend . Architecture . | Create a single, unified architecture for the backend that supports both user stories. Write down a text description to describe it and draw it as a Mermaid diagram. Justify your design choices as if you were speaking to a senior architect with your company. | . Backend Modules . For every backend module in this architecture, do the following (with assistance from the LLM): . | Specify the module’s features. What can it do? What does it not do? These should be written to be understandable by a professional backend developer. | Design the internal architecture for the module. Write down a text description to describe it and draw it as a Mermaid diagram. Justify your design choices as if you were speaking to a senior architect with your company. | Define the data abstraction used in the module. If it helps you or the LLM to think about this formally, take a look at Reading 13 from MIT’s 6.005 class. | Determine the stable storage mechanism for the module (i.e. you can’t just use an in-memory data structure because your app might crash and lose its memory. Customers really hate data loss.) . | Define any data schemas required to communicate with any storage databases. | . | Define a clear, unambiguous API for external callers of this module. We suggest employing a REST API for any services accessible over the web. | Provide a list of all class, method, and field declarations. Identify which are externally visible and which are private to the module. | Draw a Mermaid class hierarchy diagram that shows the module-internal view of each class. | Use the LLM to generate the code for each class. | . Wrap it up . | Write and run the minimum required testing code to ensure that the user stories whose program path uses each module’s API works as expected. Don’t worry about exceptional cases for now. | Check your code into the GitHub repository for your project. | Check in any code you write to test the functionality of your module. | Create a README for your backend source code. | Describe every dependency on an external library, framework, technology, or service required (or optionally required) by the module. | What databases does this module create, read from, and write to? | Describe how to intall, startup, stop, and reset the backend services and data storage. Assume the user of these docs is a site reliability engineer who has been newly assigned to work with your team. | . | . 3. Reflection . Write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in generating the backend code? What did you like about the result? | What was wrong with what the LLM first generated? What were you able to fix it easily? What problems were more difficult to fix? | How did you convince yourself that the implementation was complete and accomplished your user stories? Did you use the LLM to help? | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#deliverables",
    "relUrl": "/projects/p4.html#deliverables"
  },"60": {
    "doc": "P4: Backend Development",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The two user stories that you implemented. | The two (updated) development specifications and mermaid diagrams for those user stories as in the Update your Development Specs section. | The specification and description of the unified backend architecture and its mermaid diagram. | For each module in your backend, provide its specification as in the Backend Modules section. | Provide a link to your source code in GitHub | Provide a link to your test code in GitHub | Provide a link to your backend’s README in GitHub | A 1-page reflection as in the Reflection section. | Copy-paste logs of all LLM interactions you used during this sprint. Identify the name and version of the LLM used. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html#turn-in-instructions",
    "relUrl": "/projects/p4.html#turn-in-instructions"
  },"61": {
    "doc": "P4: Backend Development",
    "title": "P4: Backend Development",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p4.html",
    "relUrl": "/projects/p4.html"
  },"62": {
    "doc": "P5: Testing",
    "title": "Project 5: Testing",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#project-5-testing",
    "relUrl": "/projects/p5.html#project-5-testing"
  },"63": {
    "doc": "P5: Testing",
    "title": "Learning Goals",
    "content": ". | Learn how to write unit tests using multi-shot prompting. | Learn how to run tests locally. | Learn how to automate test runs using GitHub continuous integration. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#learning-goals",
    "relUrl": "/projects/p5.html#learning-goals"
  },"64": {
    "doc": "P5: Testing",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you implemented two user stories for the front end of your application. In P4, you implemented two dev specs for the back end of your application. In P5, you will write unit tests for two core frontend and two core backend files/classes. By the end of this sprint, you’ll create four test files that unit test your application’s features. You will also create a test script to run the tests on your local machine. Finally, you will automate test execution so that it runs on GitHub every time someone commits code to the repository. You will learn to look at the results of those tests to make sure your code doesn’t break the build without you knowing about it right away. Remember to use the LLMs as much as possible to generate your deliverables. You may not modify any generated code directly, only by prompting the LLM. You should use formalized LLM prompts, such as those we introduced in class. These will make the LLM output more reliable. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#project-context",
    "relUrl": "/projects/p5.html#project-context"
  },"65": {
    "doc": "P5: Testing",
    "title": "Deliverables",
    "content": "You will begin by writing a test specification for two code files in the frontend of your codebase and unit tests for code files in the backend of your codebase. You should choose the most important core code files that enable your user stories to run. A test specification is an English-language document that describes the purpose of each function to be tested along with every program path that should be tested with a unique unit test. For each unit test, the document should describe the inputs to the function that are required to engage the desired program path and the expected output. Your goal should be 80% code coverage. This means that for each function to be tested, your unit tests will exercise at least 80% of the function’s possible execution paths. Don’t forget about exceptions! . Next, you will implement the spec by creating Javascript (or Typescript) unit tests for each function. Ensure that your tests are isolated to the frontend or backend; they should not test functionality that requires connecting across the network from the frontend to the backend or vice versa. If the function under test requires connecting to the other end, you must create mock objects that simulate the other end’s public interface. You will then create scripts to setup the application and run the unit tests on your own machine. Finally, you will create a GitHub Action that sets up and runs all of your unit tests whenever anyone commits code to the GitHub repository. 1. Choose the files you want to test . Look through the source code of your frontend and identify two code files that contain the most core functionality that implements the two frontend user stories. There must be at least 5 functions in each file. Look through the source code of your backend and identify two code files that contain the most core functionality that implements the two backend user stories. There must be at least 5 functions in each file. 2. Write the test specification . Ask your LLM to write one English-language test specification for each code file you plan to test. Each specification should contain a list of all functions in the code file, followed by a table of tests. Each row of the table should describe the purpose of the test, the test inputs to the function, and the test output that is expected if the test passes. You must write at least one unit test for every function. For example, you have a validateEmail(string address) function to test. One possible test may check whether GMail addresses are considered valid. The input address would be “realemailaddress@gmail.com” and the expected output would be the boolean “true”. 2. Create your unit tests . Most projects that are written in Javascript or TypeScript should use the Jest unit testing framework. You may use another framework, but you may not simply manually test the code. You must use a testing framework. If you are building a VS Code extension, you must use VS Code’s preferred testing framework, Mocha. See VS Code’s Extension Testing Instructions on how to set it up. First, install the test framework into your application. Create a tests/ folder and keep all of your test files there. Next, have your LLM read the test specification document and generate the required unit tests. If a mock is needed, have your test framework do it for you. | Jest | Mocha uses SinonJS to generate mocks. | . Generate unit tests for each test specification using your LLM. At the end, you should have four test files. !!! note We strongly suggest that you use the LLM to generate only one unit test at a time. We have learned from experience that trying to get the LLM to do the entire thing in one prompt will lead to incorrect output. !!! note You will be graded on how well you prevent the LLM from hallucinating nonsensical test cases or creating duplicate or significantly overlapping test cases. The LLM must not generate test cases for functions and functionalities that do not exist. 3. Run the tests on your own machine . Ask the LLM to generate an npm script to setup the frontend or backend of your application, as needed, and then execute the tests with your testing framework. How did it go? Did every test pass? If not, use your LLM to give you a plan on how it wants to fix the bugs (ask it for three alternative fixes). Choose the bug fix you like and have the LLM make the change. Did your test case pass? Congratulations! If not, try again. 4. Check code coverage . Check to make sure that you have achieved at least 80% code coverage in each test file. Use your test framework to do this — the LLM will not be able to check this for you. | For Jest, read through this blog post to see how to check coverage. | For Mocha, read through this blog post. | . Check in your test code to the GitHub repository for your project. 5. Automate your tests . Adding continuous integration for quality assurance is a critical part of software development. Although you have tested your system manually, you are now setting out to establish sustained practices that can be used moving forward as you iterate over and continue to improve your system. Create GitHub Actions that run your tests on every commit. You will need to create two YAML workflow files in the .github/workflows directory. The first, for your frontend code, should be named run-frontend-tests.yml and the second, for your backend code, named run-backend-tests.yml. Each YAML file should check out your code, set up the application environment (e.g., install Node.js if needed), install dependencies, and then execute your tests. | For CI instructions to run tests with Jest, check out Dennis O’Keefe’s blog. | For CI instructions with VS Code extensions, check out these instructions. | . Check in your YAML files to the GitHub repository. Test out your CI code by making a change to one of the source code files in the frontend and one backend source code file. Commit the change to Git, push to the remote repository, create a pull request on GitHub, and accept the pull request. Finally, go to the GitHub repository on the web and click on teh Actions tab on the navigation bar. You’ll see all the workflows on the left and workflow runs on the right. If you have a green checkmark next to a workflow run, that means it worked! If there is a red cross, then it did not. Click on the workflow run to see exactly what got executed in GitHub’s “terminal window” and find out what went wrong. Fix the problem and try again until each of your two GitHub actions run successfully. Wrap it up . Edit the README.md file for your project. | Provide all the instructions needed for how to manually run the frontend tests on a developer’s local machine. Don’t forget to explain what frameworks and libraries need to be installed! | Provide all the instructions needed for how to manually run the backend tests on a developer’s local machine. Don’t forget to explain what frameworks and libraries need to be installed! | . 6. Reflection . Write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in generating the test specification? What did you like about the result? What was wrong with what the LLM first generated? What were you able to fix it easily? What problems were more difficult to fix? | How effective was the LLM in generating unit tests from the test specification? What did you like about the result? What was wrong with what the LLM first generated? What were you able to fix it easily? What problems were more difficult to fix? | How did you verify that the LLM correctly did what you asked? How did you use the test framework or the LLM to help you understand if everything was done correctly? | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#deliverables",
    "relUrl": "/projects/p5.html#deliverables"
  },"66": {
    "doc": "P5: Testing",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | The two code files you chose to test for your frontend. | The frontend test specifications. | Provide a Git repository link to the test code files that implement your frontend test specs. | Copy-paste in the test output from running your frontend tests. | Copy-paste in the code coverage report for your frontend test files. | The two code files you chose to test for your backend. | The backend test specifications. | Provide a Git repository link to the test code files that implement your backend test specs. | Copy-paste in the test output from running your backend tests. | Copy-paste in the code coverage report for your backend test files. | Provide a Git repository link to your run-frontend-tests.yml file. | Provide a Git repository link to your run-backend-tests.yml file. | Provide a GitHub link to a workflow run of run-frontend-tests that shows it ran successfully after frontend code was committed. | Provide a GitHub link to a workflow run of run-backend-tests that shows it ran successfully after backend code was committed. | Provide a link to your project’s README in GitHub. | A 1-page reflection as in the Reflection section. | Copy-paste logs of all LLM interactions you used during this sprint. Identify the name and version of the LLM used. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html#turn-in-instructions",
    "relUrl": "/projects/p5.html#turn-in-instructions"
  },"67": {
    "doc": "P5: Testing",
    "title": "P5: Testing",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p5.html",
    "relUrl": "/projects/p5.html"
  },"68": {
    "doc": "P6: Deployment",
    "title": "Project 6: Deployment",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#project-6-deployment",
    "relUrl": "/projects/p6.html#project-6-deployment"
  },"69": {
    "doc": "P6: Deployment",
    "title": "Learning Goals",
    "content": ". | Learn how to package an application for deployment to the cloud. | Learn how to deploy a frontend and backend application to Amazon Web Services (AWS) | Learn how to automate deployment using GitHub continuous deployment. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#learning-goals",
    "relUrl": "/projects/p6.html#learning-goals"
  },"70": {
    "doc": "P6: Deployment",
    "title": "Project Context",
    "content": "In P1, you defined requirements and user stories. In P2, you expanded some of those stories into detailed development specifications. In P3, you implemented two user stories for the front end of your application. In P4, you implemented two dev specs for the back end of your application. In P5, you wrote unit tests for two core frontend and two core backend files/classes. In P6, you will deploy the frontend and backend of your application to AWS. By the end of this sprint, you will set up a publicly visible deployment of your application. You will then automate deployment so that every time you commit code to your repository, GitHub will run the test cases and if successful, will deploy the updated application to AWS. Remember to use the LLMs as much as possible to generate your deliverables. You may not modify any generated code directly, only by prompting the LLM. You should use formalized LLM prompts, such as those we introduced in class. These will make the LLM output more reliable. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#project-context",
    "relUrl": "/projects/p6.html#project-context"
  },"71": {
    "doc": "P6: Deployment",
    "title": "Deliverables",
    "content": "You will begin by setting up your AWS account. You will need AWS access for all steps of this project. None of the steps in P6 should cost you any money, however the AWS account setup will likely require a credit card to be charged in case you incur any costs. Be assured that whenever we’ve done this before, we’ve spent at most 20-30 cents total. If you find that AWS has billed you anywhere near USD $1, immediately turn off any applications you have already deployed and reach out to the instructors for help. Next, you will set up your application to run with AWS Lambda. AWS Lambda lets you run server code without having to deal with actual server machines. It’s a “serverless” computing service. You will modify your backend to run on AWS Lambda. Your backend should publish its public interfaces via REST API. You will use AWS API Gateway to expose your public endpoints for web users (or applications) to interact with. Next, you will use AWS Amplify to host your frontend application. Amplify will store and serve static web assets, like HTML, CSS, and JS files, that comprise your application frontend. !!! note If you are building a VS Code Extension, you will deploy your frontend to the VS Code Extension Marketplace. Now is the time to implement integration tests. These are tests that exercise the frontend to backend (and vice versa) code paths in your app. You will learn to run these integration tests on localhost and in the cloud and run them on every checkin. At the end, you will set up GitHub actions to deploy your frontend code to Amplify and your backend code to Lambda after each pull request has been approved. 1. Create an AWS account . Go to the AWS Console and create an account. If one person on your team already has an AWS account, you can use that one. Log into the AWS Console with your new account. 2. Use AWS Lambda to run your backend code . To use Lambda, you will . | Write (slightly stylized) code that executes functions on certain events (e.g., the invocation of a given REST endpoint) | Package up your code (i.e., put it all in a ZIP file) | Upload the packaged code to AWS | . Ask your LLM to modify your backend code so that it executes as a lambda function. Eventually, that lambda function will execute when your REST API’s public interface endpoints receive post requests. To start with, though, you should become familiar with Lambda, then package up your Lambda code, deploy it, and make sure you can invoke it using the AWS command-line interface (CLI). 1. Use the AWS console to experiment with Lambda . Ask your LLM for detailed instructions on how to use AWS Lambda to set up a dummy application that you can invoke. This will help you get familiar with AWS Lambda when you have to set up your own application. If your LLM proves unhelpful, read the official AWS documentation. 2. Package and invoke your Lambda code using the AWS CLI . Ask your LLM to teach you how to package your Javascript code for deployment on AWS and upload it with the AWS CLI. If your LLM is unhelpful, you can read the official AWS documentation. There is some additional documentation in the Lambda section of the official AWS API Gateway tutorial. 3. Integrate your Lambda code with the REST API . Ask your LLM to teach you how to modify the Lambda code so that it is invoked by requests to your API’s public interface functions. If your LLM is not helpful, read the Lambda section of the official AWS API Gateway tutorial. 3. Use API Gateway to create a REST API . AWS API Gateway makes it simple to spin up an API. A web API exposes endpoints that users (or applications) can interact with. You are going to create a REST API for the backend of your app that exposes all of your public interfaces functions. Ask your LLM to teach you how to create your REST API with AWS API Gateway. If your LLM is unhelpful, read through this tutorial. After setting up AWS API Gateway, locate the API call logic in your frontend code (where it currently calls localhost). Replace the localhost URL with the API Gateway endpoint URL. Note, edit the code carefully to preserve a version of the app that runs locally for easier testing. 4. Host your frontend code . AWS Amplify makes it easy to e.g., deploy app frontends and integrate with version control. In this assignment, you will use Amplify to manage deployment of the frontend of your calculator application. Your task is to set up Amplify to host the application frontend. To complete this part of the assignment, refer to the AWS Amplify tutorial for deploying a web application by connecting Amplify to your GitHub repository. If you are building a VS Code Extension, do not follow the AWS Amplify directions. Instead, you will deploy the frontend of your extension to the VS Code Extension Marketplace. To complete this deployment, you will follow these instructions. First, install the vsce command line tool, create an Azure DevOps personal access token, define your team as a publisher, and publish your extension. Make sure to say that the cost of your extension is USD $0. Be sure to have your LLM do all this work for you! . !!! note When this course is over, please remember to unpublish your extension from the VS Code Extension Marketplace. 5. Integration testing . Ask your LLM to write an English-language test specification for the code pathways that require the execution of frontend and backend code together. Each specification should contain a list of all functionality that needs to be tested, followed by a table of tests. Each row of the table should describe the purpose of the test, the test inputs to the function, and the test output that is expected if the test passes. You must write at least one integration test for every code pathway that spans frontend and backend functionality. Generate integration tests for each row of your test specification using your LLM. Test out your full app on your local machine first. Run your npm scripts to setup and start the frontend and backend of your application on localhost, then execute the integration tests with your testing framework. !!! note Some integrations tests will fail when run on localhost, but work fine when deployed on the Internet. Please take a note of these and condition their execution to run only when deployed in the desired environment. Finally, create a new test configuration that uses the URLs of the deployed frontend and backend hosted by the AWS Cloud. Rerun your integration tests on your deployed app and fix any bugs that pop up until the entire app is working as desired. 6. Automate your integration tests . Ask your LLM to create a new GitHub Action that runs your integration tests on every commit. Store the YAML workflow file in the .github/workflows directory. Name it run-integration-tests.yml. It should check out your code, set up the application environment for frontend and backend (e.g., install Node.js if needed), install dependencies, and then execute your tests. | For CI instructions to run tests with Jest, check out Dennis O’Keefe’s blog. | For CI instructions with VS Code extensions, check out these instructions. | . Check in your YAML file to the GitHub repository. Ask your LLM to test out your CI code by making a change to one of the source code files in the frontend and one backend source code file. Commit the change to Git, push to the remote repository, create a pull request on GitHub, and accept the pull request. Finally, go to the GitHub repository on the web and click on the Actions tab on the navigation bar. You’ll see all the workflows on the left and workflow runs on the right. If you have a green checkmark next to a workflow run, that means it worked! If there is a red cross, then it did not. Click on the workflow run to see exactly what got executed in GitHub’s “terminal window” and find out what went wrong. Fix the problem and try again until each of your two GitHub actions run successfully. 7. Adopt good GitHub hygiene . Git is a very powerful and flexible version control system. One best practice you will follow is to create a new feature branch whenever you start working on a new coding task. Never work directly on the main branch. When your feature is done and your CI GitHub Actions (unit tests and integration tests) have passed their tests, create a pull request on GitHub to push the changes from the feature branch to main. As configured by default, anyone with access to your repo can push whatever garbage they want to the main branch. That’s not good! It’s important to make sure code that actually gets deployed has been thoroughly tested and reviewed (to catch everything from mistakes to intentional back doors!). In this assignment, you must block merges to main until your code is reviewed and passes CI. To protect your main branch, navigate to the Settings tab in your GitHub repo and click on Branches (on the lefthand side). You’ll see two options: (1) Add branch ruleset and (2) Add classic branch protection rule. Add a classic branch protection rule that protects main from direct, unreviewed commits: first check the box to require a pull request before merging and second check the box to require status checks to pass before merging. Select your CI testing workflows here as the relevant status checks. Finally, . 8. Use Github actions to automatically deploy on each push to main . After getting hands on experience with each service, you will use a Github action to deploy updates automatically on each push to your main branch. The CD pipeline will perform the following tasks: . | Deploy the packaged backend Lambda code. | Redeploy the frontend (to Amplify or the VS Code Extension Marketplace). | . In order to do this, you will need to allow Github to authenticate to AWS. Follow the Github documentation to safely use your AWS secrets in CD. This AWS blog post describes some (basic) best practices for generating and handling AWS authentication secrets in CI; navigate to the “Configuring AWS credentials in GitHub” section of the tutorial. Deploying backend code . Your LLM should create a Github workflow named deploy-aws-lambda.yml that takes the follow steps: . | Checks out the code, sets up Node, and installs dependencies. | Packages the code for lambda deployment. | Uses the AWS CLI to update the lambda code (giving the CLI access to your authentication secret and AWS region through the environment). | . Deploying frontend code . Your LLM should create a Github workflow named deploy-aws-amplify.yml that takes the following steps: . | Checks out the code, sets up Node, and builds the code. | Triggers AWS Amplify to redeploy the latest frontend version from your repository. See the AWS documentation for more. | . If you are publishing a VS Code Extension, your workflow will be named deploy-extension.yml. It should simply package up your extension and publish it to the marketplace. 9. Wrap it up . Edit the README.md file for your project. | Provide instructions for web users of your app to run your application. | Provide all the instructions needed for a random person on the Internet who forks your codebase to set up AWS to deploy your application. | . 10. Reflection . Without your LLM, write a 500-word (i.e., one-page) reflection on: . | How effective was the LLM in helping you understand how to deploy your app? What did you like about it? What was wrong with it? How many times did you have to change your prompt to get it to explain the information in a way you could understand? | How difficult was it to change habits and stop committing directly to main? Did you have to ask your team to change their practices to ensure minimal delays for accepting your pull requests? How do you feel about this feature branch practice? What are the pros and cons? | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#deliverables",
    "relUrl": "/projects/p6.html#deliverables"
  },"72": {
    "doc": "P6: Deployment",
    "title": "Turn-in Instructions",
    "content": "Please turn in a single document that contains these parts: . | Deploy your app. Keep it deployed until the instructors let you know that they’ve checked this part out. | Provide a link to your Amplify frontend deployment or VS Code Extension Marketplace extension URL. | Provide a link to your Lambda backend REST function. | . | The integration test specification. | Provide a Git repository link to the test code files that implement your integration test specs. | Copy-paste in the test output from running your integration tests on localhost. | Copy-paste in the test output from running your integration tests in the cloud. | Provide a Git repository link to your run-integration-tests.yml file. | Provide a Git repository link to your deploy-aws-amplify.yml file (or deploy-extension.yml as appropriate). | Provide a Git repository link to your deploy-aws-lambda.yml file. | Provide a link to your project’s README in GitHub. | A 1-page reflection as in the Reflection section. | Copy-paste logs of all LLM interactions you used during this sprint. Identify the name and version of the LLM used. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html#turn-in-instructions",
    "relUrl": "/projects/p6.html#turn-in-instructions"
  },"73": {
    "doc": "P6: Deployment",
    "title": "P6: Deployment",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p6.html",
    "relUrl": "/projects/p6.html"
  },"74": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Project 7: Final Demo &amp; Postmortem",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#project-7-final-demo--postmortem",
    "relUrl": "/projects/p7.html#project-7-final-demo--postmortem"
  },"75": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Learning Goals",
    "content": ". | Learn how to clearly and professionally present a technical software project. | Learn how to communicate architectural decisions, deployment processes, and CI/CD pipelines. | Learn how to conduct a structured postmortem analyzing team practices, project successes, and failure points. | Learn how to prepare a high-level demo of a deployed application. | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#learning-goals",
    "relUrl": "/projects/p7.html#learning-goals"
  },"76": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Project Context",
    "content": "Across P1–P6, you designed, implemented, tested, and deployed a full-stack application. Project 7 is your final sprint, in which you demonstrate your deployed app and present a reflective postmortem on your development process. You will give a 12-minute team presentation that includes: . | A live demo of your deployed application | An overview of your testing &amp; deployment process | A structured postmortem (lessons learned, surprises, team process, what you’d do differently) | . This presentation is your opportunity to demonstrate both your functional application and your mastery of the engineering practices taught in this course. As with prior sprints, you should use LLMs to generate materials, including slides, scripts, and outlines. You may revise only through prompting. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#project-context",
    "relUrl": "/projects/p7.html#project-context"
  },"77": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Deliverables",
    "content": "1. Final Presentation (12 minutes per team) . Your presentation must follow this structure: . (1) Live Demo (6 minutes) . Show the core features of your deployed application. At minimum: . | Walk through your primary user stories. | Demonstrate frontend → backend integration. | If applicable, demonstrate any nontrivial workflows (authentication, complex functionality, etc.). | Show that your frontend is active on Amplify (or VS Code Extensions Marketplace). | Show that your backend Lambda/API Gateway endpoints are live. | . (Have a backup plan or recorded demo in case AWS decides to be mischievous during your time slot.) . (2) Testing &amp; Deployment Process (2 minutes) . Explain the engineering behind your deployment environment: . | How your GitHub Actions workflows run your tests. | How your CD pipeline deploys your backend to Lambda and your frontend to Amplify (or the Extension Marketplace). | Where secrets are stored and how permissions are granted. | How integration tests run in CI and how failures impact deployment. | . (3) Postmortem (4 minutes) . Reflect on your engineering process: . | Successes: What went well in development, testing, deployment, and team collaboration? | Failures / surprises: What broke? What caused major delays? What took far longer than expected? | Process evaluation: . | Did LLM-driven development help? | Did your feature-branch workflow work smoothly? | How did your testing strategy evolve? | . | Lessons learned: . | What would you do differently if starting again? | What best practices will you adopt in future software projects? | . | . Your postmortem should be honest, analytical, and reflective. 2. Slide Deck . Prepare a slide deck (Google Slides, PowerPoint, or PDF) containing: . | Title slide: team name, app name, team members | App overview: problem statement, target user | Demo roadmap | CI/CD overview with diagrams and workflow charts | Deployment overview (LLM-generated AWS architecture diagram encouraged) | Postmortem: successes, failures, lessons | Future work: 3–5 possible next features | . All slides must be generated using LLMs and refined only through prompting. 3. Postmortem Write-Up (1-2 pages) . Submit a written postmortem expanding on your presentation reflection. Include: . | Problem summary: what you built and why | Technical accomplishments: features, architecture, test coverage, deployment stack | Team workflow: branching strategy, communication, division of labor | Bottlenecks &amp; failures | LLM usage analysis . | How effective were LLMs? | How many prompt iterations were needed for key tasks? | How did you improve confusing or incorrect outputs? | . | Roadmap for future work | . This document must be drafted entirely with LLM support. 4. Turn-In Instructions . Submit a single document or folder containing: . | Link to your deployed frontend | Link to your deployed backend API endpoint | Link to your slide deck | PDF or MD version of your postmortem write-up | Copy-paste of all prompts used for slides, scripts, diagrams, and the write-up | Names and versions of all LLMs used | A short statement verifying that all artifacts were LLM-generated and edited only via prompting | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#deliverables",
    "relUrl": "/projects/p7.html#deliverables"
  },"78": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "Evaluation Criteria",
    "content": "Your grade will be based on: . | Technical clarity of your application, testing, and deployment | Completeness and smoothness of your live demo | Depth and insight of your postmortem reflection | Professionalism of your presentation and slides | Compliance with LLM-generation requirements | Adherence to the 12-minute time limit | . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html#evaluation-criteria",
    "relUrl": "/projects/p7.html#evaluation-criteria"
  },"79": {
    "doc": "P7: Final Demo & Postmortem",
    "title": "P7: Final Demo & Postmortem",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/p7.html",
    "relUrl": "/projects/p7.html"
  },"80": {
    "doc": "Project",
    "title": "Project",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/projects/",
    "relUrl": "/projects/"
  },"81": {
    "doc": "Staff",
    "title": "Course Staff",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/#course-staff",
    "relUrl": "/staff/#course-staff"
  },"82": {
    "doc": "Staff",
    "title": "Instructors",
    "content": "Martin Kellogghe/him . martin.kellogg@njit.edu . Office Hours: Wednesdays, 1:30-2:30pm, GITC 4314; or by appointment. To schedule an appointment with me, check my calendar and add a calendar event in any open spot that works for you during regular business hours (Monday to Friday, 9:30-5:30). You must schedule meetings at least 24 hours in advance, or I will automatically decline them. In your invitation, you must, at a minimum, 1) invite me to the event, 2) add a note to the event description that mentions the code of this class (e.g., “CS 485”) and what you’d like to meet about, and 3) specify whether you would prefer the meeting to be in-person or remote. It is unprofessional to schedule a meeting with me unless you have exhausted your other options to solve the issue (for example, don’t schedule a meeting with me about a homework issue until you have attended a TA’s office hours and asked there). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/#instructors",
    "relUrl": "/staff/#instructors"
  },"83": {
    "doc": "Staff",
    "title": "Teaching Assistants",
    "content": "Chun Jie (Michael) Chong . cc255@njit.edu . Office Hours: TBD . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/#teaching-assistants",
    "relUrl": "/staff/#teaching-assistants"
  },"84": {
    "doc": "Staff",
    "title": "Staff",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/staff/",
    "relUrl": "/staff/"
  },"85": {
    "doc": "Tutorials",
    "title": "Tutorials",
    "content": " ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/",
    "relUrl": "/tutorials/"
  },"86": {
    "doc": "Ubuntu Setup Guide",
    "title": "Ubuntu Setup Guide",
    "content": "This is a software engineering course. There a focus on reading code and using large systems to accomplish tasks, because real systems are large—too large for you to hold their entire specification or codebase in your head, almost certainly. In this course, you will be expected to develop and maintain programs and scripts in multiple languages using multiple tools. As a result, we want to help you prepare a suitable development environment for the assignments in this course—your local environment might work, but all the assignments are guaranteed to work in Ubuntu 22.04. This tutorial will guide you in setting up an Ubuntu 22.04 environment. This tutorial will help you create a development environment that matches the autograder environment. If you choose to deviate from the suggested x86_64 Ubuntu 22.04 environment, you may encounter corner cases that cause test cases to fail on the autograder. In some cases, the staff may direct you to set up an Ubuntu 22.04 Virtual Machine if you have not done so and are stuck on some assignments. Ultimately, it is your responsibility to read documentation and install supported tools. This tutorial is meant to help you walk through the creation of an x86_64 Ubuntu 22.04 environment. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html",
    "relUrl": "/tutorials/ubuntu.html"
  },"87": {
    "doc": "Ubuntu Setup Guide",
    "title": "Two Options — Local or Cloud",
    "content": "There are two options that this tutorial covers: . | Option 1: Local: Set up a local Ubuntu 22.04 Virtual machine on your computer. This is the most popular option for individual assignments, but the individual assignments typically work in most environments (so you probably don’t need to do this unless you run into a problem). It has a nice UI that makes it easy to navigate. | Some students may have WSL Ubuntu set up. It is a different version of Ubuntu and may or may not work for this class: we recomend that you follow the instructions below if you run into trouble. However, your experience setting it up will help you here! | Some student reports that VirtualBox is not compatible with the new Macbooks (e.g., with M1 and M2 chipsets). If you are using such a Macbook, you may have to select the Option 2 below and use the Cloud instead of your local machine. | Some students have experience with docker. Unfortunately, docker will not suffice here (but experience with it will help you): follow the instructions below. | Some students already have other versions of Ubuntu installed. Everything will probably work fine on these other versions, but again if you run into trouble you should follow these instructions. | . | Option 2: Cloud: Set up an Amazon EC2 cloud instance with Ubuntu 22.04 running on it. This option will work if you have a slower or older computer. Start early; Amazon takes up to 24 hours to verify cloud computing accounts. This option involves more of a command-line interface but typically runs some course tools a bit faster than local machine. | . Both options should work with all assignments in this course. Option 1 (local VM) will have you install VirtualBox on your computer, download an Ubuntu 22.04 installation image, and install x86_64 Ubuntu 22.04 in your virtual machine. A reasonably modern computer (e.g., at most 5 years old) should be able to run a VM guest without issue. However, some students report that the VM executes too slowly (e.g., the mouse is laggy, keystrokes are missed, programs take too long, etc.). If your VM guest is too slow, you can consider using Option 2 instead (see below). First, you may want to read the summary of virtual machines and cloud computing below. Even if you are familiar with the concepts from previous experiences, this course may use slightly different terminology, and I recommend that you skim the material (click on the box below to see the background material). Background: Virtual Machines and Cloud Computing A Virtual Machine is an emulation of a computer system. Loosely, you can think of a VM as a program that can run an entire virtual computer system. Virtual machines are powerful software systems that enable running software designed for one operating system inside another operating system. For example, you can use your Windows host computer to run a Virtual Machine that contains a Linux operating system. Consider the image below: . This is a Windows 10 host_computer running three different Virtual Machine _guests. The guest instances are complete (virtual) environments that are isolated from the host. All of the guests share the host’s hardware as they execute — each window in the screenshot above lets you interact with a separate emulated guest. Thus, even though the host is a Windows computer, you can use one of the guests to execute Linux software inside the guest. Virtual Machines can be used in many combinations. You can have a Windows, Linux, or Mac host computer, and run arbitary numbers and combinations of Linux and Windows guests. Finally, guests are stored as files in the host computer — this means you can move your VM guest from one host to another by transferring that file around. Option 1 (“Local”): You can choose to set up and run your own Ubuntu 22.04 virtual machine locally. This will allow you complete all of the assignments in this course within that virtual machine. However, some students report that the VM guest runs too slowly (especially if you do not have enough RAM in your computer). If you find that a local VM is too slow, you can use Option 2 instead. Virtual machines are a critical part of Cloud computing. You can “rent out” computing resources from a provider like Amazon EC2 or Microsoft Azure to do whatever computation you might need. Amazon EC2 and Microsoft Azure both offer you virtual machine guests that run on their hardware. Thus, you can get access to a virtual machine running whatever operating system you like to run a variety of software. Option 2 (“Cloud”): If you find that a local VM is too slow, you can instead get a free Ubuntu 22.04 virtual machine from Amazon EC2 (or any other cloud computing provider, but this specification walks you through how to do it on EC2). Amazon EC2 (“Elastic Cloud Compute”) is a service that lets you buy and configure virtual machines. Option 2 has you setup and launch an Ubuntu 22.04 cloud instance (this is free if you are a student). Many of the assignments are easier to complete on Linux or similar command-line systems. If you’re not comfortable with such systems, the background tab below on Linux Fundamentals might be useful: . Background: Linux Fundamentals Vanderbilt professor Kevin Leach has prepared a (long) video that provides a gentle introduction to a number of Linux concepts that are relevant to this course. This video is optional, but you may find it useful if you are less familiar with the Linux environment. There are timestamps in a comment below the video that contain points of interest, such as: . | terminals | environment variables | scripts in the shell | compiling programs from source | using ssh | . The first half is more about terminals and shells (why do we have to type ./a.out? why can’t we just say a.out?), and the second half is more about compiling programs from source. The video also covers elinks in particular, which is a terminal-based browser program (using elinks is not required for this course, but it might be helpful if you choose to use a cloud computer and need to access the web to e.g., submit an assignment). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#two-options--local-or-cloud",
    "relUrl": "/tutorials/ubuntu.html#two-options--local-or-cloud"
  },"88": {
    "doc": "Ubuntu Setup Guide",
    "title": "Option 1 — Local Virtual Machine",
    "content": "You can set up your own local virtual machine for free. However, before you proceed, consider checking whether your CPU supports accelerated virtualization. If your CPU does not support virtualization extensions, then your VM may run slowly. If that’s the case, consider Option 2 for this assignment instead. You will need: . | A copy of VirtualBox for your operating system. General download link (look under “Platform Package” or similar). | A copy of 64-bit Ubuntu 22.04 (Download — 64-bit is required here: don’t use 32-bit). This is a large .iso file that might take a long time to download. You don’t need it until part way through the installation process, but you should start the download now. | When something goes wrong during this installation, we recommend that you search this webpage and also look for previous posts on the forum. Some solutions may be listed a little lower on the webpage than when you encounter them. Macs typically give students many more issues than Windows machines, so if you are a student using a Mac, looking to see if the issue is already addressed can be a big time saver. | . VirtualBox . VirtualBox is a Virtual Machine Manager. You install VirtualBox on your host computer (i.e., as a regular program or app). Then, you use VirtualBox to create a virtual machine guest. Once you have created a guest, you install Ubuntu 22.04 inside of the guest. Then, you can start the guest and have a complete Ubuntu 22.04 environment within that guest. Isolation in Virtual Machine Guests Note well: Implicit here is that the guest is, to some extent, isolated from the host. This is very important and entails a number of conceptual hurdles if you are not used to virtualization: . | The clipboard is isolated. That is, if you copy something from your host environment, you cannot paste it inside the guest environment. This is because the VM guest is a completely independent operating system environment from your host. | Typing and mouse movements have to be captured by the guest. | If you want to download a file to use in the guest, you must do so from the guest environment. Unless you set up a shared drive (which is not required), you have to download or create files within the guest environment rather than the host environment. | . Installing VirtualBox . You can install VirtualBox with the default settings. For your reference, screenshots of the course staff completing the installation are shown below: . If you receive a “The installation failed.” message on a Mac, you can resolve the issue by going to Security and Privacy and allowing the installation. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#option-1--local-virtual-machine",
    "relUrl": "/tutorials/ubuntu.html#option-1--local-virtual-machine"
  },"89": {
    "doc": "Ubuntu Setup Guide",
    "title": "Creating a Virtual Machine",
    "content": "After installing VirtualBox, it will display the main VM Management console, which we can use to create a New Machine (see circular highlight in upper left): . Next, configure your virtual machine. Select “Type” as “Linux” and “Version” as “Ubuntu 64-bit”. (If you only see options for 32-bit and do not see options for 64-bit, you will not be able to complete this option and will instead have to use the Amazon EC2 Cloud instance option. This happens to some students with older 32-bit Mac machines that cannot emulate 64-bit guests.) You can name your VM whatever you like (though note that the name in the picture is from a different course than this one that uses the same setup). We recommend using at least 2048MB of Memory. See highlights below: . Next, it will ask you to create a storage device. Remember, you are creating a virtual machine — an entire simulated computer. That includes simulating a hard disk for storage. This is represented as a large (&gt; 20GB file) on your host computer. We recommend at least 20GB, and you can choose “dynamically allocated” to save space: . After this step, you will have successfully created a Virtual Machine. Now, you have a bare system with nothing installed on it. Next, we must install an OS on it to run the VM. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#creating-a-virtual-machine",
    "relUrl": "/tutorials/ubuntu.html#creating-a-virtual-machine"
  },"90": {
    "doc": "Ubuntu Setup Guide",
    "title": "Installing an OS in the Guest VM",
    "content": "After creating a VM, we need to install Ubuntu 22.04 on it to help run software. Remember downloading a large .iso file as indicated above when we discussed downloading Ubuntu (if you missed it, you should go back and download it now)? This is a Disk Image — we need to attach the OS Disk Image into the VM. On the VM Management window, right click the VM you just created, and click “Settings”: . Next, click on “Storage”, then click on the “Empty IDE Controller” (your version of VirtualBox may call this a CD drive, Optical storage drive, or similar. Regardless, you should be able to select a virtual disk image). Click the Disk icon, then click “Choose disk file…”: . Then, select the Ubuntu .iso file you downloaded earlier. This places the Ubuntu 22.04 installation medium in the VM’s disk drive. Click OK, and you are now ready to start your VM from the Manager (note: the image below is from a previous version of the course that used Ubuntu 16.04 instead of Ubuntu 22.04. When you do this, your .iso file must be for Ubuntu 22.04.): . If you receive a “Kernel driver not installed” error, follow these instructions online for how to resolve the issue. (The image below shows the “Kernel driver not installed” error, for your reference.) . The Virtual Machine will now boot and load the Ubuntu 22.04 installation. The VM opens in a new window — you can think of this window as the virtual “screen” that lets you see what’s happening in the emulated system. You can follow through the normal Ubuntu 22.04 installation: . Note: If the VM asks you to select a startup disk, you need only select your .iso file. You want the VM to boot from the installation media so you can install Ubuntu within the guest. We recommend opting to install updates and third-party software. It should not affect the system one way or another: . You can select “Erase disk and install Ubuntu”. This is only referring to erasing the “virtual” disk you created earlier with the VM. If you are receiving an error like the “following disc images couldn’t be opened for the reason of no mountable file systems”, you may be able to resolve the issue by following recommendations online . Note: Sometimes during installation, students find that a window is too large to display all the buttons. You can actually move the window like normal to reveal the Continue button (just click to drag the window like any other — the window inside the Virtual Machine, not the Virtual Machine itself): . Next, it will ask you to create an account for logging in. You can put whatever credentials you like here — it will not have any bearing on your host computer. This is merely for an account on the guest VM. Just make sure you don’t forget whatever password you choose! . Next, you just wait a bit for the OS to install inside the guest. It might take a few minutes to complete. Eventually, you’ll see a screen asking you to remove installaton media and restart. You can just click restart (on the guest) and you’ll be all set! . Virtual Machines and Mice While you’re running the VM, you may find that it “takes control” of your mouse and keyboard, and you aren’t able to leave the window. If this happens, press CTRL+ALT to release control from the VM window. (The keystrokes may be different on Mac OS). ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#installing-an-os-in-the-guest-vm",
    "relUrl": "/tutorials/ubuntu.html#installing-an-os-in-the-guest-vm"
  },"91": {
    "doc": "Ubuntu Setup Guide",
    "title": "Install VirtualBox Additions",
    "content": "One thing you’ll notice when you install your VM successfully is that the window is small. In our opinion, one thing that makes the experience way better is the VirtualBox Additions package. It provides a number of “Quality of Life” features when using VMs. It’s essentially a helper program you install inside the VM guest that makes it “aware” that it’s running inside of a VM. To install, click “Devices”, then “Insert Guest Additions CD Image…” . Eventually, a window pops up asking if you want to run the media. Just click Run. After installing, you can reboot the VM image. One more step to make sure gcc (a compiler for C and C++ programs) is installed in your guest. In a terminal, use: . sudo apt-get update sudo apt-get install gcc . You’re all set! . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#install-virtualbox-additions",
    "relUrl": "/tutorials/ubuntu.html#install-virtualbox-additions"
  },"92": {
    "doc": "Ubuntu Setup Guide",
    "title": "Option 2 — Amazon EC2",
    "content": "Note well: This option will take longer than Option 1. Amazon AWS accounts can take up to 24 hours to verify, which means you may have to wait before you can use it for an assignment or demo. Start early! . You will need a Secure Shell (SSH) client. SSH allows you to remotely interact with a server. (If you’ve never used SSH before, scrolling back up the page and watching the appropriate section of the “Linux Fundamentals” video might help.) When you SSH to a remote computer, you have access to a command prompt that runs software on that computer. We will be using SSH to interact with a virtual machine we create in the cloud with Amazon EC2. On Windows, I recommend using WSL to run SSH. You can also use PuTTY. On Mac, you should already have ssh installed. Open a terminal and you can run ssh. On Linux, you can use ssh, but you may need to install it first (e.g., sudo apt-get install openssh or similar, depending on your platform). It is your responsibility to understand how to use SSH, though we give some pointers below. Amazon EC2 is a cloud computing service that allows you to rent virtual machines that you can ssh to and run programs like any other computer. Amazon offers a large number of cloud-based services all under the umbrella of AWS (Amazon Web Services). EC2 is a subset of AWS. In this section, you will create an AWS account to manage EC2 virtual machines. You can sign up for a new account on Amazon EC2, and in doing so, you get 12 months of free access to a virtual machine that is enough to complete the assignments in this course. If you do not already have an Amazon EC2 account, navigate to https://aws.amazon.com/ec2/ and click “Create new account” in the upper right. Complete the sign up process. You may be prompted for credit card information, however you should not be charged as long as you create only one virtual machine on the free tier. You then will have access to the Amazon AWS Console. If you are prompted, you want to sign in as a “Root” user for the AWS console. AWS Account Creation Note that it can take 24 hours for Amazon to verify your account. We believe this is because they manually review account creation — after all, they are giving you access to computing resources. Since cloud services are easily abused (e.g., for spam emails, command and control virus management, and distributed denial of service attacks), Amazon applies a bit of scrutiny to AWS users. Start early! . Notice: AWS Web GUI Changes Some of the screenshots in this guide are from older versions of the AWS Web Interface. The GUI changes fairly frequently and so your view may look a little different from the screenshots. Everything is fine and it’s good practice to follow along with documentation that is not an exact match. The course staff verified that the instructions work and pass the HW0 autograder most recently on 8/27/2022. If you believe you’ve discovered a problematic difference between this guide and the current version of the AWS GUI, contact your TA. Creating a New VM . Now that you have created an account, you can use the AWS Console to help manage and launch virtual machine instances. We will walk you through the steps to create an Ubuntu 22.04 VM below. (1) Open the AWS Console . After you create an AWS account, you can visit the AWS Console at https://console.aws.amazon.com. At the console, you should be greeted with a large screen full of many services. See highlight on left: . Click here to see AWS Console screenshot . (2) Open the EC2 Manager . From the AWS Console, click the “EC2” link to open the Elastic Cloud Compute manager. The EC2 Manager lets you manage and launch Instances, which are virtual machines that you configure. The first thing we need to do is configure and launch a new instance. Click the Launch Instance button. Click here to see EC2 Manager screenshot . (3) Choose an Ubuntu 22.04 LTS Instance . This is the most important step. You must select an Ubuntu Server 22.04 LTS (HVM), SSD Volume Type instance. This is a free tier eligible instance that contains an environment suitable for completing the rest of the assignments. Don’t pick other versions of Ubuntu (NOT 18.04 or 20.04, etc.). The autograder uses Ubuntu 22.04 (in an AWS VM!), so if you want the smoothest experience, use that version. As of 1/12/2023, the correct image is the default for Ubuntu: . Click here to see screenshot of the instructor selecting the correct VM image . After that you can fill out the rest of the selection (e.g., making certain to select your key pair for that instance) and then verify that it is in the Free Tier. Click here for \"free tier\" screenshot . (4) Configure Your Instance . After you select the image to launch, it may ask you a few questions about storage (pick the default if so). Usually, it will skip ahead and ask you about instance details. You want to pick the free version, called a t2.micro instance. If you were using cloud computing for a business or another project, you could configure resources like (a) how many CPUs, (b) how much RAM, and (c) what type of storage you get on the VM. For this course, just pick “t2.micro” to get the free level. Click here for instance type selection screenshot . (5) Configure Authentication . After you set up your instance, you need to create a way to login. This is a tricky security problem because Amazon wants to give you root (Administrator) access to your new instance. The way they do this is by using asymmetric key encryption. Basically, Amazon will let you download a file that serves as your credentials. Rather than entering a password, you will provide this special file to let you login. If you’d like to learn more about asymmetric key encryption, take a security course. Now, you will be prompted to set up credentials for logging in. Select Create a new key pair and type in any name (the examples use “eecs481” in the screenshots below). (If you are given a key type option, like “RSA” vs. “ED22519”, pick “RSA”.) Then, click Download Key Pair. It is imperative that you keep this file in a secure location. Do not upload it to GitHub, do not move it around. This is basically like a password for accessing your instance — you wouldn’t want someone malicious to access your instance and do something bad with it (you would be legally responsible for whatever they did!). Click here for keypair creation screenshot . Once you had downloaded your Key Pair, you should be able to Launch your instance. Do so and continue. There is a screenshot below showing what you should see after launching your instance. Click here for launch confirmation screenshot . (6) Connect to Your Instance . At this point, you have set up an Ubuntu 22.04 instance on EC2 and created associated credentials. You now have a virtual machine running in the cloud that you can connect to. You will use ssh to connect to your instance. This is the recommended way — you could technically install a front-end and use remote desktop software, however we strongly recommend using the command line, since you will be using the CLI in many of the course assignments. From the EC2 Management Dashboard, right-click your running instance. You should see a menu pop up like below: . Click “Connect”. It will pop up a window giving you a number of options. Pick the “SSH Client” tab to see how to connect via ssh: . On this window, you will see the hostname of your EC2 instance to which you can ssh, as well as a number of instructions for connecting. Mac permissions errors Some students, especially those using Mac computers, report receiving permission errors when they try to SSH into their EC2 instances: . In this case, a command like . chmod go-rwx /path/to/eecs481.pem . usually resolves the issue. More information is available online about this SSH issue. Using Windows WSL to SSH to EC2 If you are using Windows Subsystem for Linux (WSL) to connect to your Amazon EC2 instance, you must prepare your key file before connecting. Our recommendation is to run the following (but use your path): . mkdir -p ~/.ssh/ cp /path/to/your/downloaded/eecs481.pem ~/.ssh chmod 400 ~/.ssh/eecs481.pem . Windows WSL does not apply Linux file permissions correctly unless you are dealing with files contained within the Linux FS. Moving your key to ~/.ssh/ will allow you to chmod 400 appropriately. The SSH client will not allow you to connect to any server using that key if it does not have the correct permissions. Recall you downloaded a .pem file when you set up authentication for your instance (see part 5 above). You must specify this file on your SSH client to connect to your instance. First, you must provide the correct access permissions to the .pem file. Usually, this means running chmod 400 /path/to/your/.pem. Once you do so, you can use the ssh command directly: . ssh -i /path/to/your/.pem ubuntu@&lt;your-EC2-hostname-here&gt; . (You must substitute in the path to your downloaded .pem file as well as the hostname of your EC2 instance, which takes the form of ec2-X-Y-Z.us.W.compute.amazonaws.com for some values of W, X, Y, and Z. Collect these values from the EC2 Console.) . If you receive an error that the path is “too long for Unix domain socket” or the like, open ~/.ssh/config in a text editor and modify the control path to match this (reference): . Host * ControlPath ~/.ssh/control/%C ControlMaster auto . At this point, you should be logged in to your EC2 Instance! See below for an example of connecting to such an instance from the WSL environment (though note that the machine in the screenshot uses an old version of Ubuntu. Your instance should be version 22.04 (codename: jammy) instead of version 16.04): . Once you’re all finished, you need one more step to install gcc (a compiler for C and C++ programs): . sudo apt-get update sudo apt-get install gcc . You can safely stop the VM instance when you aren’t using it (e.g., between homeworks) and restart it when you are. ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#option-2--amazon-ec2",
    "relUrl": "/tutorials/ubuntu.html#option-2--amazon-ec2"
  },"93": {
    "doc": "Ubuntu Setup Guide",
    "title": "Final Remarks",
    "content": "There is a lot of systems programming in this course. We will use a mixture of command line tools, multiple languages, and other large projects that you may not have seen, written, or used before. That’s the point. In software engineering, much of your day-to-day work will involve reading code and documentation, as well as getting things set up to run. We are big believers that this type of experience is some of the most valuable you can acquire as a student — it makes you more productive at other tasks. This tutorial is not meant to take more than 2 hours (excluding the time taken to download the Ubuntu 22.04 .iso in Option 1, or the Amazon AWS signup time in Option 2). Please contact us on Discord if you have any questions! . ",
    "url": "/martinjkellogg.com/teaching/cs485-sp26/tutorials/ubuntu.html#final-remarks",
    "relUrl": "/tutorials/ubuntu.html#final-remarks"
  }
}
