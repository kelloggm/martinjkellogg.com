<!DOCTYPE html>
<!-- saved from url=(0092)https://courses.cs.washington.edu/courses/cse503/22sp/assignments/hw01-dev-difficulties.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>HW1: Software development difficulties</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<h1>HW1: Software development difficulties</h1>

<p>
  (With credit to <a href="https://homes.cs.washington.edu/~mernst/">Michael Ernst</a> for this assignment.)
</p>

<p>
Reflect on your software development experience.  Oftentimes it is lots of
fun, but at times it can be frustrating.
</p>

<p>
1.
Think of a time when some problem took you a lot of effort.  <b>Be specific</b>:
choose a <em>concrete incident</em> that you remember.  It should not be
trivially solvable by an existing technique or tool.  (Don't believe that
existing tools would solve all your problems, even if they claim to do so.  They
might only address part of your problem, or they might have poor usability, or
they might have other limitations.)  It should not be merely due to your
ignorance or inexperience.  (But, some tools can help you more rapidly learn
facts or overcome inexperience.  Don't believe that all problems you have had
are due to your ignorance or inexperience:  they are not!)
</p>

<p>
If you cannot remember a specific incident, then put the assignment aside, think
about it in the background, and come back to it later.  If you still can't
remember anything, you might want to look through the history of commits in
projects you have worked on, or issues opened and closed, or code reviews, or TA
comments.
</p>

<p>
After your name (which should be on all assignments),
write 1/2 to 2/3 page discussing the problem.  Give it a descriptive title.
Write about the same amount of text on each of the following:
</p>
<ol>
<li>
Describe the problem in sufficient technical detail for others to understand why
it was difficult.  The topic sentence (that is, the first sentence) should be an
informative summary or description of the problem.
</li><li>
Describe what methodologies and/or tools you used.  Be specific about ways
in which they were helpful and ways in which they fell short.
</li><li>
  Search for a tool or methodology that would solve your problem.
  <ul>
    <li>If one exists that completely solves your problem, you have learned
      something valuable, but don't write up that problem; start over at the
      beginning and choose a different problem to write up.  (As noted above,
      beware believing all tool/methodology claims.)
    </li>
    <li>
      If no tool exists that solves your problem, then describe the tool or
      tools that come closest to solving your problem, and explain how it falls
      short.
    </li>
    </ul>
</li><li>
Propose a tool that would solve your problem.  It might be similar to, or
completely different from, the one that you described above.  Describe at a high
level how it would work.  
Think about the challenges of building and deploying
such a tool.  Why do you think no one has built it already?

<p>
When thinking about how the tool might work, one approach (but not the only one)
is to start with how programmers solve it by hand.  What data do they use, and
how do they use it?  Whenever a task can be done manually, an approach to
automation is to dissect and understand the manual process, and see whether some
of the parts can be aided mechanically.  Even if you don't solve the entire
problem, automation can help programmers by performing one step.  Don't get
discouraged if some task is impossible.  Often there is a different way to solve
the underlying problem that programmers care about, or there is a special case
that is tractable.  Even approaches that seem impossible at first may help you
better understand the problem.
</p>
</li></ol>

<p>
2.
Do the same thing, but with a different problem and solutions.  Choose two
problems that are different from one another; for example, they shouldn't both
be about any one activity/topic, such as requirements, coding, testing,
debugging, performance, documentation, etc.
</p>

<p>
3. At the end of the document:
</p>
<ul>
<li>
List people or resources who helped you with this assignment.
(You don't need to mention web search, which you should definitely use.)
</li><li>
How many hours did you spend on this assignment?
</li></ul>

<p>
Submit a <b>two-page PDF</b> file.
Use a font size of 10 or 11 points, and standard margins (about 1 inch).
<!--
For anything that you submit in this class, place your
name and UW
user ID on the first page (or first slide).
-->
</p>

<p>
This assignment will reward careful thought about interesting problems and
issues.  Please introspect deeply and thoughtfully about software design,
development, and maintenance.  Doing so will help you in this class, and beyond.
</p>







<h2>Tips</h2>

<p>
Here is how to avoid some common problems that past students have had with this
assignment.
</p>

<dl>
  <dt>Write your name on your homework</dt>
  <dd>
  </dd>
  <dt>Be specific</dt>
  <dd>
    The most common reason for low grades on this assignment is lack of
    specificity.  The assignment asks for specific events in your life, not
    general descriptions of an abstract problem.  For example, don't merely say,
    “When writing tests, it is hard for me to figure out all the corner
    cases”, or “A common problem in C programming is segmentation
    faults”, or even “During my summer internship I spent a lot of
    time trying to read and understand ambiguous documentation.” Give
    enough details to understand the problem; don't describe it vaguely.  Also
    give concrete specifics about how the tools or methodologies you used were
    useful or not.
  </dd>
  <dt>Discover the underlying problem</dt>
  <dd>
    Sometimes it is easy to get tunnel vision and to get fixated on one
    particular approach.  Think about the underlying problem you were trying to
    solve, in addition to the specific way you were trying to solve it.  Is
    there a different approach to the problem that would be more effective?  Try
    to think outside the box.
  </dd> 
  <dt>Support your claims</dt>
  <dd>
    Don't say “Current techniques are not mature enough to do it,”
    without explaining why.  List and briefly describe current techniques, and
    explain why each one falls short.
  </dd>
  <dt>Avoid trivial problems</dt>
  <dd>
    Avoid discussing implementation annoyances unless you can identify an
    underlying principle.  (Example: “Windows (or Unix) lacks this feature
    that Unix (or Windows) has,” or “My favorite tool does not
    support <em>X</em>.”) Avoid mentioning difficulties in performing
    tasks that don't matter.  (Example: “I can't determine the cyclomatic
    complexity of my Tcl code.”) Avoid problems that are extremely minor
    or that can be solved easily.  (Example: “I often fail to balance
    delimiters before attempting to compile a file” or “There should
    be a public forum where people can ask and answer questions about
    tool <em>X</em>”,)
  </dd>
</dl>

<p>
Showing example code may be helpful, but is not needed for every
writeup, not even all those about issues with code.
</p>


<!--
<h2>Examples from previous years</h2>

   <p>
     Here are two example answers. Your answer should not use these particular
     problems.  (Since your problem should
     be based on an anecdote from your own experience, it should have
     been different anyway!).
   </p>

Below are some examples, but you will base yours on your own experience,
you will discuss each item in more detail, and you will illustrate it with
an anecdote.


<h3>Example 1: Un-chaining method calls for debugging</h3>

<p>
     It is a hassle to debug a long line with many function calls ("fluent style"), at least one of which fails or produces a bad result. You have to step in and out of functions on a single line of code trying to determine what is going wrong, and generally you can't see the intermediate results. The problem itself is not difficult to get around, but annoying and it wastes valuable time.
</p>

<p>
     Generally when I come across this problem, I split up the single line of code into multiple lines, with each function call result stored in its own temporary variable. An example of this is shown below:
</p>

Before:
<pre>
    return obj1.toString().substring(obj2.getList().get(idx).getIntValue());
</pre>

After:
<pre>
    List&lt;Val&gt; list1 = obj2.getList();
    Val val1 = list1.get(idx);
    int int1 = val1.getIntValue();
    String string1 = obj1.toString();
    String string2 = string1.substring(int1);
    return string2;
</pre>

<p>
       This strategy works and I can clearly tell which function call is causing the improper behavior, but it is tedious especially when you must do it a lot on a codebase.
</p>

<p>
       Eclipse has a feature for Java that allows you to see the previous
       function's returned value while debugging, and Visual Studio has a
       similar feature for C# and C++. These features are helpful and I was
       not aware they existed, but it does not give you a way to deal with
       many function calls and storing all their results temporarily for
       debugging.
</p>

<p>
       The tool I would create would simply automate the procedure I used above. The tool would be able to expand a single line of code into multiple lines, storing function return values into variables so they can easily be viewed while debugging. Often, it is cleaner and more readable to split up a line with many function calls anyways, but my tool would also support collapsing lines of code as well back into a single line. Essentially the tool would parse the line of code looking for a function call, determine its return type by finding the function header, create a new line with a temporary variable, and replace the original function call with the temporary variable. For collapsing, you would select lines of code to collapse, and the process would be reversed. I think nobody has built this tool already because it is relatively low effort to do this process by hand, and often lines of code aren't nested as deep as the example I provided.
</p>

<h3>Example 2: Smarter println debugging</h3>

<p>
     During my course in operating systems, we had to implement swapping in and out pages from physical memory to disk. One problem that occurred was concurrency and the way my partner and I had to handle multiple processes either trying to access a specific page that may or may not already been swapped out to disk. With a single process, the idea was simple. If there was no more memory in physical memory, take that page and put it to disk allowing a new page in physical memory to be allocated. If a page wanted to be accessed and was on disk, then we would have to swap out a page on disk, and swap in the one trying to be accessed. However, a huge problem rose as multiple processes were trying to swap in and out when memory got full. The test suite had multiple forks and concurrent operations that made our implementation buggy. Concurrency made the whole process a nightmare to debug.
</p>

<p>
     At first, my partner and I tried to debug via gdb. We would get to a point where the program would swap in correctly and then the operating system would switch to user mode and call fork, our program would then enter a state where it would panic and error out.We began to look at kalloc, the function where a new page would be allocated or swapped out to disk when physical memory was full. However, after looking through our code over several times, we could not find the problem and gdb would reach a dead end. We then resorted to printfs to figure out what was happening. We filled our own code base with printfs where we would swap out or swap in or enter a function. This helped us know the sequence of which all the functions were called and tried to find patterns or unexpected behavior. We eventually figured out that our program was swapping in and out the same page which was fixed by implementing a least recently used page instead of the first available one. However, as we fixed our bug. Our code base had more printlns than actual code. We basically had to grep all the printlns, one by one and delete them. Our test suite output was still flooded with printlns and sometimes tracking or remembering where the println came from became a nightmare. Both gdb and printlns helped us solve our problem and were useful ways of debugging, but when it came to concurrency, gdb fell short since we didn't know all the features. Also printlns became a nightmare when trying to clean up our code and push our code to git.
</p>

<p>
     After searching and looking online for general concurrency debuggers. I found that gdb has a watch command that looks at and addresses and notifies the us when it something changes at that address. Another useful command I found was backtrace where after a program crashes, gdb can tell you the order of functions that lead up to the crash. People also recommended adding asserts to ensure there wasn't overflow with variable or to ensure expected range values for variables. There was also another mention about logging to figure out where the program may have went wrong. I think the tool that comes closest to solving our problem was the logging which was basically what the printfs were. They helped us understand which locks were where, which functions were being called and what was changing. Logging is basically a timeline of what executed and that was exactly what we needed to solve our problem.
</p>

<p>
     One tool that I think would be useful after my experience with concurrency is a debugging tool that enable and disabled printlns or lines of code specifically for debugging. For instance, when the debugging mode is on, we could add printlns to the code and it would appear red in whatever text editor. When the debugging mode is off, the printlns go away and the code is in a state where it can be pushed. This would be useful for my specific experience with concurrency since it would allow me to continue debugging and not worrying about ruining the already implemented code. When a printf or assert or any debugging purposed line of code is written, it can be marked as a debug line to be used in execution when debugging mode is on. One problem with this would be working with various text editors or ides to make it compatible. Also a problem would be how to specifically mark a line of code since we can't just mark the line number. Such a tool probably has been implemented but in the form of logging. However, I think having on the spot on and off debugging would be a pretty cool feature to implement.


\begin{itemize}\itemsep 0pt \parskip 0pt
\item
  In dynamically-typed languages, it is easy to apply illegal operations to
  data, and for such errors to be latent for long periods until some input
  exposes them.  Even if easily reproducible, they might be exposed only
  after other long-running computations, making them difficult to detect.
  This sort of error is particularly frequent when accessing deeply-nested
  data structures:  it is easy to forget one level of dereference.
\item
  Interning values (replacing them by a canonical version) saves space,
  since only one version needs to be stored, and also saves time, since
  equality testing can be performed via pointer comparisons.  Failure to
  properly intern can be extremely hard to track down, however.
\item
  Reusing code requires an understanding of its behavior.  Most code is not
  documented, however.  This lack of specifications and documentation makes
  it difficult to use the code and difficult to know its assumptions or
  operational parameters (the values over which it has been tested and is
  known to work).
\item
  Large components are often more worth reusing than small ones.  However,
  they are also more likely to make assumptions (such as that they control
  execution of the program, that there is no need for thread safety, or
  that batch processing is acceptable) that may not be acceptable to an
  integrator who wishes to use these large components.
\item
  Test suites are crucial to eliminating bugs and improving confidence in
  programs, but are difficult and tedious to create.  For example, it may
  be difficult to create valid inputs to a program, because there are
  implicit constraints on the input.  Given an arbitrary input to the
  program, it can be difficult to determine whether the program operated
  correctly.
\item
  Large, comprehensive test suites tend to take a long time to execute.
  That discourages developers from using them as frequently as they ought
  to, or slows them down waiting for tests to complete when they could be
  moving on to other tasks.
\item
  Some
%%% 
  program analyses produce so much output
%%%
  code quality tools produce so many warnings
%%%
  that it is difficult or
  time-consuming to separate the useful information from spurious reports,
  prompting programmers to give up on these tools.
  % Use machine learning to automatically classify the output.
\item
  &ldquo;Maintenance&rdquo; activities (modifying a program) tend to degrade its
  structure at both the macro (modules) and micro (specific functions)
  levels.
  % How can this be avoided?  (Making more clear what the
  % consequences of the change are; making more clear what the properties
  % before the change are.)
\item
  Good performance can be achieved by storing computed values in a cache;
  the next time a value is needed, it can be looked up rather than
  recomputed.  However, if values in the caches are side-effected or if the
  computation depends on values that are not use as an index into the
  cache, the cache becomes corrupted, leading to extremely hard-to-debug
  errors.

\item
  It is hard to build new analyses for existing languages;
  lots of grunge work is required, even though building a front end is no
  longer considered interesting research.  A related problem is that real
  infrastructures are difficult to use, and it is difficult to integrate
  new tools with them.
  % (Correcting this probably requires building
  %  quite a bit of infrastructure that would extend beyond a one-semester
  %  class project.)



% Examples:
%  * shadowed variables
%  * make a change which violates an undocumented assumption in the program,
%    introducing a bug in a far-removed part of the program
%  * ensure program conforms to the architecture specified in its design
%  * deep const
%  * asserts in code can fire for users; wish to statically discharge them (or
%    partially discharge them)
%  * visualization of complex data
%  * teasing apart conflated types (eg, convert (some) int to bool, or to a
%    struct.  typechecker might or might not help.
\end{itemize}
-->




<!--  LocalWords:  obj1 substring obj2 getList idx getIntValue list1 val1 int1 string1 string2 writeup gdb theoperating kalloc printfs printlns println backtrace
 -->
<!--  LocalWords:  shouldn aren didn wasn Tcl
 -->
</body></html>
